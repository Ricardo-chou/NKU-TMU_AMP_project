{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac73ec49-5ed7-4779-9071-b9d89403916b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: fair-esm in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: openpyxl in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (0.22.1)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (1.1.5)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (1.19.5)\n",
      "Requirement already satisfied: torch in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (1.8.0)\n",
      "Collecting xlrd\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/a6/0c/c2a72d51fe56e08a08acc85d13013558a2d793028ae7385448a6ccdfae64/xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96 kB 65.0 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: et-xmlfile in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.8/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm openpyxl scikit-learn pandas numpy torch xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bf85d9-cc83-4f10-9faa-ab99bcf7e957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.8.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages\n",
      "Requires: numpy, typing-extensions\n",
      "Required-by: torchvision, torchtext\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561aac4c-82c2-4319-8c66-d473d7d74a81",
   "metadata": {},
   "source": [
    "# **ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡å·¥ä½œå°ï¼(ç¯å¢ƒè®¾ç½®ä¸å¯¼å…¥åº“)**\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬è¦å¼€å§‹ä¸€ä¸ªé‡è¦çš„ç”Ÿç‰©å®éªŒï¼é¦–å…ˆå¾—æŠŠå®éªŒå°æ”¶æ‹¾å¹²å‡€ï¼ŒæŠŠæ‰€æœ‰éœ€è¦çš„å·¥å…·å’Œè¯•å‰‚å‡†å¤‡å¥½ï¼Œå¯¹å§ï¼Ÿè¿™ä¸€æ­¥å°±æ˜¯åšè¿™ä¸ªå‡†å¤‡å·¥ä½œã€‚æˆ‘ä»¬ä¼šï¼š\n",
    "\n",
    "1.  **å¯¼å…¥â€œå·¥å…·ç®±â€ :** åŠ è½½æ‰€æœ‰éœ€è¦çš„ Python åº“ï¼Œæ¯”å¦‚ `pandas` (å¤„ç†è¡¨æ ¼æ•°æ®è¶…æ–¹ä¾¿)ã€`numpy` (ç§‘å­¦è®¡ç®—åŸºç¡€)ã€`torch` å’Œ `esm` (æˆ‘ä»¬è¯·æ¥çš„â€œè›‹ç™½è´¨è¯­è¨€å¤§å¸ˆâ€ ESM æ¨¡å‹å°±ä½åœ¨è¿™é‡Œé¢)ã€ä»¥åŠ `sklearn` (æœºå™¨å­¦ä¹ â€œæ­¦å™¨åº“â€ï¼Œéšæœºæ£®æ—å°±åœ¨è¿™)ã€‚\n",
    "2.  **è®¾å®šâ€œå®éªŒå‚æ•°â€ :** å‘Šè¯‰ç¨‹åºæˆ‘ä»¬çš„æ•°æ®æ”¾åœ¨å“ªé‡Œ (`DATA_DIR`)ï¼Œè¦ç”¨å“ªä¸ªç‰ˆæœ¬çš„ ESM æ¨¡å‹ (`ESM_MODEL_NAME` - æˆ‘ä»¬ä¼šé€‰ä¸€ä¸ªå¯¹ CPU å‹å¥½çš„ç‰ˆæœ¬å“¦ï¼)ï¼Œä»¥åŠæ¯”èµ›è§„åˆ™ï¼ˆæ¯”å¦‚æœ€å¤šåªèƒ½çªå˜å‡ ä¸ªä½ç‚¹ `MAX_MUTATIONS`ï¼‰ã€‚\n",
    "3.  **æ£€æŸ¥â€œç¡¬ä»¶â€:** çœ‹çœ‹æœ‰æ²¡æœ‰ GPU å¯ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6771f530-01d6-488d-ba54-a5a0be261d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # å¤„ç†è¡¨æ ¼æ•°æ®ï¼ˆå¦‚ Excelã€CSVï¼‰\n",
    "import numpy as np   # æ•°å­¦è®¡ç®—åº“\n",
    "import torch         # PyTorchï¼Œä¸»è¦ç”¨äºæ¨¡å‹åŠ è½½ä¸è¿è¡Œ\n",
    "import esm           # Facebook çš„è›‹ç™½è¯­è¨€æ¨¡å‹åº“ ESMï¼ˆç”¨äºæå–è›‹ç™½åºåˆ—åµŒå…¥ï¼‰\n",
    "import os            # æ“ä½œæ–‡ä»¶è·¯å¾„\n",
    "import random        # è®¾ç½®éšæœºç§å­\n",
    "from sklearn.model_selection import train_test_split  # è®­ç»ƒé›†æµ‹è¯•é›†åˆ’åˆ†\n",
    "from sklearn.metrics import r2_score                  # æ¨¡å‹æ€§èƒ½è¯„ä¼°æŒ‡æ ‡\n",
    "import re           # æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºå¤„ç†çªå˜ä¿¡æ¯\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # å¿½ç•¥è­¦å‘Šä¿¡æ¯ï¼ˆä¸å½±å“ä¸»é€»è¾‘ï¼‰\n",
    "\n",
    "# å¸¸é‡å®šä¹‰ \n",
    "TRAIN_DATA_FILE = os.path.join('GFP_data.xlsx')  \n",
    "# åŒ…å«äº®åº¦ã€çªå˜ä¿¡æ¯ç­‰è®­ç»ƒæ•°æ®çš„ Excel æ–‡ä»¶\n",
    "WT_SEQ_FILE = os.path.join('AAseqs of 4 GFP proteins.txt')  \n",
    "# 4 ä¸ª GFP è›‹ç™½çš„æ°¨åŸºé…¸åºåˆ—ï¼ˆwild-type åºåˆ—ï¼‰ï¼Œåç»­å°†åŸºäºè¿™äº›åºåˆ—è®¾è®¡çªå˜\n",
    "EXCLUSION_FILE = os.path.join('Exclusion_List.csv')  \n",
    "# ä¸å…è®¸çš„åºåˆ—æ¸…å•ï¼Œå¯èƒ½æ˜¯å¤±è´¥åºåˆ—ã€æ¯’æ€§åºåˆ—ç­‰ï¼ˆç”¨äºè¿‡æ»¤ï¼‰\n",
    "\n",
    "\n",
    "# --- æ¨¡å‹ä¸ç”Ÿæˆå‚æ•° ---\n",
    "ESM_MODEL_NAME = \"esm2_t12_35M_UR50D\" # é€‰æ‹©ä¸€ä¸ªä¸­ç­‰å¤§å°çš„ESMæ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œæ€§èƒ½\n",
    "MAX_MUTATIONS = 6 # æ¯”èµ›è§„åˆ™ï¼šæœ€å¤š6ä¸ªçªå˜\n",
    "N_CANDIDATES_TO_GENERATE = 500 # ç”Ÿæˆå€™é€‰åºåˆ—çš„æ•°é‡ï¼ˆå¯è°ƒæ•´ï¼‰\n",
    "TOP_N_SELECT = 10 # æœ€ç»ˆé€‰æ‹©çš„åºåˆ—æ•°é‡\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ä¾¿ç»“æœå¯å¤ç°ï¼ˆå¯é€‰ï¼‰\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f143d-9aca-4f20-830f-29df29b407ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " # **ç¬¬äºŒæ­¥ï¼šè·å–åŸæ–™å¹¶æ¸…æ´—ï¼(æ•°æ®åŠ è½½ä¸é¢„å¤„ç†)**\n",
    "\n",
    "å®éªŒææ–™æ¥äº†ï¼æˆ‘ä»¬éœ€è¦å¤„ç†å¥½è¿™äº›â€œåŸæ–™â€æ‰èƒ½è¿›è¡Œä¸‹ä¸€æ­¥ã€‚æˆ‘ä»¬ä¼šï¼š\n",
    "\n",
    "1.  **åŠ è½½â€œé…æ–¹è¡¨â€ :** è¯»å– `GFP_data.xlsx` æ–‡ä»¶ï¼Œè¿™é‡Œé¢è®°å½•äº†å¾ˆå¤šå·²çŸ¥çš„ GFP çªå˜ä»¥åŠå®ƒä»¬çš„äº®åº¦ä¿¡æ¯ã€‚è¿™æ˜¯æˆ‘ä»¬å­¦ä¹ çš„åŸºç¡€ï¼\n",
    "2.  **æ‰¾åˆ°â€œåŸå§‹æ¨¡æ¿â€ :** ä» `AAseqs of 4 GFP proteins.txt` æ–‡ä»¶é‡Œæ‰¾åˆ°æˆ‘ä»¬è¿™æ¬¡çš„ç›®æ ‡â€”â€”avGFP çš„é‡ç”Ÿå‹æ°¨åŸºé…¸åºåˆ—ã€‚è¿™æ˜¯æˆ‘ä»¬è¿›è¡Œæ”¹é€ çš„åŸºç¡€ã€‚\n",
    "3.  **æ‹¿åˆ°â€œç¦æ­¢åå•â€ :** åŠ è½½ `Exclusion_List.csv` æ–‡ä»¶ã€‚è®°ä½ï¼è¿™é‡Œé¢çš„åºåˆ—æ˜¯**ä¸èƒ½**æäº¤çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¾—æ—¶åˆ»å¯¹ç…§ç€å®ƒã€‚\n",
    "4.  **ç­›é€‰ä¸è½¬æ¢ :** æˆ‘ä»¬åªå…³å¿ƒ avGFP çš„æ•°æ®ï¼Œæ‰€ä»¥ä¼šå…ˆç­›é€‰ä¸€ä¸‹ã€‚ç„¶åï¼Œæœ€å…³é”®çš„ä¸€æ­¥ï¼šæŠŠ \"G101A\" è¿™ç§çªå˜æè¿°ï¼Œåº”ç”¨åˆ°åŸå§‹æ¨¡æ¿ä¸Šï¼Œç”Ÿæˆæ¯ä¸€ä¸ªçªå˜ä½“**å®Œæ•´**çš„æ°¨åŸºé…¸åºåˆ—ã€‚è¿™å°±åƒæŒ‰é…æ–¹ä¿®æ”¹åŸå§‹æ¨¡æ¿ï¼Œå¾—åˆ°å…·ä½“çš„æˆå“åºåˆ—ã€‚\n",
    "5.  **æ¸…æ´—æ•´ç† :** æ£€æŸ¥ä¸€ä¸‹ï¼Œç¡®ä¿ç”Ÿæˆçš„åºåˆ—æ˜¯æœ‰æ•ˆçš„ï¼Œäº®åº¦å€¼ä¹Ÿæ˜¯æ­£å¸¸çš„æ•°å­—ã€‚æŠŠä¸€äº›æœ‰é—®é¢˜çš„â€œåŸæ–™â€å‰”é™¤æ‰ï¼Œä¿è¯æˆ‘ä»¬åç»­ä½¿ç”¨çš„æ˜¯é«˜è´¨é‡æ•°æ®ã€‚\n",
    "\n",
    "å¤„ç†å®Œè¿™äº›ï¼Œæˆ‘ä»¬å°±æœ‰äº†å¹²å‡€ã€è§„èŒƒçš„è®­ç»ƒæ•°æ®å•¦ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3e7c5-cea9-4f0a-9deb-d5ecf25f55a7",
   "metadata": {},
   "source": [
    "## 2.1 åŠ è½½è®­ç»ƒæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "770c4590-f020-4215-82e3-ca159e546a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading training data...\")\n",
    "try:\n",
    "    gfp_df = pd.ExcelFile(TRAIN_DATA_FILE, sheet_name='brightness') # å‡è®¾äº®åº¦æ•°æ®åœ¨åä¸º 'brightness' çš„ sheet\n",
    "    print(f\"Loaded {len(gfp_df)} rows from {TRAIN_DATA_FILE}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Training data file not found at {TRAIN_DATA_FILE}\")\n",
    "    # exit() # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦åœæ­¢æ‰§è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931e6ad-2b02-4daa-8ff9-7244d3f70ae9",
   "metadata": {},
   "source": [
    "## 2.2 åŠ è½½ avGFP é‡ç”Ÿå‹åºåˆ— "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329667ad-b658-4f6c-aca1-3da1fcc577bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading avGFP WT sequence...\n",
      "Found avGFP WT sequence (Length: 238).\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading avGFP WT sequence...\")\n",
    "avGFP_WT_sequence = None\n",
    "try:\n",
    "    with open(WT_SEQ_FILE, 'r') as f:\n",
    "        # å‡è®¾æ–‡ä»¶æ ¼å¼æ˜¯ >Header \\n Sequence \\n >Header2...\n",
    "        # æˆ‘ä»¬éœ€è¦æ‰¾åˆ° avGFP çš„åºåˆ—\n",
    "        header = \"\"\n",
    "        seq_lines = []\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                # å¦‚æœæ‰¾åˆ°äº†ä¸Šä¸€ä¸ªåºåˆ—ï¼Œå¹¶ä¸”æ˜¯avGFPï¼Œä¿å­˜å®ƒ\n",
    "                if \"avGFP\" in header and seq_lines:\n",
    "                    avGFP_WT_sequence = \"\".join(seq_lines).strip()\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                # å¼€å§‹æ–°çš„åºåˆ—è®°å½•\n",
    "                header = line.strip()\n",
    "                seq_lines = []\n",
    "            else:\n",
    "                seq_lines.append(line.strip())\n",
    "        # å¤„ç†æ–‡ä»¶æœ€åä¸€ä¸ªåºåˆ—çš„æƒ…å†µ\n",
    "        if avGFP_WT_sequence is None and \"avGFP\" in header and seq_lines:\n",
    "             avGFP_WT_sequence = \"\".join(seq_lines).strip()\n",
    "\n",
    "    if avGFP_WT_sequence:\n",
    "        print(f\"Found avGFP WT sequence (Length: {len(avGFP_WT_sequence)}).\")\n",
    "        # print(avGFP_WT_sequence) # å¯ä»¥å–æ¶ˆæ³¨é‡ŠæŸ¥çœ‹åºåˆ—\n",
    "    else:\n",
    "        print(\"Error: avGFP WT sequence not found in\", WT_SEQ_FILE)\n",
    "        # æ‰‹åŠ¨è®¾ç½®ä¸€ä¸ªé»˜è®¤å€¼æˆ–åœæ­¢æ‰§è¡Œ\n",
    "        # avGFP_WT_sequence = \"MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\" # ç¤ºä¾‹\n",
    "        # print(\"Using default WT sequence.\")\n",
    "        # exit()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: WT sequence file not found at {WT_SEQ_FILE}\")\n",
    "    # exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e7e8d29-36c0-4b01-9fbf-edaa5a594ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sheet_name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_37730/2857899309.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Loading training data...\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mgfp_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExcelFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTRAIN_DATA_FILE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msheet_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'brightness'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# å‡è®¾äº®åº¦æ•°æ®åœ¨åä¸º 'brightness' çš„ sheet\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Loaded {len(gfp_df)} rows from {TRAIN_DATA_FILE}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mexcept\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'sheet_name'"
     ]
    }
   ],
   "source": [
    "# --- 2.3 åŠ è½½æ’é™¤åˆ—è¡¨ ---\n",
    "print(\"Loading exclusion list...\")\n",
    "try:\n",
    "    exclusion_df = pd.read_csv(EXCLUSION_FILE)\n",
    "    # å‡è®¾æ’é™¤åºåˆ—åœ¨åä¸º 'sequences-not-submit' çš„åˆ—ä¸­\n",
    "    exclusion_sequences = set(exclusion_df['sequences-not-submit'].astype(str))\n",
    "    print(f\"Loaded {len(exclusion_sequences)} sequences into exclusion list.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Exclusion list file not found at {EXCLUSION_FILE}\")\n",
    "    exclusion_sequences = set() # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºé›†åˆ\n",
    "    print(\"Warning: Proceeding without an exclusion list.\")\n",
    "except KeyError:\n",
    "    print(f\"Error: Column 'sequences-not-submit' not found in {EXCLUSION_FILE}\")\n",
    "    exclusion_sequences = set()\n",
    "    print(\"Warning: Proceeding without an exclusion list.\")\n",
    "\n",
    "\n",
    "# --- 2.4 é¢„å¤„ç†è®­ç»ƒæ•°æ® ---\n",
    "print(\"Preprocessing training data...\")\n",
    "# ç­›é€‰ avGFP æ•°æ®\n",
    "avGFP_train_df = gfp_df[gfp_df['GFP type'] == 'avGFP'].copy()\n",
    "print(f\"Filtered down to {len(avGFP_train_df)} avGFP entries.\")\n",
    "\n",
    "# å®šä¹‰å‡½æ•°ï¼šæ ¹æ®çªå˜å­—ç¬¦ä¸²ç”Ÿæˆå®Œæ•´åºåˆ—\n",
    "def generate_mutated_sequence(mutation_str, wt_sequence):\n",
    "    \"\"\"\n",
    "    æ ¹æ®çªå˜æè¿°å­—ç¬¦ä¸²å’Œé‡ç”Ÿå‹åºåˆ—ç”Ÿæˆçªå˜åçš„å®Œæ•´åºåˆ—ã€‚\n",
    "    mutation_str: e.g., \"WT\", \"G101A\", \"A12B:C34D\"\n",
    "    wt_sequence: é‡ç”Ÿå‹æ°¨åŸºé…¸åºåˆ—å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    if not isinstance(mutation_str, str) or not wt_sequence:\n",
    "        return None\n",
    "    if mutation_str.strip().upper() == 'WT':\n",
    "        return wt_sequence\n",
    "\n",
    "    sequence = list(wt_sequence)\n",
    "    mutations = mutation_str.split(':') # æ”¯æŒå¤šä¸ªçªå˜ï¼Œä»¥å†’å·åˆ†éš”\n",
    "    valid_mutation_count = 0\n",
    "    try:\n",
    "        for mut in mutations:\n",
    "            match = re.match(r'([A-Z])(\\d+)([A-Z*.])$', mut.strip(), re.IGNORECASE) # åŒ¹é… G101A, T203*, V163.\n",
    "            if match:\n",
    "                original_aa, pos, new_aa = match.groups()\n",
    "                pos = int(pos) - 1 # è½¬æ¢ä¸º 0-based index\n",
    "\n",
    "                # æ£€æŸ¥ä½ç½®æ˜¯å¦æœ‰æ•ˆ\n",
    "                if pos < 0 or pos >= len(sequence):\n",
    "                    # print(f\"Warning: Invalid position {pos+1} in mutation '{mut}' for sequence length {len(sequence)}. Skipping mutation.\")\n",
    "                    continue # è·³è¿‡æ— æ•ˆä½ç½®çš„çªå˜\n",
    "\n",
    "                # æ£€æŸ¥åŸå§‹æ°¨åŸºé…¸æ˜¯å¦åŒ¹é… (å¯é€‰ï¼Œä½†å»ºè®®)\n",
    "                if sequence[pos].upper() != original_aa.upper():\n",
    "                    # print(f\"Warning: Original AA mismatch at position {pos+1} in mutation '{mut}'. Expected {sequence[pos]}, got {original_aa}. Applying mutation anyway.\")\n",
    "                    pass # å…è®¸ä¸åŒ¹é…ï¼Œä½†æ‰“å°è­¦å‘Š\n",
    "\n",
    "                # å¤„ç†ç‰¹æ®Šå­—ç¬¦\n",
    "                if new_aa == '*': # ç»ˆæ­¢å¯†ç å­ - é€šå¸¸ä¸å¸Œæœ›å‡ºç°åœ¨ä¸­é—´\n",
    "                    # print(f\"Warning: Stop codon '*' mutation '{mut}' encountered. Treating as deletion or invalid sequence for this tutorial.\")\n",
    "                    # å¯¹äºäº®åº¦é¢„æµ‹ï¼Œç»ˆæ­¢å¯†ç å­é€šå¸¸å¯¼è‡´æ— åŠŸèƒ½è›‹ç™½ï¼Œå¯ä»¥è¿”å›Noneæˆ–ç‰¹æ®Šæ ‡è®°\n",
    "                    return None # æˆ–è€…æ ¹æ®éœ€è¦å¤„ç†\n",
    "                elif new_aa == '.': # è¡¨ç¤ºä¸åŸæ°¨åŸºé…¸ç›¸åŒ (æ— çªå˜)\n",
    "                    new_aa = sequence[pos] # ä¿æŒä¸å˜\n",
    "\n",
    "                sequence[pos] = new_aa.upper()\n",
    "                valid_mutation_count += 1\n",
    "            else:\n",
    "                # print(f\"Warning: Could not parse mutation '{mut}'. Skipping.\")\n",
    "                pass # è·³è¿‡æ— æ³•è§£æçš„çªå˜æ ¼å¼\n",
    "        # å¦‚æœæ²¡æœ‰æˆåŠŸåº”ç”¨ä»»ä½•çªå˜ï¼ˆå¯èƒ½æ˜¯æ ¼å¼é—®é¢˜ï¼‰ï¼Œè¿”å›None\n",
    "        # if valid_mutation_count == 0 and mutations:\n",
    "        #     return None\n",
    "        return \"\".join(sequence)\n",
    "    except Exception as e:\n",
    "        # print(f\"Error processing mutation string '{mutation_str}': {e}\")\n",
    "        return None # è¿”å› None è¡¨ç¤ºåºåˆ—ç”Ÿæˆå¤±è´¥\n",
    "\n",
    "# åº”ç”¨å‡½æ•°ç”Ÿæˆåºåˆ—\n",
    "avGFP_train_df['full_sequence'] = avGFP_train_df['aaMutations'].apply(\n",
    "    lambda x: generate_mutated_sequence(x, avGFP_WT_sequence)\n",
    ")\n",
    "\n",
    "# æ¸…ç†æ•°æ®ï¼šç§»é™¤åºåˆ—ç”Ÿæˆå¤±è´¥æˆ–äº®åº¦æ— æ•ˆçš„è¡Œ\n",
    "original_len = len(avGFP_train_df)\n",
    "avGFP_train_df.dropna(subset=['full_sequence', 'Brightness'], inplace=True)\n",
    "# ç¡®ä¿äº®åº¦æ˜¯æ•°å€¼ç±»å‹\n",
    "avGFP_train_df['Brightness'] = pd.to_numeric(avGFP_train_df['Brightness'], errors='coerce')\n",
    "avGFP_train_df.dropna(subset=['Brightness'], inplace=True)\n",
    "\n",
    "print(f\"Removed {original_len - len(avGFP_train_df)} rows due to invalid sequences or brightness.\")\n",
    "print(f\"Final training set size: {len(avGFP_train_df)}\")\n",
    "\n",
    "# æŸ¥çœ‹å¤„ç†åçš„æ•°æ®\n",
    "print(\"\\nSample of processed training data:\")\n",
    "print(avGFP_train_df[['aaMutations', 'Brightness', 'full_sequence']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06166a-0e02-4773-a817-d7ad187feb52",
   "metadata": {},
   "source": [
    "---\n",
    "ğŸ§  **ç¬¬ä¸‰æ­¥ï¼šè®©æœºå™¨è¯»æ‡‚è›‹ç™½è´¨è¯­è¨€ï¼(ç‰¹å¾å·¥ç¨‹ - ESM åµŒå…¥)**\n",
    "\n",
    "è›‹ç™½è´¨åºåˆ—å°±åƒä¸€ç§ç‰¹æ®Šçš„è¯­è¨€ï¼Œç›´æ¥ä¸¢ç»™æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒå¯èƒ½çœ‹ä¸æ‡‚ã€‚æˆ‘ä»¬éœ€è¦æŠŠå®ƒç¿»è¯‘æˆæ¨¡å‹èƒ½ç†è§£çš„â€œæ•°å­—è¯­è¨€â€ã€‚è¿™å°±æ˜¯ ESM å¤§æ˜¾èº«æ‰‹çš„æ—¶å€™äº†ï¼ä½†æ˜¯ï¼Œè€ƒè™‘åˆ°å¤§å®¶çš„ CPU å¯èƒ½æ¯”è¾ƒâ€œåƒåŠ›â€ï¼Œæˆ‘ä»¬åšäº†ç‰¹åˆ«ä¼˜åŒ–ï¼š\n",
    "\n",
    "1.  **è¯·ä¸ªâ€œè½»é‡çº§â€å¤§å¸ˆ ğŸ‘¨â€ğŸ«:** æˆ‘ä»¬ä¼šåŠ è½½ä¸€ä¸ª**æ›´å°å·§ã€æ›´å¿«é€Ÿ**çš„ ESM æ¨¡å‹ç‰ˆæœ¬ (`esm2_t6_8M_UR50D`)ã€‚å®ƒè™½ç„¶å‚æ•°å°‘ä¸€ç‚¹ï¼Œä½†è·‘èµ·æ¥ä¼šå¿«å¾ˆå¤šï¼\n",
    "2.  **â€œæŠ½æ ·â€å­¦ä¹  ğŸ“‰:** æˆ‘ä»¬ä¸éœ€è¦æŠŠè®­ç»ƒæ•°æ®é‡Œæˆåƒä¸Šä¸‡æ¡åºåˆ—å…¨éƒ½æ‰”ç»™ ESM å¤„ç†ï¼ˆé‚£æ ·å¤ªæ…¢äº†ï¼ï¼‰ã€‚æˆ‘ä»¬ä¼šä»ä¸­**éšæœºæŠ½å–ä¸€éƒ¨åˆ†**ï¼ˆæ¯”å¦‚ 1 ä¸‡æ¡ï¼‰ä½œä¸ºä»£è¡¨æ¥è¿›è¡Œå­¦ä¹ ã€‚è¿™å°±åƒè€ƒè¯•å‰åˆ’é‡ç‚¹ï¼Œèƒ½å¤§å¤§èŠ‚çœæ—¶é—´ï¼â³\n",
    "3.  **ç”Ÿæˆâ€œæ•°å­—æŒ‡çº¹â€ ğŸ”¢:** å¯¹äºæŠ½æ ·é€‰å‡ºçš„æ¯ä¸€æ¡è›‹ç™½è´¨åºåˆ—ï¼ŒESM æ¨¡å‹ä¼šé˜…è¯»å®ƒï¼Œå¹¶è¾“å‡ºä¸€ä¸ªå›ºå®šé•¿åº¦çš„æ•°å­—åˆ—è¡¨ï¼ˆå‘é‡ï¼‰ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œåµŒå…¥â€(Embedding)ã€‚è¿™ä¸ªåµŒå…¥å°±åƒæ˜¯è¿™æ¡è›‹ç™½è´¨åºåˆ—çš„â€œæ•°å­—æŒ‡çº¹â€ï¼ŒåŒ…å«äº†å®ƒçš„å…³é”®ç”Ÿç‰©å­¦ä¿¡æ¯ã€‚\n",
    "\n",
    "æœ‰äº†è¿™äº›â€œæ•°å­—æŒ‡çº¹â€ï¼Œæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹å°±èƒ½æ›´å¥½åœ°ç†è§£è›‹ç™½è´¨åºåˆ—äº†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9430787d-01ef-4e33-856a-bc2cff4edc9f",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_50",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:11:15.305674Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_50",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "æ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨GPUè¿›è¡Œè®¡ç®—ã€‚\n",
      "æ­£åœ¨ä½¿ç”¨è®¾å¤‡: cuda\n",
      "å°†åŠ è½½çš„ESMæ¨¡å‹: esm2_t30_150M_UR50D\n",
      "å°†ä½¿ç”¨çš„æ‰¹æ¬¡å¤§å°: 16\n",
      "\n",
      "æ­£åœ¨æ£€æŸ¥è®­ç»ƒæ•°æ®å¤§å°ä»¥è¿›è¡Œé‡‡æ ·...\n",
      "è®­ç»ƒæ•°æ®å¤§å° (51715) è¶…è¿‡é™åˆ¶ (5000)ã€‚æ­£åœ¨é‡‡æ ·...\n",
      "ä½¿ç”¨ 5000 ä¸ªé‡‡æ ·åºåˆ—è¿›è¡ŒåµŒå…¥ã€‚\n",
      "\n",
      "æ­£åœ¨åŠ è½½ESMæ¨¡å‹: esm2_t30_150M_UR50D åˆ°è®¾å¤‡ cuda...\n",
      "ESMæ¨¡å‹åœ¨ 8.33 ç§’å†…æˆåŠŸåŠ è½½ã€‚\n",
      "æ­£åœ¨ä¸º 5000 ä¸ªåºåˆ—ç”ŸæˆåµŒå…¥ï¼Œå…± 313 ä¸ªæ‰¹æ¬¡ï¼ˆæ‰¹æ¬¡å¤§å°: 16ï¼Œè®¾å¤‡: cudaï¼‰...\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 10/313... (è€—æ—¶: 10.54 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 20/313... (è€—æ—¶: 17.25 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 30/313... (è€—æ—¶: 23.79 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 40/313... (è€—æ—¶: 29.90 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 50/313... (è€—æ—¶: 36.21 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 60/313... (è€—æ—¶: 42.74 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 70/313... (è€—æ—¶: 49.45 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 80/313... (è€—æ—¶: 56.13 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 90/313... (è€—æ—¶: 62.88 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 100/313... (è€—æ—¶: 69.62 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 110/313... (è€—æ—¶: 76.36 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 120/313... (è€—æ—¶: 83.09 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 130/313... (è€—æ—¶: 89.87 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 140/313... (è€—æ—¶: 96.67 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 150/313... (è€—æ—¶: 103.48 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 160/313... (è€—æ—¶: 110.28 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 170/313... (è€—æ—¶: 117.07 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 180/313... (è€—æ—¶: 123.84 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 190/313... (è€—æ—¶: 130.64 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 200/313... (è€—æ—¶: 137.45 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 210/313... (è€—æ—¶: 144.25 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 220/313... (è€—æ—¶: 151.05 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 230/313... (è€—æ—¶: 157.85 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 240/313... (è€—æ—¶: 164.65 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 250/313... (è€—æ—¶: 171.47 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 260/313... (è€—æ—¶: 178.28 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 270/313... (è€—æ—¶: 185.10 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 280/313... (è€—æ—¶: 191.93 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 290/313... (è€—æ—¶: 198.74 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 300/313... (è€—æ—¶: 205.54 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 310/313... (è€—æ—¶: 212.33 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 313/313... (è€—æ—¶: 214.04 ç§’)\n",
      "åµŒå…¥ç”Ÿæˆåœ¨ 214.04 ç§’å†…å®Œæˆã€‚\n",
      "å¹³å‡æ¯ä¸ªåºåˆ—è€—æ—¶: 0.0428 ç§’\n",
      "ç”Ÿæˆçš„åµŒå…¥å¼ é‡å½¢çŠ¶: torch.Size([5000, 640])\n",
      "åµŒå…¥ä¸­æœªæ£€æµ‹åˆ°NaNå€¼ã€‚\n",
      "\n",
      "å‡†å¤‡å¥½çš„Xï¼ˆåµŒå…¥ï¼‰å½¢çŠ¶: (5000, 640), yï¼ˆäº®åº¦ï¼‰å½¢çŠ¶: (5000,)\n",
      "æ­¥éª¤3ï¼ˆåµŒå…¥ç”Ÿæˆï¼‰å®Œæˆã€‚\n",
      "\n",
      "æ­£åœ¨æ¸…ç†å†…å­˜...\n",
      "æ¸…ç©ºCUDAç¼“å­˜...\n",
      "æ¸…ç†å®Œæˆã€‚\n",
      "\n",
      "æ•°æ®å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚X shape: (5000, 640), y shape: (5000,)\n"
     ]
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_84",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:11:15.116611Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:14:57.546273Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_84",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import esm  # fair-esmåº“\n",
    "import os\n",
    "import time  # ç”¨äºè®¡æ—¶\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # å¿½ç•¥ä¸€äº›ä¸å½±å“ç»“æœçš„è­¦å‘Š\n",
    "\n",
    "# --- ä¼˜åŒ–å¸¸é‡ ---\n",
    "# æ ¹æ®è®¾å¤‡é€‰æ‹©åˆé€‚çš„ESMæ¨¡å‹\n",
    "ESM_MODEL_NAME_CPU = \"esm2_t6_8M_UR50D\"\n",
    "ESM_MODEL_NAME_GPU = \"esm2_t30_150M_UR50D\" # å¯ä»¥é€‰ç”¨æ›´å¤§çš„æ¨¡å‹ï¼Œä¾‹å¦‚ \"esm2_t33_650M_UR50D\"ï¼Œå–å†³äºGPUå†…å­˜\n",
    "\n",
    "# æ ¹æ®è®¾å¤‡é€‰æ‹©åˆé€‚çš„æ‰¹æ¬¡å¤§å°\n",
    "CPU_BATCH_SIZE = 8\n",
    "GPU_BATCH_SIZE = 16 # GPUé€šå¸¸å¯ä»¥å¤„ç†æ›´å¤§çš„æ‰¹æ¬¡ï¼Œå¯ä»¥æ ¹æ®GPUå†…å­˜è°ƒæ•´\n",
    "\n",
    "# ç”¨äºåµŒå…¥çš„æœ€å¤§è®­ç»ƒæ ·æœ¬æ•°ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰\n",
    "# å¦‚æœæ•°æ®é›†å°äºæ­¤å€¼ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰æ ·æœ¬\n",
    "MAX_TRAIN_SAMPLES_FOR_EMBEDDING = 5000\n",
    "SEED = 42 # ç¡®ä¿é‡‡æ ·å¯å¤ç°\n",
    "\n",
    "# --- 1. è®¾å¤‡æ£€æµ‹ ---\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    ESM_MODEL_NAME = ESM_MODEL_NAME_GPU\n",
    "    BATCH_SIZE = GPU_BATCH_SIZE\n",
    "    print(\"æ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨GPUè¿›è¡Œè®¡ç®—ã€‚\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    ESM_MODEL_NAME = ESM_MODEL_NAME_CPU\n",
    "    BATCH_SIZE = CPU_BATCH_SIZE\n",
    "    print(\"æœªæ£€æµ‹åˆ°CUDA GPUæˆ–CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œè®¡ç®—ã€‚\")\n",
    "\n",
    "print(f\"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {DEVICE}\")\n",
    "print(f\"å°†åŠ è½½çš„ESMæ¨¡å‹: {ESM_MODEL_NAME}\")\n",
    "print(f\"å°†ä½¿ç”¨çš„æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "# --- 3.0ï¼ˆä¼˜åŒ–ï¼‰å¿…è¦æ—¶å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œé‡‡æ · ---\n",
    "print(\"\\næ­£åœ¨æ£€æŸ¥è®­ç»ƒæ•°æ®å¤§å°ä»¥è¿›è¡Œé‡‡æ ·...\")\n",
    "# ç›´æ¥ä½¿ç”¨å·²åŠ è½½çš„ avGFP_train_df\n",
    "if len(avGFP_train_df) > MAX_TRAIN_SAMPLES_FOR_EMBEDDING:\n",
    "    print(f\"è®­ç»ƒæ•°æ®å¤§å° ({len(avGFP_train_df)}) è¶…è¿‡é™åˆ¶ ({MAX_TRAIN_SAMPLES_FOR_EMBEDDING})ã€‚æ­£åœ¨é‡‡æ ·...\")\n",
    "    # å¯¹DataFrameè¿›è¡Œé‡‡æ ·ä»¥å‡å°‘ç”¨äºåµŒå…¥çš„åºåˆ—æ•°é‡\n",
    "    sampled_train_df = avGFP_train_df.sample(n=MAX_TRAIN_SAMPLES_FOR_EMBEDDING, random_state=SEED)\n",
    "    print(f\"ä½¿ç”¨ {len(sampled_train_df)} ä¸ªé‡‡æ ·åºåˆ—è¿›è¡ŒåµŒå…¥ã€‚\")\n",
    "else:\n",
    "    print(f\"è®­ç»ƒæ•°æ®å¤§å° ({len(avGFP_train_df)}) åœ¨é™åˆ¶èŒƒå›´å†…ã€‚ä½¿ç”¨æ‰€æœ‰åºåˆ—ã€‚\")\n",
    "    # ä½¿ç”¨å®Œæ•´çš„DataFrame\n",
    "    sampled_train_df = avGFP_train_df.copy()  # ä½¿ç”¨å‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\n",
    "\n",
    "# --- 3.1 åŠ è½½é€‚åˆé€‰å®šè®¾å¤‡çš„ESMæ¨¡å‹ ---\n",
    "print(f\"\\næ­£åœ¨åŠ è½½ESMæ¨¡å‹: {ESM_MODEL_NAME} åˆ°è®¾å¤‡ {DEVICE}...\")\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # åŠ è½½æ¨¡å‹å’Œå­—æ¯è¡¨\n",
    "    esm_model, alphabet = esm.pretrained.load_model_and_alphabet(ESM_MODEL_NAME)\n",
    "    esm_model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    esm_model = esm_model.to(DEVICE)  # å°†æ¨¡å‹ç§»åŠ¨åˆ°é€‰å®šçš„è®¾å¤‡ (GPU or CPU)\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    print(f\"ESMæ¨¡å‹åœ¨ {time.time() - start_time:.2f} ç§’å†…æˆåŠŸåŠ è½½ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"åŠ è½½ESMæ¨¡å‹æ—¶å‡ºé”™: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿å·²å®‰è£… 'fair-esm' åº“ (pip install fair-esm) ä¸”æ¨¡å‹åç§°æ­£ç¡®ã€‚\")\n",
    "    print(\"å¯¹äºGPUä½¿ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä¸CUDAå…¼å®¹çš„PyTorchç‰ˆæœ¬ã€‚\")\n",
    "    exit()  # æ— æ³•åŠ è½½æ¨¡å‹åˆ™é€€å‡º\n",
    "\n",
    "# --- 3.2 å®šä¹‰åµŒå…¥å‡½æ•°ï¼ˆé€‚ç”¨äºCPUå’ŒGPUï¼‰ ---\n",
    "def get_esm_embeddings(sequences, model, alphabet, batch_converter, device, batch_size):\n",
    "    \"\"\"\n",
    "    åœ¨æŒ‡å®šè®¾å¤‡(CPUæˆ–GPU)ä¸Šç”ŸæˆESMåµŒå…¥ï¼ˆå¹³å‡æ± åŒ–ï¼‰ã€‚\n",
    "    å°†è¾“å…¥æ•°æ®å’Œæ¨¡å‹éƒ½ç§»åŠ¨åˆ° `device`ã€‚\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    num_sequences = len(sequences)\n",
    "    num_batches = (num_sequences + batch_size - 1) // batch_size\n",
    "    model.eval() # ç¡®ä¿æ¨¡å‹åœ¨è¯„ä¼°æ¨¡å¼\n",
    "    model = model.to(device) # ç¡®ä¿æ¨¡å‹åœ¨ç›®æ ‡è®¾å¤‡\n",
    "\n",
    "    print(f\"æ­£åœ¨ä¸º {num_sequences} ä¸ªåºåˆ—ç”ŸæˆåµŒå…¥ï¼Œå…± {num_batches} ä¸ªæ‰¹æ¬¡ï¼ˆæ‰¹æ¬¡å¤§å°: {batch_size}ï¼Œè®¾å¤‡: {device}ï¼‰...\")\n",
    "    start_time_embed = time.time()\n",
    "\n",
    "    with torch.no_grad():  # å¯¹æ¨ç†é€Ÿåº¦å’Œå†…å­˜è‡³å…³é‡è¦\n",
    "        for i in range(0, num_sequences, batch_size):\n",
    "            batch_seqs = sequences[i:i + batch_size]\n",
    "            batch_labels = [f\"seq_{j + i}\" for j in range(len(batch_seqs))]  # æ¯ä¸ªæ‰¹æ¬¡é¡¹çš„å”¯ä¸€æ ‡ç­¾\n",
    "            data = list(zip(batch_labels, batch_seqs))\n",
    "\n",
    "            try:\n",
    "                # 1. å‡†å¤‡æ‰¹æ¬¡\n",
    "                _, _, batch_tokens = batch_converter(data)\n",
    "                # å°†ä»¤ç‰Œç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡ (GPU or CPU)\n",
    "                batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "                # 2. è·å–è¡¨ç¤ºï¼ˆåªéœ€è¦æœ€åä¸€å±‚ï¼‰\n",
    "                # results = model(batch_tokens, repr_layers=[model.num_layers], return_contacts=False) # æ—§ç‰ˆå†™æ³•\n",
    "                # é€‚é…æ–°ç‰ˆ fair-esm (>=2.0.0)\n",
    "                results = model(batch_tokens, repr_layers=[model.num_layers])\n",
    "                token_representations = results[\"representations\"][model.num_layers]\n",
    "\n",
    "                # 3. å¯¹åºåˆ—é•¿åº¦è¿›è¡Œå¹³å‡æ± åŒ–ï¼ˆå¿½ç•¥CLS/EOS/PADä»¤ç‰Œï¼‰\n",
    "                # token_representationså½¢çŠ¶: [batch_size, seq_len+2, embed_dim]\n",
    "                seq_repr_list = []\n",
    "                for j, seq in enumerate(batch_seqs):\n",
    "                    # +1 æ˜¯å› ä¸º batch_converter æ·»åŠ äº† <cls> token\n",
    "                    actual_len = len(seq)\n",
    "                    # ä»ç´¢å¼• 1 å¼€å§‹åˆ° actual_len ç»“æŸ (ä¸åŒ…æ‹¬ <eos> å’Œ padding)\n",
    "                    # æ³¨æ„ï¼šéœ€è¦ç¡®ä¿batch_converteræ²¡æœ‰æ·»åŠ å…¶ä»–çš„ç‰¹æ®Štokenå½±å“é•¿åº¦è®¡ç®—\n",
    "                    # å¯¹äºæ ‡å‡†esmæ¨¡å‹ï¼Œé€šå¸¸æ˜¯<cls>...seq...<eos><pad>...\n",
    "                    # æ‰€ä»¥ token_representations[j, 1 : actual_len + 1, :] æ˜¯æ­£ç¡®çš„\n",
    "                    seq_tokens_repr = token_representations[j, 1 : actual_len + 1, :]\n",
    "                    seq_repr = seq_tokens_repr.mean(dim=0) # å¯¹å®é™…åºåˆ—é•¿åº¦çš„è¡¨ç¤ºè¿›è¡Œå¹³å‡\n",
    "                    seq_repr_list.append(seq_repr)\n",
    "\n",
    "                batch_seq_repr = torch.stack(seq_repr_list, dim=0) # [batch_size, embed_dim]\n",
    "\n",
    "                # 4. å­˜å‚¨ç»“æœ (ç§»å›CPUä»¥èšåˆå’Œåç»­å¤„ç†ï¼Œå¦‚è½¬Numpy)\n",
    "                embeddings.append(batch_seq_repr.cpu())\n",
    "\n",
    "                if (i // batch_size + 1) % 10 == 0 or (i // batch_size + 1) == num_batches:  # æ¯10ä¸ªæ‰¹æ¬¡æˆ–æœ€åä¸€ä¸ªæ‰¹æ¬¡æ‰“å°è¿›åº¦\n",
    "                    elapsed_time = time.time() - start_time_embed\n",
    "                    print(f\"  å·²å¤„ç†æ‰¹æ¬¡ {i // batch_size + 1}/{num_batches}... (è€—æ—¶: {elapsed_time:.2f} ç§’)\")\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" in str(e) and device == torch.device(\"cuda\"):\n",
    "                    print(f\"\\nå¤„ç†æ‰¹æ¬¡ {i // batch_size + 1} æ—¶å‘ç”ŸCUDAå†…å­˜ä¸è¶³é”™è¯¯: {e}\")\n",
    "                    print(f\"å½“å‰æ‰¹æ¬¡å¤§å°: {batch_size}ã€‚å°è¯•å‡å°æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹ã€‚\")\n",
    "                    # è®°å½•é”™è¯¯å¹¶è·³è¿‡ï¼Œä½†ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±\n",
    "                    embed_dim = model.embed_dim\n",
    "                    error_placeholder = torch.full((len(batch_seqs), embed_dim), float('nan'), device='cpu') # å­˜æ”¾åœ¨CPU\n",
    "                    embeddings.append(error_placeholder)\n",
    "                    torch.cuda.empty_cache() # å°è¯•é‡Šæ”¾ä¸€äº›å†…å­˜\n",
    "                else:\n",
    "                    print(f\"å¤„ç†æ‰¹æ¬¡ {i // batch_size + 1} æ—¶å‘ç”Ÿè¿è¡Œæ—¶é”™è¯¯: {e}\")\n",
    "                    embed_dim = model.embed_dim\n",
    "                    error_placeholder = torch.full((len(batch_seqs), embed_dim), float('nan'), device='cpu')\n",
    "                    embeddings.append(error_placeholder)\n",
    "            except Exception as e:\n",
    "                print(f\"å¤„ç†æ‰¹æ¬¡ {i // batch_size + 1} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "                # å¤„ç†é”™è¯¯ï¼Œä¾‹å¦‚è·³è¿‡æ‰¹æ¬¡æˆ–ç”¨NaNå¡«å……\n",
    "                embed_dim = model.embed_dim  # è·å–é¢„æœŸç»´åº¦\n",
    "                error_placeholder = torch.full((len(batch_seqs), embed_dim), float('nan'), device='cpu')\n",
    "                embeddings.append(error_placeholder)\n",
    "\n",
    "\n",
    "    total_embed_time = time.time() - start_time_embed\n",
    "    print(f\"åµŒå…¥ç”Ÿæˆåœ¨ {total_embed_time:.2f} ç§’å†…å®Œæˆã€‚\")\n",
    "    if num_sequences > 0:\n",
    "      print(f\"å¹³å‡æ¯ä¸ªåºåˆ—è€—æ—¶: {total_embed_time / num_sequences:.4f} ç§’\")\n",
    "\n",
    "\n",
    "    if not embeddings:\n",
    "        return torch.tensor([])  # è¿”å›ç©ºå¼ é‡\n",
    "\n",
    "    # è¿æ¥æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ\n",
    "    try:\n",
    "        full_embeddings = torch.cat(embeddings, dim=0)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"è¿æ¥åµŒå…¥æ‰¹æ¬¡æ—¶å‡ºé”™: {e}\")\n",
    "        print(\"è¿™å¯èƒ½å‘ç”Ÿåœ¨æ‰¹æ¬¡å¤„ç†å‡ºé”™å¯¼è‡´ç»´åº¦ä¸åŒ¹é…æ—¶ã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯ã€‚\")\n",
    "        # å°è¯•æ‰¾å‡ºæœ‰æ•ˆæ‰¹æ¬¡å¹¶è¿æ¥ï¼Œæˆ–è€…è¿”å›é”™è¯¯\n",
    "        try:\n",
    "            embed_dim = model.embed_dim # è·å–æ¨¡å‹ç»´åº¦\n",
    "            valid_embeddings = [emb for emb in embeddings if isinstance(emb, torch.Tensor) and emb.ndim == 2 and emb.shape[1] == embed_dim and not torch.isnan(emb).all()]\n",
    "            if valid_embeddings:\n",
    "                print(\"å°è¯•ä»…è¿æ¥æœ‰æ•ˆçš„åµŒå…¥æ‰¹æ¬¡...\")\n",
    "                full_embeddings = torch.cat(valid_embeddings, dim=0)\n",
    "            else:\n",
    "                print(\"æ²¡æœ‰æœ‰æ•ˆçš„åµŒå…¥æ‰¹æ¬¡å¯ä»¥è¿æ¥ã€‚\")\n",
    "                return torch.tensor([]) # è¿”å›ç©ºå¼ é‡\n",
    "        except Exception as concat_err:\n",
    "             print(f\"å°è¯•è¿æ¥æœ‰æ•ˆåµŒå…¥æ—¶å†æ¬¡å‡ºé”™: {concat_err}\")\n",
    "             return torch.tensor([]) # è¿”å›ç©ºå¼ é‡\n",
    "\n",
    "\n",
    "    return full_embeddings  # ä½œä¸ºå•ä¸ªå¼ é‡è¿”å› (åœ¨ CPU ä¸Š)\n",
    "\n",
    "# --- 3.3 ä¸ºï¼ˆå¯èƒ½é‡‡æ ·çš„ï¼‰è®­ç»ƒæ•°æ®ç”ŸæˆåµŒå…¥ ---\n",
    "train_sequences_to_embed = sampled_train_df['full_sequence'].tolist()\n",
    "\n",
    "X = None # åˆå§‹åŒ– X\n",
    "y = None # åˆå§‹åŒ– y\n",
    "\n",
    "if train_sequences_to_embed:\n",
    "    # è·å–åµŒå…¥ä½œä¸ºPyTorchå¼ é‡\n",
    "    train_embeddings_tensor = get_esm_embeddings(\n",
    "        train_sequences_to_embed,\n",
    "        esm_model,\n",
    "        alphabet,\n",
    "        batch_converter,\n",
    "        DEVICE,            # ä¼ é€’æ£€æµ‹åˆ°çš„è®¾å¤‡\n",
    "        batch_size=BATCH_SIZE # ä¼ é€’é€‚åˆè®¾å¤‡çš„æ‰¹æ¬¡å¤§å°\n",
    "    )\n",
    "\n",
    "    if train_embeddings_tensor.numel() > 0: # æ£€æŸ¥å¼ é‡æ˜¯å¦ä¸ºç©º\n",
    "        print(f\"ç”Ÿæˆçš„åµŒå…¥å¼ é‡å½¢çŠ¶: {train_embeddings_tensor.shape}\")\n",
    "\n",
    "        # å°†å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¸scikit-learnå…¼å®¹\n",
    "        # å› ä¸ºä¸Šé¢ append æ—¶å·²ç» .cpu()ï¼Œæ‰€ä»¥è¿™é‡Œ tensor å·²ç»åœ¨ CPU ä¸Š\n",
    "        train_embeddings_np = train_embeddings_tensor.numpy()\n",
    "\n",
    "        # --- å¤„ç†åµŒå…¥è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„NaNå€¼ ---\n",
    "        nan_rows_mask = np.isnan(train_embeddings_np).any(axis=1)\n",
    "        if np.any(nan_rows_mask):\n",
    "            num_nan_rows = nan_rows_mask.sum()\n",
    "            print(f\"è­¦å‘Š: åœ¨åµŒå…¥ä¸­å‘ç° {num_nan_rows} è¡ŒNaNå€¼ï¼ˆå¯èƒ½æ˜¯ç”±äºé”™è¯¯ï¼‰ã€‚æ­£åœ¨ç§»é™¤è¿™äº›è¡ŒåŠå…¶å¯¹åº”çš„åŸå§‹æ•°æ®ã€‚\")\n",
    "\n",
    "            # è¿‡æ»¤åµŒå…¥æ•°ç»„å’Œç›¸åº”çš„DataFrameè¡Œ\n",
    "            valid_indices_bool = ~nan_rows_mask\n",
    "            # è·å–åŸå§‹sampled_train_dfä¸­å¯¹åº”valid_indices_boolä¸ºTrueçš„ç´¢å¼•\n",
    "            original_indices = sampled_train_df.index[valid_indices_bool]\n",
    "\n",
    "            train_embeddings_np = train_embeddings_np[valid_indices_bool]\n",
    "            # ä½¿ç”¨ .loc å’ŒåŸå§‹ç´¢å¼•è¿›è¡Œè¿‡æ»¤ï¼Œç¡®ä¿æ­£ç¡®å¯¹é½\n",
    "            sampled_train_df_filtered = sampled_train_df.loc[original_indices]\n",
    "\n",
    "            print(f\"è¿‡æ»¤åçš„åµŒå…¥æ•°æ®å¤§å°: {train_embeddings_np.shape[0]}\")\n",
    "            print(f\"è¿‡æ»¤åçš„DataFrameå¤§å°: {len(sampled_train_df_filtered)}\")\n",
    "\n",
    "\n",
    "            # æ£€æŸ¥è¿‡æ»¤åæ˜¯å¦è¿˜æœ‰æ•°æ®\n",
    "            if train_embeddings_np.shape[0] == 0:\n",
    "                 print(\"\\né”™è¯¯: ç§»é™¤NaNå€¼åæ²¡æœ‰å‰©ä½™æ•°æ®ã€‚æ— æ³•ç»§ç»­ã€‚\")\n",
    "                 X, y = None, None\n",
    "            else:\n",
    "                 # --- ä¸ºæ¨¡å‹è®­ç»ƒå‡†å¤‡æœ€ç»ˆçš„Xå’Œy ---\n",
    "                 if train_embeddings_np.shape[0] == len(sampled_train_df_filtered):\n",
    "                     X = train_embeddings_np\n",
    "                     y = sampled_train_df_filtered['Brightness'].values\n",
    "                     print(f\"\\nå‡†å¤‡å¥½çš„Xï¼ˆåµŒå…¥ï¼‰å½¢çŠ¶: {X.shape}, yï¼ˆäº®åº¦ï¼‰å½¢çŠ¶: {y.shape}\")\n",
    "                     print(\"æ­¥éª¤3ï¼ˆåµŒå…¥ç”Ÿæˆï¼‰å®Œæˆã€‚\")\n",
    "                 else:\n",
    "                     # è¿™ä¸ªæƒ…å†µç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œå› ä¸ºæˆ‘ä»¬åŒæ—¶è¿‡æ»¤äº†ä¸¤è€…\n",
    "                     print(f\"\\né”™è¯¯: NaNè¿‡æ»¤åæœ€ç»ˆåµŒå…¥ ({train_embeddings_np.shape[0]}) å’ŒDataFrameè¡Œ ({len(sampled_train_df_filtered)}) æ•°é‡ä¸åŒ¹é…ã€‚\")\n",
    "                     print(\"æ— æ³•è¿›è¡Œè®­ç»ƒã€‚è¯·æ£€æŸ¥è¿‡æ»¤é€»è¾‘ã€‚\")\n",
    "                     X, y = None, None\n",
    "\n",
    "        else:\n",
    "             # æ²¡æœ‰NaNå€¼ï¼Œç›´æ¥ä½¿ç”¨\n",
    "             print(\"åµŒå…¥ä¸­æœªæ£€æµ‹åˆ°NaNå€¼ã€‚\")\n",
    "             X = train_embeddings_np\n",
    "             # ç›´æ¥ä» sampled_train_df è·å– yï¼Œå› ä¸ºæ²¡æœ‰è¿‡æ»¤\n",
    "             y = sampled_train_df['Brightness'].values\n",
    "             print(f\"\\nå‡†å¤‡å¥½çš„Xï¼ˆåµŒå…¥ï¼‰å½¢çŠ¶: {X.shape}, yï¼ˆäº®åº¦ï¼‰å½¢çŠ¶: {y.shape}\")\n",
    "             print(\"æ­¥éª¤3ï¼ˆåµŒå…¥ç”Ÿæˆï¼‰å®Œæˆã€‚\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nåµŒå…¥è¿‡ç¨‹æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åµŒå…¥å¼ é‡ï¼ˆå¯èƒ½æ‰€æœ‰æ‰¹æ¬¡éƒ½å‡ºé”™æˆ–è¾“å…¥ä¸ºç©ºï¼‰ã€‚\")\n",
    "        X, y = None, None\n",
    "\n",
    "else:\n",
    "    print(\"\\né‡‡æ ·/é¢„å¤„ç†åæ²¡æœ‰å¯ç”¨çš„åºåˆ—è¿›è¡ŒåµŒå…¥ã€‚\")\n",
    "    X, y = None, None\n",
    "\n",
    "# --- æ¸…ç†ï¼ˆå¯é€‰ï¼Œæœ‰åŠ©äºé‡Šæ”¾å†…å­˜ï¼Œç‰¹åˆ«æ˜¯GPUå†…å­˜ï¼‰ ---\n",
    "print(\"\\næ­£åœ¨æ¸…ç†å†…å­˜...\")\n",
    "del esm_model, alphabet, batch_converter\n",
    "# åˆ é™¤å¯èƒ½å·²åˆ›å»ºçš„å¼ é‡å’Œnumpyæ•°ç»„\n",
    "if 'train_embeddings_tensor' in locals() and isinstance(train_embeddings_tensor, torch.Tensor):\n",
    "    del train_embeddings_tensor\n",
    "if 'train_embeddings_np' in locals():\n",
    "    del train_embeddings_np\n",
    "# åˆ é™¤é‡‡æ ·æˆ–è¿‡æ»¤åçš„DataFrameå‰¯æœ¬\n",
    "if 'sampled_train_df' in locals():\n",
    "    del sampled_train_df\n",
    "if 'sampled_train_df_filtered' in locals():\n",
    "     del sampled_train_df_filtered\n",
    "\n",
    "# å¦‚æœä½¿ç”¨äº†GPUï¼Œæ˜¾å¼æ¸…ç©ºç¼“å­˜\n",
    "if DEVICE == torch.device(\"cuda\"):\n",
    "    print(\"æ¸…ç©ºCUDAç¼“å­˜...\")\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"æ¸…ç†å®Œæˆã€‚\")\n",
    "\n",
    "# --- ç°åœ¨Xå’Œyï¼ˆå¦‚æœæˆåŠŸåˆ›å»ºï¼‰å·²å‡†å¤‡å¥½ç”¨äºæ­¥éª¤4ï¼ˆæ¨¡å‹è®­ç»ƒï¼‰ ---\n",
    "if X is not None and y is not None:\n",
    "     print(f\"\\næ•°æ®å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚X shape: {X.shape}, y shape: {y.shape}\")\n",
    "     # è¿™é‡Œå¯ä»¥æ¥ä¸Šä½ çš„æ¨¡å‹è®­ç»ƒä»£ç ï¼Œä¾‹å¦‚ï¼š\n",
    "     # from sklearn.model_selection import train_test_split\n",
    "     # from sklearn.ensemble import RandomForestRegressor\n",
    "     # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "     # model = RandomForestRegressor(n_estimators=100, random_state=SEED)\n",
    "     # model.fit(X_train, y_train)\n",
    "     # print(\"æ¨¡å‹è®­ç»ƒå®Œæˆã€‚\")\n",
    "     # score = model.score(X_test, y_test)\n",
    "     # print(f\"æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„ R^2 åˆ†æ•°: {score:.4f}\")\n",
    "else:\n",
    "     print(\"\\næ•°æ®å‡†å¤‡å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„æ—¥å¿—è¾“å‡ºã€‚\")\n",
    "\n",
    "# ç¤ºä¾‹: å¦‚æœXä¸ä¸ºNoneï¼Œåˆ™æ‰“å°(X.shape, y.shape)ï¼Œå¦åˆ™æ‰“å°(\"X is None\")\n",
    "# print(\"\\n--- æœ€ç»ˆæ£€æŸ¥ ---\")\n",
    "# print((X.shape, y.shape) if X is not None else \"X is None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083f863-80c4-40a2-9a17-1f4c56bbf545",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ“ **ç¬¬å››æ­¥ï¼šè®­ç»ƒæˆ‘ä»¬çš„äº®åº¦é¢„æµ‹å™¨ï¼(æ¨¡å‹è®­ç»ƒ - éšæœºæ£®æ—)**\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†è›‹ç™½è´¨çš„â€œæ•°å­—æŒ‡çº¹â€ï¼ˆXï¼Œæ¥è‡ª ESM åµŒå…¥ï¼‰å’Œå®ƒä»¬å¯¹åº”çš„å·²çŸ¥â€œäº®åº¦åˆ†æ•°â€ï¼ˆyï¼‰ã€‚æ˜¯æ—¶å€™è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œè®©å®ƒå­¦ä¼šæ ¹æ®æŒ‡çº¹é¢„æµ‹äº®åº¦äº†ï¼\n",
    "\n",
    "1.  **åˆ†ç­è€ƒè¯• ğŸ“:** æˆ‘ä»¬ä¼šæŠŠæ•°æ®åˆ†æˆä¸¤éƒ¨åˆ†ï¼šå¤§éƒ¨åˆ†ï¼ˆè®­ç»ƒé›†ï¼‰ç”¨æ¥â€œæ•™â€æ¨¡å‹å­¦ä¹ è§„å¾‹ï¼Œä¸€å°éƒ¨åˆ†ï¼ˆéªŒè¯é›†ï¼‰ç”¨æ¥â€œæµ‹è¯•â€æ¨¡å‹å­¦å¾—æ€ä¹ˆæ ·ï¼Œé˜²æ­¢å®ƒâ€œæ­»è®°ç¡¬èƒŒâ€ã€‚\n",
    "2.  **è¯·â€œéšæœºæ£®æ—â€è€å¸ˆ ğŸŒ³ğŸŒ³ğŸŒ³:** æˆ‘ä»¬é€‰æ‹©â€œéšæœºæ£®æ—â€ (Random Forest) ä½œä¸ºæˆ‘ä»¬çš„é¢„æµ‹æ¨¡å‹ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆå¾ˆå¤šæ£µå†³ç­–æ ‘ç»„æˆçš„â€œæ™ºå›Šå›¢â€ï¼Œå®ƒä»¬å„è‡ªå­¦ä¹ ï¼Œç„¶åæŠ•ç¥¨å†³å®šæœ€ç»ˆçš„é¢„æµ‹ç»“æœã€‚è¿™ç§æ–¹æ³•é€šå¸¸å¾ˆç¨³å¥ï¼Œæ•ˆæœä¹Ÿä¸é”™ã€‚\n",
    "3.  **å¼€å§‹å­¦ä¹  ğŸ§‘â€ğŸ’»:** ç”¨è®­ç»ƒé›†çš„æ•°æ®ï¼Œâ€œå–‚â€ç»™éšæœºæ£®æ—æ¨¡å‹ï¼Œè®©å®ƒåŠªåŠ›å­¦ä¹ ä» ESM æŒ‡çº¹åˆ°äº®åº¦å€¼çš„æ˜ å°„å…³ç³»ã€‚\n",
    "4.  **æ¨¡æ‹Ÿæµ‹éªŒ âœ…:** è®­ç»ƒå®Œæˆåï¼Œç”¨æˆ‘ä»¬ä¹‹å‰ç•™å‡ºçš„éªŒè¯é›†æ¥è€ƒè€ƒæ¨¡å‹ï¼Œçœ‹çœ‹å®ƒçš„é¢„æµ‹å‡†ç¡®åº¦ï¼ˆæ¯”å¦‚ç”¨ RÂ² åˆ†æ•°è¯„ä¼°ï¼‰æ€ä¹ˆæ ·ã€‚è¿™èƒ½å¸®æˆ‘ä»¬äº†è§£è¿™ä¸ªâ€œäº®åº¦é¢„æµ‹å™¨â€é ä¸é è°±ã€‚\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†ä¸€ä¸ªå¯ä»¥é¢„æµ‹æœªçŸ¥åºåˆ—äº®åº¦çš„æ¨¡å‹å•¦ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7870f396-3653-413c-b418-2ff0b5fbd616",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_88",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:14:57.726075Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_88",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "Split data into training (4000) and validation (1000) sets.\n",
      "\n",
      "Training Random Forest Regressor...\n",
      "Random Forest training complete.\n",
      "\n",
      "Model Performance on Validation Set:\n",
      "  R-squared (RÂ²): 0.2793\n"
     ]
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_90",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:14:57.548572Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:16:01.711135Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_90",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "# --- 4.1 åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›† ---\n",
    "# å¦‚æœæ•°æ®é‡è¾ƒå°‘ï¼Œå¯ä»¥è€ƒè™‘äº¤å‰éªŒè¯ï¼Œè¿™é‡Œç”¨ç®€å•çš„åˆ’åˆ†\n",
    "if len(X) > 10: # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®åˆ’åˆ†\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "    print(f\"Split data into training ({len(X_train)}) and validation ({len(X_val)}) sets.\")\n",
    "else:\n",
    "    print(\"Dataset too small for validation split, using all data for training.\")\n",
    "    X_train, y_train = X, y\n",
    "    X_val, y_val = None, None # æ²¡æœ‰éªŒè¯é›†\n",
    "\n",
    "# --- 4.2 åˆå§‹åŒ–å¹¶è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ ---\n",
    "print(\"\\nTraining Random Forest Regressor...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100, # æ ‘çš„æ•°é‡ï¼Œå¯ä»¥è°ƒæ•´\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1, # ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ CPU æ ¸å¿ƒ\n",
    "    max_depth=20, # é™åˆ¶æ ‘çš„æ·±åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ (å¯è°ƒæ•´)\n",
    "    min_samples_leaf=3 # å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•° (å¯è°ƒæ•´)\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Random Forest training complete.\")\n",
    "\n",
    "# --- 4.3 (å¯é€‰) è¯„ä¼°æ¨¡å‹æ€§èƒ½ ---\n",
    "if X_val is not None:\n",
    "    y_pred_val = rf_model.predict(X_val)\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    print(f\"\\nModel Performance on Validation Set:\")\n",
    "    print(f\"  R-squared (RÂ²): {r2:.4f}\")\n",
    "    # RÂ² æ¥è¿‘ 1 è¡¨ç¤ºæ¨¡å‹æ‹Ÿåˆå¾—è¾ƒå¥½ï¼Œæ¥è¿‘ 0 æˆ–è´Ÿæ•°è¡¨ç¤ºæ‹Ÿåˆå¾ˆå·®\n",
    "else:\n",
    "    # å¯ä»¥åœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼°ï¼Œä½†è¿™é€šå¸¸ä¼šè¿‡äºä¹è§‚\n",
    "    y_pred_train = rf_model.predict(X_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    print(\"\\nModel Performance on Training Set (may be optimistic):\")\n",
    "    print(f\"  R-squared (RÂ²): {r2_train:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14d7f9-5fc2-4bd4-97e1-77e1e254e844",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡ **ç¬¬äº”æ­¥ï¼šè®¾è®¡æ–°çš„æ½œåŠ›åºåˆ—ï¼(å€™é€‰åºåˆ—ç”Ÿæˆ - çŸ¥è¯†å¼•å¯¼)**\n",
    "\n",
    "æ¿€åŠ¨äººå¿ƒçš„åˆ›é€ ç¯èŠ‚æ¥äº†ï¼æˆ‘ä»¬è¦è®¾è®¡å…¨æ–°çš„ avGFP åºåˆ—ï¼Œç›®æ ‡æ˜¯æ‰¾åˆ°æ¯”åŸå§‹æ¨¡æ¿æ›´äº®çš„ï¼ä½†æˆ‘ä»¬ä¸ççŒœï¼Œè€Œæ˜¯é‡‡å–â€œçŸ¥è¯†å¼•å¯¼â€ç­–ç•¥ï¼š\n",
    "\n",
    "1.  **åˆ’å®šâ€œé‡ç‚¹åŒºåŸŸâ€ ğŸ¯:** è¿™ä¸€æ­¥éœ€è¦å¤§å®¶å‘æŒ¥èªæ˜æ‰æ™ºå•¦ï¼ä½ éœ€è¦å»æŸ¥é˜…æ–‡çŒ®ã€åˆ†ææˆ‘ä»¬æä¾›çš„æ•°æ®ï¼ˆå°¤å…¶æ˜¯ `beforetop10` é‡Œçš„é«˜åˆ†åºåˆ—ï¼‰ï¼Œç”šè‡³çœ‹çœ‹è›‹ç™½è´¨çš„ 3D ç»“æ„ (PDB æ–‡ä»¶)ï¼Œæ‰¾å‡ºé‚£äº›**æœ€æœ‰å¯èƒ½å½±å“äº®åº¦**çš„æ°¨åŸºé…¸ä½ç½®ã€‚æŠŠè¿™äº›ä½ç½®æ±‡æ€»èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªâ€œå€™é€‰ä½ç‚¹æ± â€ã€‚è¿™å°±åƒå¯»å®å‰å…ˆç ”ç©¶è—å®å›¾ï¼ğŸ—ºï¸\n",
    "2.  **ç»„åˆçªå˜ ğŸ§ª:** ç¨‹åºä¼šä»ä½ ç²¾å¿ƒæŒ‘é€‰çš„â€œå€™é€‰ä½ç‚¹æ± â€ä¸­ï¼Œéšæœºé€‰æ‹© 1 åˆ° 6 ä¸ªä¸åŒçš„ä½ç½®ã€‚\n",
    "3.  **å¼•å…¥å˜åŒ– âœ¨:** åœ¨é€‰ä¸­çš„è¿™å‡ ä¸ªä½ç½®ä¸Šï¼Œéšæœºåœ°å°†åŸæ¥çš„æ°¨åŸºé…¸æ›¿æ¢æˆå…¶ä»– 19 ç§æ°¨åŸºé…¸ä¸­çš„ä¸€ç§ã€‚\n",
    "4.  **å¤§é‡åˆ¶é€  ğŸ­:** é‡å¤æ­¥éª¤ 2 å’Œ 3 å¾ˆå¤šå¾ˆå¤šæ¬¡ï¼ˆæ¯”å¦‚å‡ åƒæ¬¡ï¼‰ï¼Œç”Ÿæˆå¤§é‡å…¨æ–°çš„ã€å¸¦æœ‰ 1-6 ä¸ªçªå˜çš„ avGFP å€™é€‰åºåˆ—ã€‚è¿™äº›åºåˆ—éƒ½æ˜¯åŸºäºä½ çš„â€œçŸ¥è¯†å¼•å¯¼â€äº§ç”Ÿçš„ï¼Œå¸Œæœ›èƒ½æ›´æœ‰æ½œåŠ›ï¼\n",
    "\n",
    "è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†ä¸€å¤§æ‰¹ç­‰å¾…è¯„ä¼°çš„æ–°è®¾è®¡ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dfc18d4-6665-4758-a8d6-a0b85d5b7f4e",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_175",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:29:58.750205Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_175",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "\n",
      "Using a candidate position pool of 25 sites (0-based index):\n",
      "\n",
      "Generating 500 candidate sequences...\n",
      "  Generated 50/500 unique candidates...\n",
      "  Generated 100/500 unique candidates...\n",
      "  Generated 150/500 unique candidates...\n",
      "  Generated 200/500 unique candidates...\n",
      "  Generated 250/500 unique candidates...\n",
      "  Generated 300/500 unique candidates...\n",
      "  Generated 350/500 unique candidates...\n",
      "  Generated 400/500 unique candidates...\n",
      "  Generated 450/500 unique candidates...\n",
      "  Generated 500/500 unique candidates...\n",
      "Generated a total of 500 unique candidate sequences.\n"
     ]
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_176",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:29:58.724813Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:29:58.751498Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_176",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "# --- 5.1 å®šä¹‰å€™é€‰ä½ç‚¹æ±  (ç¤ºä¾‹) ---\n",
    "# !!! å…³é”®æ­¥éª¤ï¼šè¿™ä¸ªåˆ—è¡¨åº”è¯¥åŸºäºæ‚¨çš„ç ”ç©¶ !!!\n",
    "# ç¤ºä¾‹ï¼šåŒ…å«ä¸€äº›æ–‡çŒ®ä¸­æåˆ°çš„ç¨³å®š/äº®åº¦ç›¸å…³ä½ç‚¹ï¼Œä»¥åŠé è¿‘å‘è‰²å›¢çš„ä½ç‚¹\n",
    "\n",
    "candidate_position_pool = [\n",
    "    # é è¿‘å‘è‰²å›¢ (at 65-67)\n",
    "    64, 68, 69, 70, 71, 72,\n",
    "    # æ–‡çŒ®ä¸­æåˆ°çš„ä¸ç¨³å®š/äº®åº¦ç›¸å…³çš„ (ç¤ºä¾‹)\n",
    "    10, 30, 64, # F64L æ˜¯ Superfolder GFP çš„å…³é”®çªå˜ä¹‹ä¸€\n",
    "    101, 105, 109,\n",
    "    145, 147, 153, # M153T ä¹Ÿæ˜¯ Superfolder GFP çªå˜\n",
    "    163, 167, # V163A ä¹Ÿæ˜¯ Superfolder GFP çªå˜\n",
    "    171, 187,\n",
    "    203, 205, 221, 231, 232, 235\n",
    "]\n",
    "# è½¬æ¢ä¸º 0-based index ç”¨äºä»£ç å¤„ç†\n",
    "candidate_position_pool_0based = [p - 1 for p in candidate_position_pool]\n",
    "print(f\"\\nUsing a candidate position pool of {len(candidate_position_pool)} sites (0-based index):\")\n",
    "# print(candidate_position_pool_0based)\n",
    "\n",
    "# --- 5.2 å®šä¹‰ç”Ÿæˆå€™é€‰åºåˆ—çš„å‡½æ•° ---\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY' # 20ç§æ ‡å‡†æ°¨åŸºé…¸\n",
    "\n",
    "def generate_single_candidate(wt_sequence, position_pool_0based, max_mutations):\n",
    "    \"\"\"ç”Ÿæˆä¸€ä¸ªéšæœºç»„åˆçªå˜çš„å€™é€‰åºåˆ—\"\"\"\n",
    "    num_mutations = random.randint(1, max_mutations)\n",
    "    # ä»æ± ä¸­éšæœºé€‰æ‹© num_mutations ä¸ªä¸åŒçš„ä½ç½®\n",
    "    positions_to_mutate = random.sample(position_pool_0based, num_mutations)\n",
    "\n",
    "    mutated_sequence = list(wt_sequence)\n",
    "    mutation_details = []\n",
    "\n",
    "    for pos in positions_to_mutate:\n",
    "        original_aa = wt_sequence[pos]\n",
    "        # éšæœºé€‰æ‹©ä¸€ä¸ªä¸åŒäºåŸå§‹æ°¨åŸºé…¸çš„æ–°æ°¨åŸºé…¸\n",
    "        possible_new_aas = [aa for aa in amino_acids if aa != original_aa]\n",
    "        new_aa = random.choice(possible_new_aas)\n",
    "        mutated_sequence[pos] = new_aa\n",
    "        mutation_details.append(f\"{original_aa}{pos+1}{new_aa}\") # è®°å½•çªå˜ (1-based)\n",
    "\n",
    "    return \"\".join(mutated_sequence), \":\".join(sorted(mutation_details, key=lambda x: int(re.search(r'\\d+', x).group()))) # æŒ‰ä½ç½®æ’åºçªå˜æè¿°\n",
    "\n",
    "# --- 5.3 ç”Ÿæˆå¤§é‡å€™é€‰åºåˆ— ---\n",
    "print(f\"\\nGenerating {N_CANDIDATES_TO_GENERATE} candidate sequences...\")\n",
    "candidate_sequences = {} # ä½¿ç”¨å­—å…¸å­˜å‚¨ {sequence: mutation_str} ä»¥ç¡®ä¿å”¯ä¸€æ€§\n",
    "generated_count = 0\n",
    "attempts = 0\n",
    "max_attempts = N_CANDIDATES_TO_GENERATE * 5 # è®¾ç½®å°è¯•ä¸Šé™ï¼Œé˜²æ­¢æ— é™å¾ªç¯\n",
    "\n",
    "while generated_count < N_CANDIDATES_TO_GENERATE and attempts < max_attempts:\n",
    "    attempts += 1\n",
    "    seq, mut_str = generate_single_candidate(avGFP_WT_sequence, candidate_position_pool_0based, MAX_MUTATIONS)\n",
    "    if seq not in candidate_sequences and seq != avGFP_WT_sequence: # ç¡®ä¿ä¸é‡å¤ä¸”ä¸æ˜¯é‡ç”Ÿå‹\n",
    "        candidate_sequences[seq] = mut_str\n",
    "        generated_count += 1\n",
    "        if generated_count % (N_CANDIDATES_TO_GENERATE // 10) == 0:\n",
    "            print(f\"  Generated {generated_count}/{N_CANDIDATES_TO_GENERATE} unique candidates...\")\n",
    "\n",
    "if generated_count < N_CANDIDATES_TO_GENERATE:\n",
    "    print(f\"Warning: Could only generate {generated_count} unique candidates after {attempts} attempts.\")\n",
    "\n",
    "candidate_list = list(candidate_sequences.keys())\n",
    "mutation_list = [candidate_sequences[seq] for seq in candidate_list]\n",
    "print(f\"Generated a total of {len(candidate_list)} unique candidate sequences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfcd0e-dd3a-4b0a-90a7-388c0c21d700",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ” **ç¬¬å…­æ­¥ï¼šé¢„æµ‹ã€ç­›é€‰ä¸æ·˜æ±°ï¼(é¢„æµ‹ä¸è¿‡æ»¤)**\n",
    "\n",
    "æˆ‘ä»¬åˆ›é€ äº†ä¸€å †æ–°åºåˆ—ï¼Œç°åœ¨è¦ç”¨ä¹‹å‰è®­ç»ƒå¥½çš„â€œäº®åº¦é¢„æµ‹å™¨â€æ¥ç»™å®ƒä»¬æ‰“åˆ†ï¼Œå¹¶è¿›è¡Œä¸¥æ ¼ç­›é€‰ï¼š\n",
    "\n",
    "1.  **å†æ¬¡â€œç¿»è¯‘â€ ğŸ—£ï¸:** å¯¹æ‰€æœ‰æ–°ç”Ÿæˆçš„å€™é€‰åºåˆ—ï¼Œå†æ¬¡ä½¿ç”¨**ç›¸åŒ**çš„ ESM æ¨¡å‹ï¼ˆé‚£ä¸ªè½»é‡çº§çš„ï¼‰æ¥è®¡ç®—å®ƒä»¬çš„â€œæ•°å­—æŒ‡çº¹â€ï¼ˆåµŒå…¥ï¼‰ã€‚\n",
    "2.  **é¢„æµ‹äº®åº¦ ğŸ”®:** æŠŠè¿™äº›æ–°åºåˆ—çš„æŒ‡çº¹è¾“å…¥åˆ°æˆ‘ä»¬è®­ç»ƒå¥½çš„éšæœºæ£®æ—æ¨¡å‹ä¸­ï¼Œè®©æ¨¡å‹é¢„æµ‹å‡ºæ¯ä¸€æ¡æ–°åºåˆ—çš„äº®åº¦å€¼ã€‚\n",
    "3.  **å¯¹ç…§â€œé»‘åå•â€ ğŸš«:** è¿™æ˜¯éå¸¸å…³é”®çš„ä¸€æ­¥ï¼æ‹¿å‡º `Exclusion_List.csv`ï¼Œæ£€æŸ¥æˆ‘ä»¬é¢„æµ‹å‡ºæ¥çš„é«˜åˆ†åºåˆ—ï¼Œ**ç»å¯¹ä¸èƒ½**å‡ºç°åœ¨è¿™ä¸ªåå•é‡Œï¼å¦‚æœåœ¨åå•ä¸Šï¼Œå³ä½¿é¢„æµ‹åˆ†æ•°å†é«˜ï¼Œä¹Ÿå¿…é¡»æ·˜æ±°æ‰ã€‚\n",
    "4.  **æ’åºé€‰ä¼˜ ğŸ†:** å°†æ‰€æœ‰é€šè¿‡â€œé»‘åå•â€æ£€æŸ¥çš„å€™é€‰åºåˆ—ï¼ŒæŒ‰ç…§é¢„æµ‹çš„äº®åº¦å€¼ä»é«˜åˆ°ä½æ’åºã€‚\n",
    "\n",
    "ç»è¿‡è¿™ä¸€è½®ï¼Œå‰©ä¸‹çš„å°±æ˜¯æˆ‘ä»¬è®¤ä¸ºæœ€æœ‰æ½œåŠ›ã€å¹¶ä¸”ç¬¦åˆæ¯”èµ›è§„åˆ™çš„å€™é€‰åºåˆ—äº†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cfd0120-45d3-4f8c-a402-339e9a5fbc86",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_180",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:30:06.462673Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_180",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "å°è¯•åŠ è½½ç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹: esm2_t30_150M_UR50D\n",
      "ç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹ 'esm2_t30_150M_UR50D' å·²åŠ è½½åˆ° cudaï¼Œè€—æ—¶ 2.48 ç§’ã€‚\n",
      "\n",
      "ä½¿ç”¨é¢„æµ‹æ¨¡å‹ä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ ESM åµŒå…¥...\n",
      "æ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ GPU æ‰¹æ¬¡å¤§å°: 8\n",
      "æ­£åœ¨ä¸º 500 ä¸ªåºåˆ—ç”ŸæˆåµŒå…¥ï¼Œå…± 63 ä¸ªæ‰¹æ¬¡ï¼ˆæ‰¹æ¬¡å¤§å°: 8ï¼Œè®¾å¤‡: cudaï¼‰...\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 10/63... (è€—æ—¶: 2.23 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 20/63... (è€—æ—¶: 4.39 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 30/63... (è€—æ—¶: 7.31 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 40/63... (è€—æ—¶: 11.05 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 50/63... (è€—æ—¶: 14.43 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 60/63... (è€—æ—¶: 17.84 ç§’)\n",
      "  å·²å¤„ç†æ‰¹æ¬¡ 63/63... (è€—æ—¶: 18.71 ç§’)\n",
      "åµŒå…¥ç”Ÿæˆåœ¨ 18.71 ç§’å†…å®Œæˆã€‚\n",
      "å¹³å‡æ¯ä¸ªåºåˆ—è€—æ—¶: 0.0374 ç§’\n",
      "å€™é€‰åºåˆ—åµŒå…¥çš„å½¢çŠ¶: (500, 640)\n",
      "\n",
      "æ­£åœ¨ä¸ºå€™é€‰åºåˆ—é¢„æµ‹äº®åº¦...\n",
      "é¢„æµ‹å®Œæˆã€‚\n",
      "\n",
      "æ ¹æ®æ’é™¤åˆ—è¡¨ (739 ä¸ªåºåˆ—) è¿›è¡Œè¿‡æ»¤...\n",
      "ç§»é™¤äº† 1 ä¸ªåœ¨æ’é™¤åˆ—è¡¨ä¸­çš„åºåˆ—ã€‚\n",
      "\n",
      "é¢„æµ‹å‡ºçš„ Top 6 ä¸ªå€™é€‰åºåˆ— (å·²æ’é™¤):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence ID</th>\n",
       "      <th>Mutations</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>PredictedBrightness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Candidate_1</td>\n",
       "      <td>V163T</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>3.514671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Candidate_2</td>\n",
       "      <td>E235T</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>3.490361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Candidate_3</td>\n",
       "      <td>F71L</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>3.485293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Candidate_4</td>\n",
       "      <td>V163D</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>3.483591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Candidate_5</td>\n",
       "      <td>L221T</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>3.482050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Candidate_6</td>\n",
       "      <td>E235S</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>3.481949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sequence ID Mutations                                           Sequence  \\\n",
       "328  Candidate_1     V163T  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "496  Candidate_2     E235T  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "479  Candidate_3      F71L  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "412  Candidate_4     V163D  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "179  Candidate_5     L221T  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "82   Candidate_6     E235S  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "\n",
       "     PredictedBrightness  \n",
       "328             3.514671  \n",
       "496             3.490361  \n",
       "479             3.485293  \n",
       "412             3.483591  \n",
       "179             3.482050  \n",
       "82              3.481949  "
      ]
     },
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_189",
     "meta": {},
     "metadata": {},
     "output_type": "display_data",
     "parent_header": {
      "date": "2025-04-27T14:30:27.565040Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_189",
      "msg_type": "display_data",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_190",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:30:27.650211Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_190",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "\n",
      "æ¸…ç†é¢„æµ‹æ¨¡å‹å†…å­˜...\n",
      "æ¸…ç©ºCUDAç¼“å­˜...\n",
      "é¢„æµ‹æ¨¡å‹æ¸…ç†å®Œæˆã€‚\n"
     ]
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_191",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:30:06.241240Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:30:27.651551Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_191",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import esm # å‡è®¾ esm åº“å·²å¯¼å…¥\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# å‡è®¾ rf_model, candidate_list, mutation_list, exclusion_sequences,\n",
    "# TOP_N_SELECT, CPU_BATCH_SIZE, get_esm_embeddings (æ¥è‡ªä¸Šä¸€æ­¥) å·²ç»å®šä¹‰å¥½\n",
    "# å¹¶ä¸” avGFP_WT_sequence, candidate_position_pool_0based, MAX_MUTATIONS, N_CANDIDATES_TO_GENERATE ä¹Ÿå·²å®šä¹‰\n",
    "\n",
    "# --- ä¿®æ­£ï¼šå®šä¹‰ç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹åç§° ---\n",
    "# !!! å…³é”®ï¼šè¿™é‡Œå¿…é¡»ä½¿ç”¨ä¸è®­ç»ƒ rf_model æ—¶ç›¸åŒçš„ ESM æ¨¡å‹ !!!\n",
    "# æ ¹æ®ä¹‹å‰çš„æ—¥å¿—ï¼Œrf_model æ˜¯ç”¨ 640 ç»´åµŒå…¥è®­ç»ƒçš„ (æ¥è‡ª esm2_t30_150M_UR50D)\n",
    "PREDICTION_ESM_MODEL_NAME = \"esm2_t30_150M_UR50D\" # <--- ç¡®è®¤è¿™ä¸ªæ¨¡å‹ä¸è®­ç»ƒæ—¶ä¸€è‡´\n",
    "\n",
    "print(f\"å°è¯•åŠ è½½ç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹: {PREDICTION_ESM_MODEL_NAME}\")\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # åŠ è½½æŒ‡å®šç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹å’Œå­—æ¯è¡¨\n",
    "    esm_model_pred, alphabet_pred = esm.pretrained.load_model_and_alphabet(PREDICTION_ESM_MODEL_NAME)\n",
    "    batch_converter_pred = alphabet_pred.get_batch_converter()\n",
    "    # é‡æ–°ç¡®å®šè®¾å¤‡ (ä¼˜å…ˆä½¿ç”¨ GPU)\n",
    "    DEVICE_pred = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    esm_model_pred.to(DEVICE_pred)\n",
    "    esm_model_pred.eval() # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ (å…³é—­ dropout ç­‰)\n",
    "    print(f\"ç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹ '{PREDICTION_ESM_MODEL_NAME}' å·²åŠ è½½åˆ° {DEVICE_pred}ï¼Œè€—æ—¶ {time.time() - start_time:.2f} ç§’ã€‚\")\n",
    "except Exception as e:\n",
    "    print(f\"åŠ è½½ ESM æ¨¡å‹ {PREDICTION_ESM_MODEL_NAME} æ—¶å‡ºé”™: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿ 'fair-esm' å·²å®‰è£…ï¼Œæ¨¡å‹åç§°æ­£ç¡®ï¼Œå¹¶ä¸”æœ‰è¶³å¤Ÿçš„å†…å­˜ã€‚\")\n",
    "    # æ ¹æ®éœ€è¦å¤„ç†é”™è¯¯ï¼Œä¾‹å¦‚é€€å‡º\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 6.1 ä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ ESM åµŒå…¥ ---\n",
    "print(\"\\nä½¿ç”¨é¢„æµ‹æ¨¡å‹ä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ ESM åµŒå…¥...\")\n",
    "candidate_embeddings_np = np.array([]) # åˆå§‹åŒ–ä¸ºç©º numpy æ•°ç»„\n",
    "\n",
    "if candidate_list:\n",
    "    # ç¡®å®šæ‰¹æ¬¡å¤§å° (å¦‚æœä½¿ç”¨GPUï¼Œå¯ä»¥å°è¯•æ›´å¤§çš„æ‰¹æ¬¡)\n",
    "    prediction_batch_size = CPU_BATCH_SIZE # é»˜è®¤ä½¿ç”¨ CPU æ‰¹æ¬¡å¤§å° (æ¥è‡ªä¹‹å‰çš„å®šä¹‰)\n",
    "    if DEVICE_pred == torch.device(\"cuda\"):\n",
    "        # å¦‚æœæ˜¯GPUï¼Œå¯ä»¥å°è¯•æ›´å¤§çš„æ‰¹æ¬¡ï¼Œä¾‹å¦‚ 8, 16 æˆ– 32ï¼Œå–å†³äºGPUå†…å­˜å’Œæ¨¡å‹å¤§å°\n",
    "        # å¯¹äºè¾ƒå¤§çš„æ¨¡å‹å¦‚ 150Mï¼Œå¯èƒ½éœ€è¦è¾ƒå°çš„æ‰¹æ¬¡å¤§å°\n",
    "        prediction_batch_size = 8 # ç¤ºä¾‹å€¼ (æ ¹æ®ä½ çš„ GPU å†…å­˜è°ƒæ•´ï¼Œä¸è®­ç»ƒæ—¶ç”¨çš„GPU_BATCH_SIZEå¯ä»¥ä¸åŒ)\n",
    "        print(f\"æ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ GPU æ‰¹æ¬¡å¤§å°: {prediction_batch_size}\")\n",
    "    else:\n",
    "        print(f\"ä½¿ç”¨ CPU æ‰¹æ¬¡å¤§å°: {prediction_batch_size}\")\n",
    "\n",
    "    # *** ä¿®å¤ç‚¹ï¼šä½¿ç”¨æ­£ç¡®çš„å‡½æ•°å 'get_esm_embeddings' ***\n",
    "    # ä¼ é€’ç”¨äºé¢„æµ‹çš„æ¨¡å‹ã€å­—æ¯è¡¨ã€è½¬æ¢å™¨å’Œè®¾å¤‡\n",
    "    candidate_embeddings_tensor = get_esm_embeddings( # <-- ä½¿ç”¨æ­£ç¡®çš„å‡½æ•°å\n",
    "        candidate_list,\n",
    "        esm_model_pred,         # ä½¿ç”¨é¢„æµ‹æ¨¡å‹\n",
    "        alphabet_pred,        # ä½¿ç”¨é¢„æµ‹æ¨¡å‹çš„å­—æ¯è¡¨\n",
    "        batch_converter_pred, # ä½¿ç”¨é¢„æµ‹æ¨¡å‹çš„è½¬æ¢å™¨\n",
    "        DEVICE_pred,          # ä½¿ç”¨é¢„æµ‹æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡ (å¯èƒ½æ˜¯ cuda æˆ– cpu)\n",
    "        batch_size=prediction_batch_size # ä½¿ç”¨è°ƒæ•´åçš„æ‰¹æ¬¡å¤§å°\n",
    "    )\n",
    "\n",
    "    # å°†åµŒå…¥ç»“æœè½¬æ¢ä¸º NumPy æ•°ç»„ä»¥ç”¨äº scikit-learn æ¨¡å‹\n",
    "    # .cpu() ç¡®ä¿æ•°æ®åœ¨ CPU ä¸Šï¼Œç„¶åè½¬æ¢ä¸º numpy\n",
    "    candidate_embeddings_np = candidate_embeddings_tensor.cpu().numpy()\n",
    "\n",
    "    print(f\"å€™é€‰åºåˆ—åµŒå…¥çš„å½¢çŠ¶: {candidate_embeddings_np.shape}\") # æ£€æŸ¥ç»´åº¦æ˜¯å¦æ­£ç¡® (åº”ä¸º N x 640)\n",
    "\n",
    "    # æ£€æŸ¥æ˜¯å¦æœ‰ NaN (å¦‚æœåµŒå…¥è¿‡ç¨‹ä¸­å‡ºé”™)\n",
    "    if np.isnan(candidate_embeddings_np).any():\n",
    "        print(\"è­¦å‘Šï¼šåœ¨å€™é€‰åºåˆ—åµŒå…¥ä¸­å‘ç° NaN å€¼ã€‚å°†ç§»é™¤ç›¸åº”çš„å€™é€‰åºåˆ—ã€‚\")\n",
    "        nan_mask = np.isnan(candidate_embeddings_np).any(axis=1)\n",
    "        # éœ€è¦åŒæ—¶è¿‡æ»¤ candidate_list, mutation_list å’Œ embeddings\n",
    "        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼è¿›è¡Œè¿‡æ»¤\n",
    "        original_count = len(candidate_list)\n",
    "        candidate_list = [seq for i, seq in enumerate(candidate_list) if not nan_mask[i]]\n",
    "        mutation_list = [mut for i, mut in enumerate(mutation_list) if not nan_mask[i]]\n",
    "        candidate_embeddings_np = candidate_embeddings_np[~nan_mask]\n",
    "        print(f\"å›  NaN åµŒå…¥ç§»é™¤äº† {original_count - len(candidate_list)} ä¸ªå€™é€‰åºåˆ—ã€‚\")\n",
    "        print(f\"å‰©ä½™å€™é€‰åºåˆ—æ•°é‡: {len(candidate_list)}\")\n",
    "        print(f\"è¿‡æ»¤åçš„å€™é€‰åºåˆ—åµŒå…¥å½¢çŠ¶: {candidate_embeddings_np.shape}\")\n",
    "\n",
    "else:\n",
    "    # candidate_embeddings_np å·²ç»åˆå§‹åŒ–ä¸ºç©ºæ•°ç»„\n",
    "    print(\"ä¸Šä¸€æ­¥æ²¡æœ‰ç”Ÿæˆå€™é€‰åºåˆ—ï¼Œè·³è¿‡é¢„æµ‹ã€‚\")\n",
    "\n",
    "\n",
    "# --- 6.2 é¢„æµ‹äº®åº¦ ---\n",
    "predicted_brightness = []\n",
    "# ç¡®ä¿æˆ‘ä»¬æœ‰æœ‰æ•ˆçš„åµŒå…¥å’Œå€™é€‰åˆ—è¡¨æ¥è¿›è¡Œé¢„æµ‹\n",
    "# å¹¶ä¸”åµŒå…¥çš„æ•°é‡ä¸å€™é€‰åˆ—è¡¨çš„æ•°é‡ä¸€è‡´\n",
    "if candidate_embeddings_np.shape[0] > 0 and len(candidate_list) == candidate_embeddings_np.shape[0]:\n",
    "    print(\"\\næ­£åœ¨ä¸ºå€™é€‰åºåˆ—é¢„æµ‹äº®åº¦...\")\n",
    "    try:\n",
    "        # ä½¿ç”¨åŠ è½½çš„éšæœºæ£®æ—æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "        predicted_brightness = rf_model.predict(candidate_embeddings_np)\n",
    "        print(\"é¢„æµ‹å®Œæˆã€‚\")\n",
    "    except ValueError as ve: # æ•è·æ›´å…·ä½“çš„ ValueError\n",
    "        print(f\"éšæœºæ£®æ—æ¨¡å‹é¢„æµ‹æœŸé—´å‡ºé”™: {ve}\")\n",
    "        print(\"è¯·ç¡®è®¤ç”¨äºé¢„æµ‹çš„ ESM æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾ç»´åº¦ä¸è®­ç»ƒ rf_model æ—¶ä½¿ç”¨çš„ç»´åº¦ä¸€è‡´ã€‚\")\n",
    "        # å¦‚æœé¢„æµ‹å¤±è´¥ï¼Œå°†ç»“æœåˆ—è¡¨æ¸…ç©ºï¼Œåç»­æ­¥éª¤ä¼šå¤„ç†ç©ºç»“æœ\n",
    "        predicted_brightness = []\n",
    "    except Exception as e:\n",
    "        print(f\"éšæœºæ£®æ—æ¨¡å‹é¢„æµ‹æœŸé—´å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "        predicted_brightness = []\n",
    "else:\n",
    "    if not candidate_list:\n",
    "         print(\"æ²¡æœ‰å¯ç”¨çš„å€™é€‰åºåˆ—è¿›è¡Œé¢„æµ‹ã€‚\")\n",
    "    elif candidate_embeddings_np.shape[0] == 0 and candidate_list:\n",
    "         print(\"ç”Ÿæˆäº†å€™é€‰åºåˆ—ï¼Œä½†æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åµŒå…¥å‘é‡è¿›è¡Œé¢„æµ‹ã€‚\")\n",
    "    elif len(candidate_list) != candidate_embeddings_np.shape[0]:\n",
    "         print(\"é”™è¯¯ï¼šç»è¿‡ NaN è¿‡æ»¤åï¼Œå€™é€‰åºåˆ—æ•°é‡ä¸åµŒå…¥å‘é‡æ•°é‡ä¸åŒ¹é…ã€‚\")\n",
    "\n",
    "\n",
    "# --- 6.3 ç»„åˆç»“æœå¹¶ç­›é€‰ ---\n",
    "final_candidates_formatted = pd.DataFrame() # åˆå§‹åŒ–ä¸ºç©º DataFrame\n",
    "\n",
    "# åªæœ‰åœ¨æˆåŠŸç”Ÿæˆé¢„æµ‹å¹¶ä¸”æ•°é‡ä¸å€™é€‰åˆ—è¡¨åŒ¹é…æ—¶æ‰ç»§ç»­\n",
    "if len(candidate_list) > 0 and len(predicted_brightness) > 0 and len(candidate_list) == len(predicted_brightness):\n",
    "    # åˆ›å»ºåŒ…å«åºåˆ—ã€çªå˜å’Œé¢„æµ‹å€¼çš„ DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Sequence': candidate_list,\n",
    "        'Mutations': mutation_list, # ç¡®ä¿ mutation_list ä¸ candidate_list ä¿æŒåŒæ­¥\n",
    "        'PredictedBrightness': predicted_brightness\n",
    "    })\n",
    "\n",
    "    # è¿‡æ»¤æ‰æ’é™¤åˆ—è¡¨ä¸­çš„åºåˆ—\n",
    "    print(f\"\\næ ¹æ®æ’é™¤åˆ—è¡¨ ({len(exclusion_sequences)} ä¸ªåºåˆ—) è¿›è¡Œè¿‡æ»¤...\")\n",
    "    initial_candidate_count = len(results_df)\n",
    "    # ç¡®ä¿æ¯”è¾ƒçš„æ˜¯å­—ç¬¦ä¸²ç±»å‹\n",
    "    results_df = results_df[~results_df['Sequence'].astype(str).isin(exclusion_sequences)]\n",
    "    removed_count = initial_candidate_count - len(results_df)\n",
    "    if removed_count > 0:\n",
    "        print(f\"ç§»é™¤äº† {removed_count} ä¸ªåœ¨æ’é™¤åˆ—è¡¨ä¸­çš„åºåˆ—ã€‚\")\n",
    "    else:\n",
    "        print(\"å€™é€‰åˆ—è¡¨ä¸­çš„åºåˆ—å‡ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ã€‚\")\n",
    "\n",
    "    # æŒ‰é¢„æµ‹äº®åº¦é™åºæ’åº\n",
    "    results_df = results_df.sort_values(by='PredictedBrightness', ascending=False)\n",
    "\n",
    "    # é€‰æ‹© Top N ä¸ªç»“æœ\n",
    "    final_candidates = results_df.head(TOP_N_SELECT).copy() # ä½¿ç”¨ .copy() é¿å… SettingWithCopyWarning\n",
    "\n",
    "    print(f\"\\né¢„æµ‹å‡ºçš„ Top {min(TOP_N_SELECT, len(final_candidates))} ä¸ªå€™é€‰åºåˆ— (å·²æ’é™¤):\") # æ˜¾ç¤ºå®é™…é€‰å‡ºçš„æ•°é‡\n",
    "\n",
    "    if not final_candidates.empty:\n",
    "        # ä¸ºäº†æ›´æ¸…æ™°åœ°å±•ç¤ºï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ª ID åˆ—\n",
    "        final_candidates.insert(0, 'Sequence ID', [f'Candidate_{i+1}' for i in range(len(final_candidates))])\n",
    "        # è°ƒæ•´åˆ—é¡ºåºä»¥ç¬¦åˆæäº¤æ ¼å¼è¦æ±‚\n",
    "        final_candidates_formatted = final_candidates[['Sequence ID', 'Mutations', 'Sequence', 'PredictedBrightness']]\n",
    "        # ä½¿ç”¨ display æˆ– print æ˜¾ç¤º DataFrame\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(final_candidates_formatted) # åœ¨ Jupyter ç¯å¢ƒä¸­å‹å¥½æ˜¾ç¤º\n",
    "        except ImportError:\n",
    "            print(final_candidates_formatted.to_string()) # åœ¨é IPython ç¯å¢ƒä¸­æ‰“å°å®Œæ•´ DataFrame\n",
    "    else:\n",
    "        print(\"ç»è¿‡è¿‡æ»¤å’Œç­›é€‰åï¼Œæ²¡æœ‰å‰©ä½™çš„å€™é€‰åºåˆ—ã€‚\")\n",
    "\n",
    "elif not candidate_list:\n",
    "     print(\"\\næ²¡æœ‰ç”Ÿæˆå€™é€‰åºåˆ—æˆ–å€™é€‰åºåˆ—åœ¨é¢„æµ‹å‰å·²è¢«è¿‡æ»¤æ‰ã€‚\")\n",
    "elif not predicted_brightness:\n",
    "     print(\"\\né¢„æµ‹æ­¥éª¤å¤±è´¥æˆ–æ²¡æœ‰äº§ç”Ÿç»“æœã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯ã€‚\")\n",
    "else: # candidate_list å’Œ predicted_brightness é•¿åº¦ä¸åŒ¹é…\n",
    "     print(\"\\né”™è¯¯ï¼šæœ€ç»ˆå€™é€‰åºåˆ—æ•°é‡ä¸é¢„æµ‹ç»“æœæ•°é‡ä¸åŒ¹é…ã€‚æ— æ³•ç»§ç»­å¤„ç†ã€‚\")\n",
    "\n",
    "# --- æ¸…ç†é¢„æµ‹æ¨¡å‹å ç”¨çš„å†…å­˜ ---\n",
    "print(\"\\næ¸…ç†é¢„æµ‹æ¨¡å‹å†…å­˜...\")\n",
    "del esm_model_pred, alphabet_pred, batch_converter_pred\n",
    "if 'candidate_embeddings_tensor' in locals():\n",
    "    del candidate_embeddings_tensor\n",
    "if 'candidate_embeddings_np' in locals():\n",
    "    del candidate_embeddings_np\n",
    "if DEVICE_pred == torch.device(\"cuda\"):\n",
    "    print(\"æ¸…ç©ºCUDAç¼“å­˜...\")\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"é¢„æµ‹æ¨¡å‹æ¸…ç†å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef106f37-c167-4796-87f9-ae024a2c06b1",
   "metadata": {},
   "source": [
    "---\n",
    "ğŸ“„ **ç¬¬ä¸ƒæ­¥ï¼šæˆæœå±•ç¤ºä¸æœªæ¥å±•æœ›ï¼(è¾“å‡ºä¸åç»­æ­¥éª¤)**\n",
    "\n",
    "å¤ªæ£’äº†ï¼æˆ‘ä»¬ç»ˆäºèµ°å®Œäº†æ•´ä¸ªæµç¨‹ï¼ğŸ‰\n",
    "\n",
    "1.  **æœ€ç»ˆåå• ğŸ…:** ä»ä¸Šä¸€è½®ç­›é€‰æ’åºåçš„ç»“æœä¸­ï¼Œé€‰å‡ºé¢„æµ‹äº®åº¦æœ€é«˜çš„ **Top 6** æ¡åºåˆ—ã€‚\n",
    "2.  **æ•´ç†æäº¤ âœï¸:** å°†è¿™ 6 æ¡åºåˆ—çš„ä¿¡æ¯ï¼ˆæ¯”å¦‚ç»™å®ƒä»¬èµ·ä¸ªåå­— `Sequence ID`ã€è®°å½•æ¸…æ¥šå…·ä½“çš„çªå˜ `Mutations`ã€ä»¥åŠå®Œæ•´çš„åºåˆ— `Sequence`ï¼‰æ•´ç†æˆæ¯”èµ›è¦æ±‚çš„ `.csv` æ–‡ä»¶æ ¼å¼ã€‚\n",
    "3.  **ä¸‹ä¸€æ­¥è¡ŒåŠ¨ ğŸ¤”:** è¿™ä¸ªæ•™ç¨‹åªæ˜¯ä¸€ä¸ªèµ·ç‚¹ï¼è¦åœ¨æ¯”èµ›ä¸­è·å¾—å¥½æˆç»©ï¼Œä½ è¿˜éœ€è¦ï¼š\n",
    "    *   **æ·±å…¥ç ”ç©¶ ğŸ“š:** èŠ±æ›´å¤šæ—¶é—´ä¼˜åŒ–ä½ çš„â€œå€™é€‰ä½ç‚¹æ± â€ï¼Œè®©å®ƒæ›´ç²¾å‡†ï¼\n",
    "    *   **å¹³è¡¡ç¨³å®šæ€§ ğŸ”¥:** è¿™æ¬¡æˆ‘ä»¬ä¸»è¦å…³æ³¨äº†äº®åº¦ï¼Œä½†æ¯”èµ›è¿˜è¦æ±‚**çƒ­ç¨³å®šæ€§**ï¼ä½ éœ€è¦æ€è€ƒå¦‚ä½•å¼•å…¥æé«˜ç¨³å®šæ€§çš„ç­–ç•¥ï¼ˆæ¯”å¦‚å‚è€ƒ Superfolder GFP çš„çªå˜ï¼Œåˆ†æ PDB ç»“æ„å¯»æ‰¾å¯ä»¥ä¼˜åŒ–çš„ç‚¹ï¼‰ã€‚è¿™å¯èƒ½æ˜¯ä¸ªå¤šç›®æ ‡ä¼˜åŒ–çš„æŒ‘æˆ˜ï¼\n",
    "    *   **å‡çº§è£…å¤‡ ğŸš€:** å¯ä»¥å°è¯•ä¸åŒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€æ›´ä»”ç»†åœ°è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œç”šè‡³æ¢ç´¢æ›´é«˜çº§çš„æŠ€æœ¯ã€‚\n",
    "    *   **æ‰“åŒ…æ–‡æ¡£ ğŸ“¦:** åˆ«å¿˜äº†æŒ‰è¦æ±‚æ•´ç†å¥½ä½ çš„ä»£ç  (`.zip`)ï¼Œå¹¶å†™ä¸€ä»½æ¸…æ™°çš„â€œè®¾è®¡æ€è·¯â€æ–‡æ¡£ (`.docx` æˆ– `.pdf`)ï¼Œè§£é‡Šä½ æ˜¯æ€ä¹ˆåšçš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": " ",
   "id": "c4c1695e-85c9-4fe7-82f3-c058d201f856",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_105",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:16:06.076223Z",
      "status": "aborted"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:16:06.076240Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_105",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "# --- 7.1 å‡†å¤‡æäº¤æ ¼å¼ (ç¤ºä¾‹) ---\n",
    "# æ¯”èµ›è¦æ±‚æäº¤ CSVï¼ŒåŒ…å« 'Sequence ID', 'Mutations', 'Full Sequence'\n",
    "# æˆ‘ä»¬å·²ç»æœ‰äº†ç±»ä¼¼æ ¼å¼çš„ DataFrame 'final_candidates_formatted'\n",
    "\n",
    "# å¦‚æœéœ€è¦ä¿å­˜ä¸º CSV æ–‡ä»¶ï¼š\n",
    "output_filename = \"my_top_brightness_candidates.csv\"\n",
    "if not final_candidates_formatted.empty:\n",
    "    # é€‰æ‹©éœ€è¦çš„åˆ—\n",
    "    submission_df = final_candidates_formatted[['Sequence ID', 'Mutations', 'Sequence']].copy()\n",
    "    # é‡å‘½ååˆ—ä»¥å®Œå…¨åŒ¹é…ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "    # submission_df.rename(columns={'Sequence': 'Full Sequence'}, inplace=True) # å‡è®¾éœ€è¦ 'Full Sequence' åˆ—å\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nSuccessfully saved top {len(submission_df)} candidates to {output_filename}\")\n",
    "else:\n",
    "    print(\"\\nNo final candidates to save.\")\n",
    "\n",
    "\n",
    "# --- 7.2 åç»­æ­¥éª¤ --- \n",
    "print(\"\\n--- æ•™ç¨‹å·²å®Œæˆ ---\") \n",
    "print(\"åç»­å¯èƒ½çš„ä¼˜åŒ–æ­¥éª¤ï¼š\") \n",
    "print(\"1.  **ä¼˜åŒ–ä½ç½®æ± ï¼š** ç›®å‰ä½¿ç”¨çš„æ•°æ®é‡å’Œæ‰¹æ¬¡éå¸¸å°ï¼Œæ‚¨å¯ä»¥è¿›è¡Œå…¨é¢çš„æ–‡çŒ®/æ•°æ®/ç»“æ„åˆ†æï¼Œä»¥åˆ›å»ºæ›´å¥½çš„`å€™é€‰ä½ç½®æ± `ã€‚\") \n",
    "print(\"2.  **è€ƒè™‘ç¨³å®šæ€§ï¼š** æœ¬æ•™ç¨‹ä»…å…³æ³¨äº®åº¦ã€‚ä½ éœ€è¦çº³å…¥é¢„æµ‹/æé«˜çƒ­ç¨³å®šæ€§çš„ç­–ç•¥æˆ–æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨PDBç»“æ„ã€å·²çŸ¥çš„ç¨³å®šçªå˜ï¼‰ã€‚è¿™å¯èƒ½æ¶‰åŠå¤šç›®æ ‡ä¼˜åŒ–ã€‚\") \n",
    "print(\"3.  **æ”¹è¿›æ¨¡å‹ï¼š** å°è¯•ä¸åŒçš„ESMæ¨¡å‹ã€å›å½’ç®—æ³•ï¼ˆä¾‹å¦‚æ¢¯åº¦æå‡ï¼‰ã€è¶…å‚æ•°è°ƒæ•´ï¼Œæˆ–æ›´å…ˆè¿›çš„æŠ€æœ¯ï¼Œå¦‚å¾®è°ƒESMã€‚\") \n",
    "print(\"4.  **ä»£ç æ‰“åŒ…ï¼š** æ ¹æ®è¦æ±‚å°†ä»£ç æ•´ç†æˆå¯è¿è¡Œçš„è„šæœ¬æˆ–åŒ…ï¼ˆ.zipï¼‰ã€‚åŒ…å«ä¸€ä¸ªREADMEæ–‡ä»¶ã€‚\") \n",
    "print(\"5.  **è®¾è®¡åŸç†ï¼š** æ’°å†™ä¸€ä»½æ¸…æ™°çš„æ–‡æ¡£ï¼Œè§£é‡Šä½ çš„æ–¹æ³•ã€é€‰æ‹©ç‰¹å®šä½ç½®/çªå˜çš„åŸå› ä»¥åŠæ‰€ä½¿ç”¨çš„æ–¹æ³•ã€‚\") \n",
    "print(\"6.  **æäº¤ï¼š** å‡†å¤‡æœ€ç»ˆçš„CSVæ–‡ä»¶ï¼Œå…¶ä¸­å‡†ç¡®åŒ…å«6æ¡åºåˆ—ï¼Œç¡®ä¿å®ƒä»¬ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ä¸”ç¬¦åˆçªå˜é™åˆ¶ã€‚\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0e68a-329d-45ba-b3c6-40097eeb330c",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972765c-db3d-4639-a8f3-3eb1926e7cc1",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹æ¼”ç¤ºäº†å…¶å®ƒæ–¹æ¡ˆ ä½¿ç”¨Saprotæ¨¡å‹ç”¨äºå‘é‡åµŒå…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776a8f4-625c-4192-b42b-889c3dedff91",
   "metadata": {},
   "source": [
    "---\n",
    "ğŸ§  **(å¤‡é€‰) ç¬¬ä¸‰æ­¥ Bï¼šè®© SaProt è¯»æ‡‚è›‹ç™½è´¨è¯­è¨€ï¼(ç‰¹å¾å·¥ç¨‹ - SaProt åµŒå…¥)**\n",
    "\n",
    "é™¤äº† ESMï¼Œè¿˜æœ‰å…¶ä»–å¼ºå¤§çš„è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ SaProtã€‚SaProt é€šå¸¸åŸºäº Transformer æ¶æ„ï¼Œå¹¶é€šè¿‡ Hugging Face çš„ `transformers` åº“åŠ è½½ã€‚\n",
    "\n",
    "ä¸ä¹‹å‰ä½¿ç”¨çš„è½»é‡çº§ ESM æ¨¡å‹ç›¸æ¯”ï¼ŒSaProt æ¨¡å‹ï¼ˆå¦‚ `ECAS/SaProt_650M_AF2`ï¼‰å‚æ•°é‡å¯èƒ½æ›´å¤§ï¼Œç†è®ºä¸Šå¯èƒ½æ•æ‰æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºï¼ˆå†…å­˜å’Œæ—¶é—´ï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨ CPU ä¸Šã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åŠ è½½ SaProt å¹¶ç”¨å®ƒæ¥ç”ŸæˆåµŒå…¥ã€‚ä½ å¯ä»¥é€‰æ‹©æ€§åœ°ç”¨è¿™äº›åµŒå…¥æ›¿æ¢å‰é¢ ESM ç”Ÿæˆçš„åµŒå…¥ï¼Œç”¨äºåç»­çš„æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚\n",
    "\n",
    "**æ³¨æ„:** ä¸‹ä¸€æ­¥éœ€è¦å®‰è£… `transformers` åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da53f72c-bf19-4fe9-b768-fad94ce17e96",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_201",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:30:37.706136Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_201",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers in /opt/miniconda/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/miniconda/lib/python3.7/site-packages (0.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: importlib-metadata in /opt/miniconda/lib/python3.7/site-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: filelock in /opt/miniconda/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/miniconda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.7/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n"
     ]
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_207",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:30:35.774968Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:30:39.488146Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_207",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "# å®‰è£… Hugging Face Transformers åº“\n",
    "!pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee8a40c-f568-43c1-a672-869e76a9bbe4",
   "metadata": {},
   "outputs": [
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_211",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:30:40.035015Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_211",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "HF_ENDPOINT æœªè®¾ç½®æˆ–éé¢„æœŸå€¼ã€‚å°†å°è¯•è®¾ç½® Hugging Face ç«¯ç‚¹ä¸ºé•œåƒ: https://hf-mirror.com\n",
      "å½“å‰è„šæœ¬æ‰§è¡Œç¯å¢ƒä¸­ HF_ENDPOINT å·²è®¾ç½®ä¸º: https://hf-mirror.com\n",
      "--- å¼€å§‹ SaProt å·¥ä½œæµç¨‹ ---\n",
      "æŒ‡å®šä½¿ç”¨çš„ SaProt æ¨¡å‹ (æ¥è‡ªé•œåƒ): westlake-repl/SaProt_35M_AF2\n",
      "æ£€æµ‹åˆ° CUDA GPUï¼Œå°†ä½¿ç”¨ GPU è¿›è¡Œ SaProt è®¡ç®—ã€‚\n",
      "GPU æ€»æ˜¾å­˜: 7.86 GB\n",
      "æœ€ç»ˆä½¿ç”¨çš„ SaProt è®¾å¤‡: cuda\n",
      "æœ€ç»ˆä½¿ç”¨çš„ SaProt æ¨¡å‹: westlake-repl/SaProt_35M_AF2\n",
      "æœ€ç»ˆä½¿ç”¨çš„ SaProt æ‰¹æ¬¡å¤§å°: 32\n",
      "\n",
      "[æ­¥éª¤ 1/9] æ£€æŸ¥ä¾èµ–å˜é‡/å‡½æ•°... é€šè¿‡ã€‚\n",
      "\n",
      "[æ­¥éª¤ 2/9] æ­£åœ¨åŠ è½½ SaProt Tokenizer å’Œæ¨¡å‹: westlake-repl/SaProt_35M_AF2 åˆ° cuda...\n",
      "Some weights of the model checkpoint at westlake-repl/SaProt_35M_AF2 were not used when initializing EsmModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at westlake-repl/SaProt_35M_AF2 and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "SaProt æ¨¡å‹åŠ è½½å¹¶åœ¨ cuda ä¸Šå‡†å¤‡å°±ç»ªï¼Œè€—æ—¶ 3.71 ç§’ã€‚\n",
      "\n",
      "[æ­¥éª¤ 3/9] æ­£åœ¨å®šä¹‰ SaProt åµŒå…¥å‡½æ•°...\n",
      "SaProt åµŒå…¥å‡½æ•°å®šä¹‰å®Œæˆã€‚\n",
      "\n",
      "[æ­¥éª¤ 4/9] æ­£åœ¨ä¸ºè®­ç»ƒæ•°æ®ç”Ÿæˆ SaProt åµŒå…¥...\n",
      "  è®­ç»ƒæ•°æ®é‡ (51715) è¾ƒå¤§ï¼Œå°†é‡‡æ · 5000 æ¡ç”¨äºåµŒå…¥å’Œè®­ç»ƒã€‚\n",
      "  å‡†å¤‡ä¸º 5000 ä¸ªåºåˆ—ç”Ÿæˆ SaProt åµŒå…¥ï¼Œå…± 157 æ‰¹ (æ‰¹å¤§å°: 32)...\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 15/157 (9.6%) - è€—æ—¶: 3.85 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 30/157 (19.1%) - è€—æ—¶: 9.62 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 45/157 (28.7%) - è€—æ—¶: 15.70 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 60/157 (38.2%) - è€—æ—¶: 21.73 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 75/157 (47.8%) - è€—æ—¶: 27.76 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 90/157 (57.3%) - è€—æ—¶: 33.78 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 105/157 (66.9%) - è€—æ—¶: 39.82 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 120/157 (76.4%) - è€—æ—¶: 45.88 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 135/157 (86.0%) - è€—æ—¶: 51.90 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 150/157 (95.5%) - è€—æ—¶: 57.92 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 157/157 (100.0%) - è€—æ—¶: 60.44 ç§’\n",
      "  SaProt åµŒå…¥ç”Ÿæˆå®Œæˆï¼Œæ€»è€—æ—¶: 60.44 ç§’ã€‚\n",
      "  å¹³å‡æ¯ä¸ªåºåˆ—è€—æ—¶: 0.0121 ç§’ã€‚\n",
      "  ç”Ÿæˆçš„è®­ç»ƒæ•°æ®åµŒå…¥å¼ é‡å½¢çŠ¶: torch.Size([5000, 480])\n",
      "  å‡†å¤‡å¥½çš„ X_saprot (åµŒå…¥) å½¢çŠ¶: (5000, 480), y_saprot (äº®åº¦) å½¢çŠ¶: (5000,)\n",
      "\n",
      "[æ­¥éª¤ 5/9] æ­£åœ¨ä½¿ç”¨ SaProt åµŒå…¥è®­ç»ƒéšæœºæ£®æ—å›å½’å™¨...\n",
      "  å·²å°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›† (4000) å’ŒéªŒè¯é›† (1000)ã€‚\n",
      "  å¼€å§‹è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...\n",
      "  éšæœºæ£®æ—è®­ç»ƒå®Œæˆï¼Œè€—æ—¶ 0.43 ç§’ã€‚\n",
      "  åŸºäº SaProt çš„æ¨¡å‹åœ¨ã€éªŒè¯é›†ã€‘ä¸Šçš„ RÂ² åˆ†æ•°: -0.0043\n",
      "\n",
      "[æ­¥éª¤ 6/9] æ­£åœ¨ç”Ÿæˆ 500 ä¸ªå€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 50/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 100/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 150/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 200/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 250/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 300/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 350/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 400/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 450/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  å·²ç”Ÿæˆ 500/500 ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\n",
      "  æˆåŠŸç”Ÿæˆ 500 ä¸ªç‹¬ç‰¹çš„å€™é€‰åºåˆ—ã€‚\n",
      "  å€™é€‰åºåˆ—ç”Ÿæˆè€—æ—¶: 0.01 ç§’ã€‚\n",
      "\n",
      "[æ­¥éª¤ 7/9] æ­£åœ¨ä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ SaProt åµŒå…¥...\n",
      "  å°†ä¸º 500 ä¸ªå€™é€‰åºåˆ—ç”ŸæˆåµŒå…¥ã€‚\n",
      "  å‡†å¤‡ä¸º 500 ä¸ªåºåˆ—ç”Ÿæˆ SaProt åµŒå…¥ï¼Œå…± 16 æ‰¹ (æ‰¹å¤§å°: 32)...\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 1/16 (6.2%) - è€—æ—¶: 0.25 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 2/16 (12.5%) - è€—æ—¶: 0.50 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 3/16 (18.8%) - è€—æ—¶: 0.76 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 4/16 (25.0%) - è€—æ—¶: 1.06 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 5/16 (31.2%) - è€—æ—¶: 1.44 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 6/16 (37.5%) - è€—æ—¶: 1.85 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 7/16 (43.8%) - è€—æ—¶: 2.28 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 8/16 (50.0%) - è€—æ—¶: 2.71 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 9/16 (56.2%) - è€—æ—¶: 3.13 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 10/16 (62.5%) - è€—æ—¶: 3.55 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 11/16 (68.8%) - è€—æ—¶: 3.98 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 12/16 (75.0%) - è€—æ—¶: 4.38 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 13/16 (81.2%) - è€—æ—¶: 4.79 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 14/16 (87.5%) - è€—æ—¶: 5.20 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 15/16 (93.8%) - è€—æ—¶: 5.60 ç§’\n",
      "    å·²å¤„ç†æ‰¹æ¬¡ 16/16 (100.0%) - è€—æ—¶: 5.85 ç§’\n",
      "  SaProt åµŒå…¥ç”Ÿæˆå®Œæˆï¼Œæ€»è€—æ—¶: 5.85 ç§’ã€‚\n",
      "  å¹³å‡æ¯ä¸ªåºåˆ—è€—æ—¶: 0.0117 ç§’ã€‚\n",
      "  ç”Ÿæˆçš„å€™é€‰åºåˆ—åµŒå…¥å¼ é‡å½¢çŠ¶: torch.Size([500, 480])\n",
      "\n",
      "[æ­¥éª¤ 8/9] æ­£åœ¨ä½¿ç”¨åŸºäº SaProt çš„éšæœºæ£®æ—æ¨¡å‹é¢„æµ‹å€™é€‰åºåˆ—çš„äº®åº¦...\n",
      "  äº®åº¦é¢„æµ‹å®Œæˆï¼Œè€—æ—¶ 0.10 ç§’ã€‚\n",
      "  æˆåŠŸé¢„æµ‹äº† 500 ä¸ªå€™é€‰åºåˆ—çš„äº®åº¦ã€‚\n",
      "\n",
      "[æ­¥éª¤ 9/9] æ­£åœ¨è¿‡æ»¤ã€é€‰æ‹© Top N å€™é€‰åºåˆ—å¹¶ä¿å­˜ç»“æœ...\n",
      "  å·²åˆ›å»ºåŒ…å« 500 ä¸ªå€™é€‰åºåˆ—åŠå…¶é¢„æµ‹äº®åº¦çš„ DataFrameã€‚\n",
      "  æ­£åœ¨æ ¹æ®æ’é™¤åˆ—è¡¨ (739 æ¡) è¿›è¡Œè¿‡æ»¤...\n",
      "  ç§»é™¤äº† 1 ä¸ªåœ¨æ’é™¤åˆ—è¡¨ä¸­çš„åºåˆ—ã€‚\n",
      "  è¿‡æ»¤åå‰©ä½™å€™é€‰åºåˆ—: 499 æ¡ã€‚\n",
      "\n",
      "  ç­›é€‰å‡ºçš„ Top 6 (æœ€å¤š 6) ä¸ª SaProt é¢„æµ‹å€™é€‰ (å·²æ’é™¤):\n",
      "--- SaProt Top Candidates ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence ID</th>\n",
       "      <th>Mutations</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>PredictedBrightness_SaProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SaProt_Candidate_1</td>\n",
       "      <td>C70I</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>2.650868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>SaProt_Candidate_2</td>\n",
       "      <td>S30Q:N105Q:M153P:V163E:T203S:L221D</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVQGEGEGDATYGKLTLKF...</td>\n",
       "      <td>2.650868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>SaProt_Candidate_3</td>\n",
       "      <td>V68K:K101H:N105T:T203Y:L221V:H231E</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>2.650868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>SaProt_Candidate_4</td>\n",
       "      <td>S30F:F71G:K101M:N105S:M153T</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVFGEGEGDATYGKLTLKF...</td>\n",
       "      <td>2.650868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>SaProt_Candidate_5</td>\n",
       "      <td>Y145A</td>\n",
       "      <td>MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>2.650868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>SaProt_Candidate_6</td>\n",
       "      <td>G10F:N105I:Y145T:S147Y:I171P</td>\n",
       "      <td>MSKGEELFTFVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...</td>\n",
       "      <td>2.650868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sequence ID                           Mutations  \\\n",
       "0    SaProt_Candidate_1                                C70I   \n",
       "328  SaProt_Candidate_2  S30Q:N105Q:M153P:V163E:T203S:L221D   \n",
       "341  SaProt_Candidate_3  V68K:K101H:N105T:T203Y:L221V:H231E   \n",
       "340  SaProt_Candidate_4         S30F:F71G:K101M:N105S:M153T   \n",
       "339  SaProt_Candidate_5                               Y145A   \n",
       "338  SaProt_Candidate_6        G10F:N105I:Y145T:S147Y:I171P   \n",
       "\n",
       "                                              Sequence  \\\n",
       "0    MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "328  MSKGEELFTGVVPILVELDGDVNGHKFSVQGEGEGDATYGKLTLKF...   \n",
       "341  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "340  MSKGEELFTGVVPILVELDGDVNGHKFSVFGEGEGDATYGKLTLKF...   \n",
       "339  MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "338  MSKGEELFTFVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKF...   \n",
       "\n",
       "     PredictedBrightness_SaProt  \n",
       "0                      2.650868  \n",
       "328                    2.650868  \n",
       "341                    2.650868  \n",
       "340                    2.650868  \n",
       "339                    2.650868  \n",
       "338                    2.650868  "
      ]
     },
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_245",
     "meta": {},
     "metadata": {},
     "output_type": "display_data",
     "parent_header": {
      "date": "2025-04-27T14:31:51.223730Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_245",
      "msg_type": "display_data",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_246",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-04-27T14:31:51.227887Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_246",
      "msg_type": "stream",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "----------------------------\n",
      "\n",
      "  å·²æˆåŠŸå°† Top 6 ä¸ª SaProt å€™é€‰åºåˆ—ä¿å­˜åˆ°æ–‡ä»¶: my_top_saprot_candidates.csv\n",
      "\n",
      "--- SaProt å·¥ä½œæµç¨‹ç»“æŸ ---\n"
     ]
    },
    {
     "id": "9c1f9c87-33eef1a094312e02050a72e7_374_247",
     "meta": {
      "dependencies_met": true,
      "engine": "91221703-bed9-4a3d-953a-9ea6a097dcc2",
      "started": "2025-04-27T14:30:39.757053Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-04-27T14:31:51.229008Z",
      "msg_id": "9c1f9c87-33eef1a094312e02050a72e7_374_247",
      "msg_type": "execute_reply",
      "session": "9c1f9c87-33eef1a094312e02050a72e7",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# --- SaProt å®Œæ•´å·¥ä½œæµç¨‹å•å…ƒ ---\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# === åœ¨å¯¼å…¥ transformers ä¹‹å‰è®¾ç½® Hugging Face é•œåƒ ===\n",
    "# æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦å·²è®¾ç½®ï¼Œå¦‚æœæœªè®¾ç½®ï¼Œåˆ™ä½¿ç”¨é•œåƒ\n",
    "# è¿™æ ·åšå¯ä»¥æœ€å¤§ç¨‹åº¦ç¡®ä¿ transformers åº“åœ¨åˆå§‹åŒ–æ—¶å°±ä½¿ç”¨é•œåƒåœ°å€\n",
    "hf_endpoint = os.environ.get('HF_ENDPOINT')\n",
    "mirror_endpoint = 'https://hf-mirror.com' # æŒ‡å®šé•œåƒåœ°å€\n",
    "\n",
    "if hf_endpoint != mirror_endpoint: # ä»…åœ¨æœªè®¾ç½®æˆ–è®¾ç½®ä¸æ­£ç¡®æ—¶è¿›è¡Œè®¾ç½®\n",
    "    print(f\"HF_ENDPOINT æœªè®¾ç½®æˆ–éé¢„æœŸå€¼ã€‚å°†å°è¯•è®¾ç½® Hugging Face ç«¯ç‚¹ä¸ºé•œåƒ: {mirror_endpoint}\")\n",
    "    os.environ['HF_ENDPOINT'] = mirror_endpoint\n",
    "    # éªŒè¯æ˜¯å¦è®¾ç½®æˆåŠŸ (å¯èƒ½éœ€è¦é‡å¯å†…æ ¸/ç¯å¢ƒæ‰èƒ½å®Œå…¨ç”Ÿæ•ˆï¼Œä½†åœ¨è„šæœ¬å†…å°½åŠ›è®¾ç½®)\n",
    "    current_endpoint = os.environ.get('HF_ENDPOINT')\n",
    "    if current_endpoint == mirror_endpoint:\n",
    "        print(f\"å½“å‰è„šæœ¬æ‰§è¡Œç¯å¢ƒä¸­ HF_ENDPOINT å·²è®¾ç½®ä¸º: {current_endpoint}\")\n",
    "    else:\n",
    "        print(f\"è­¦å‘Š: å°è¯•è®¾ç½® HF_ENDPOINTï¼Œä½†è¯»å–å€¼ä»ä¸º {current_endpoint}ã€‚ç¯å¢ƒå˜é‡å¯èƒ½æœªå®Œå…¨ç”Ÿæ•ˆã€‚\")\n",
    "        # å¦‚æœè„šæœ¬å†…è®¾ç½®æ— æ•ˆï¼Œå¯èƒ½éœ€è¦åœ¨å¤–éƒ¨ç¯å¢ƒï¼ˆå¦‚å¯åŠ¨è„šæœ¬æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡ï¼‰ä¸­è®¾ç½®\n",
    "else:\n",
    "    print(f\"æ£€æµ‹åˆ° HF_ENDPOINT å·²è®¾ç½®ä¸ºé•œåƒ: {hf_endpoint}ï¼Œå°†ç»§ç»­ä½¿ç”¨æ­¤åœ°å€ã€‚\")\n",
    "\n",
    "# === 1. å¯¼å…¥åº“ä¸åŸºç¡€è®¾ç½® ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "# å°è¯•å¯¼å…¥ transformers (ç°åœ¨åº”è¯¥ä¼šä½¿ç”¨è®¾ç½®çš„ HF_ENDPOINT)\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "except ImportError:\n",
    "    print(\"é”™è¯¯: æ— æ³•å¯¼å…¥ transformers åº“ã€‚è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… (pip install transformers)ã€‚\")\n",
    "    sys.exit(1) # æ— æ³•å¯¼å…¥åˆ™é€€å‡º\n",
    "\n",
    "# åœ¨Jupyter Notebookä¸­ä¼˜åŒ–DataFrameçš„æ˜¾ç¤º\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    # å¦‚æœä¸åœ¨IPythonç¯å¢ƒä¸­ï¼Œå®šä¹‰ä¸€ä¸ªç®€å•çš„displayå‡½æ•°\n",
    "    def display(x):\n",
    "        print(x)\n",
    "\n",
    "warnings.filterwarnings('ignore') # å¿½ç•¥ä¸å½±å“ç»“æœçš„è­¦å‘Š\n",
    "\n",
    "print(\"--- å¼€å§‹ SaProt å·¥ä½œæµç¨‹ ---\")\n",
    "\n",
    "# === 2. å®‰è£…ä¾èµ– (æ³¨é‡Šæ‰ï¼Œå»ºè®®åœ¨ç¯å¢ƒçº§åˆ«ç®¡ç†) ===\n",
    "# print(\"\\n[æ­¥éª¤ 1/9] æ­£åœ¨å®‰è£…æ‰€éœ€åº“ (transformers, sentencepiece)...\")\n",
    "# !pip install transformers sentencepiece -q # -q è¡¨ç¤ºé™é»˜å®‰è£…\n",
    "# print(\"åº“å®‰è£…æ£€æŸ¥å®Œæˆã€‚\")\n",
    "\n",
    "\n",
    "# === 3. SaProt å¸¸é‡è®¾ç½®ä¸è®¾å¤‡æ£€æµ‹ ===\n",
    "\n",
    "# --- æ¨¡å‹åç§° (æ¥è‡ªé•œåƒ) ---\n",
    "SAPROT_MODEL_NAME = \"westlake-repl/SaProt_35M_AF2\"\n",
    "print(f\"æŒ‡å®šä½¿ç”¨çš„ SaProt æ¨¡å‹ (æ¥è‡ªé•œåƒ): {SAPROT_MODEL_NAME}\")\n",
    "\n",
    "# --- æ‰¹æ¬¡å¤§å°è®¾ç½® ---\n",
    "SAPROT_BATCH_SIZE_CPU = 4\n",
    "SAPROT_BATCH_SIZE_GPU = 32 # 35M æ¨¡å‹é€šå¸¸å…è®¸è¾ƒå¤§çš„æ‰¹æ¬¡\n",
    "\n",
    "# --- è®¾å¤‡æ£€æµ‹ ---\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_SAPROT = torch.device(\"cuda\")\n",
    "    SAPROT_BATCH_SIZE = SAPROT_BATCH_SIZE_GPU\n",
    "    print(\"æ£€æµ‹åˆ° CUDA GPUï¼Œå°†ä½¿ç”¨ GPU è¿›è¡Œ SaProt è®¡ç®—ã€‚\")\n",
    "    try:\n",
    "        gpu_mem_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"GPU æ€»æ˜¾å­˜: {gpu_mem_gb:.2f} GB\")\n",
    "    except Exception as e:\n",
    "        print(f\"æ— æ³•è·å–GPUå†…å­˜ä¿¡æ¯: {e}\")\n",
    "else:\n",
    "    DEVICE_SAPROT = torch.device(\"cpu\")\n",
    "    SAPROT_BATCH_SIZE = SAPROT_BATCH_SIZE_CPU\n",
    "    print(\"æœªæ£€æµ‹åˆ° CUDA GPU æˆ– CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è¿›è¡Œ SaProt è®¡ç®—ã€‚\")\n",
    "\n",
    "# --- æœ€ç»ˆç¡®è®¤æ‰“å° ---\n",
    "print(f\"æœ€ç»ˆä½¿ç”¨çš„ SaProt è®¾å¤‡: {DEVICE_SAPROT}\")\n",
    "print(f\"æœ€ç»ˆä½¿ç”¨çš„ SaProt æ¨¡å‹: {SAPROT_MODEL_NAME}\")\n",
    "print(f\"æœ€ç»ˆä½¿ç”¨çš„ SaProt æ‰¹æ¬¡å¤§å°: {SAPROT_BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "# === æ£€æŸ¥å…ˆå‰å•å…ƒæ ¼å®šä¹‰çš„å¿…è¦å˜é‡/å‡½æ•°æ˜¯å¦å­˜åœ¨ ===\n",
    "# ç¡®ä¿è¿è¡Œæ­¤å•å…ƒæ ¼å‰ï¼Œå·²æˆåŠŸè¿è¡Œå®šä¹‰è¿™äº›å˜é‡å’Œå‡½æ•°çš„å•å…ƒæ ¼\n",
    "# !!! æ³¨æ„: è¯·ç¡®ä¿åœ¨è¿è¡Œæ­¤è„šæœ¬/å•å…ƒæ ¼ä¹‹å‰ï¼Œè¿™äº›å˜é‡å·²ç»åœ¨æ‚¨çš„ç¯å¢ƒä¸­å®šä¹‰ !!!\n",
    "required_vars = ['avGFP_train_df', 'avGFP_WT_sequence', 'exclusion_sequences',\n",
    "                 'MAX_TRAIN_SAMPLES_FOR_EMBEDDING', 'SEED', 'candidate_position_pool_0based',\n",
    "                 'amino_acids', 'MAX_MUTATIONS', 'N_CANDIDATES_TO_GENERATE', 'TOP_N_SELECT',\n",
    "                 'generate_single_candidate']\n",
    "missing = [var for var in required_vars if not (var in locals() or var in globals())]\n",
    "if missing:\n",
    "    print(\"\\né”™è¯¯: æœªæ‰¾åˆ°æ‰€æœ‰å¿…éœ€çš„å˜é‡æˆ–å‡½æ•°ã€‚\")\n",
    "    print(f\"è¯·ç¡®ä¿å·²é¦–å…ˆè¿è¡Œå®šä¹‰äº†ä»¥ä¸‹å†…å®¹çš„å•å…ƒæ ¼: {', '.join(missing)}\")\n",
    "    raise NameError(f\"ç¼ºå°‘æ¥è‡ªå…ˆå‰ç¬”è®°æœ¬å•å…ƒæ ¼çš„å¿…éœ€å˜é‡: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"\\n[æ­¥éª¤ 1/9] æ£€æŸ¥ä¾èµ–å˜é‡/å‡½æ•°... é€šè¿‡ã€‚\")\n",
    "\n",
    "\n",
    "# === 4. åŠ è½½ SaProt Tokenizer å’Œæ¨¡å‹ ===\n",
    "# ç°åœ¨è°ƒç”¨ from_pretrained æ—¶ï¼Œåº”è¯¥ä½¿ç”¨è„šæœ¬é¡¶éƒ¨è®¾ç½®çš„ç¯å¢ƒå˜é‡\n",
    "print(f\"\\n[æ­¥éª¤ 2/9] æ­£åœ¨åŠ è½½ SaProt Tokenizer å’Œæ¨¡å‹: {SAPROT_MODEL_NAME} åˆ° {DEVICE_SAPROT}...\")\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # ç›´æ¥è°ƒç”¨ï¼Œä¾èµ–äºé¡¶éƒ¨çš„ç¯å¢ƒå˜é‡è®¾ç½®\n",
    "    saprot_tokenizer = AutoTokenizer.from_pretrained(SAPROT_MODEL_NAME)\n",
    "    saprot_model = AutoModel.from_pretrained(SAPROT_MODEL_NAME)\n",
    "\n",
    "    # --- ä¼˜åŒ–: å°è¯•ä½¿ç”¨ torch.compile (ä¿æŒä¸å˜) ---\n",
    "    use_torch_compile = False\n",
    "    if DEVICE_SAPROT == torch.device(\"cuda\") and hasattr(torch, 'compile'):\n",
    "        try:\n",
    "            print(\"  å°è¯•ä½¿ç”¨ torch.compile ä¼˜åŒ–æ¨¡å‹ (å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...\")\n",
    "            # 'reduce-overhead' æ¨¡å¼é€šå¸¸é€‚ç”¨äºæ¨ç†\n",
    "            saprot_model = torch.compile(saprot_model, mode=\"reduce-overhead\", fullgraph=True)\n",
    "            print(\"  torch.compile åº”ç”¨æˆåŠŸï¼\")\n",
    "            use_torch_compile = True\n",
    "        except Exception as compile_err:\n",
    "            print(f\"  torch.compile å¤±è´¥: {compile_err}ã€‚å°†ä½¿ç”¨æœªä¼˜åŒ–çš„æ¨¡å‹ã€‚\")\n",
    "\n",
    "    # --- æ¨¡å‹è®¾ç½®ä¸è®¾å¤‡è½¬ç§» (ä¿æŒä¸å˜) ---\n",
    "    saprot_model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    saprot_model = saprot_model.to(DEVICE_SAPROT) # å°†æ¨¡å‹å‚æ•°ç§»åŠ¨åˆ° GPU æˆ– CPU\n",
    "\n",
    "    print(f\"SaProt æ¨¡å‹åŠ è½½å¹¶åœ¨ {DEVICE_SAPROT} ä¸Šå‡†å¤‡å°±ç»ªï¼Œè€—æ—¶ {time.time() - start_time:.2f} ç§’ã€‚\")\n",
    "\n",
    "except OSError as e:\n",
    "    # æ•è· OSErrorï¼Œå®ƒé€šå¸¸åŒ…å«è¿æ¥æˆ–æ–‡ä»¶æœªæ‰¾åˆ°çš„é”™è¯¯\n",
    "    print(f\"\\n!!! åŠ è½½æ¨¡å‹æ—¶å‘ç”Ÿ OSError: {e}\")\n",
    "    print(\"è¿™é€šå¸¸æ„å‘³ç€ï¼š\")\n",
    "    print(\"  1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼šæ— æ³•è®¿é—® HF_ENDPOINT æŒ‡å®šçš„åœ°å€ã€‚\")\n",
    "    print(f\"     - æ£€æŸ¥é•œåƒåœ°å€ '{os.environ.get('HF_ENDPOINT')}' æ˜¯å¦å¯è®¿é—®ã€‚\")\n",
    "    print(f\"     - æ£€æŸ¥ä½ çš„ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®ã€‚\")\n",
    "    print(\"  2. æ¨¡å‹åç§°é”™è¯¯æˆ–é•œåƒä¸Šä¸å­˜åœ¨è¯¥æ¨¡å‹ã€‚\")\n",
    "    print(f\"     - ç¡®è®¤æ¨¡å‹ '{SAPROT_MODEL_NAME}' åœ¨é•œåƒç«™ç‚¹ä¸Šç¡®å®å­˜åœ¨ã€‚\")\n",
    "    print(\"  3. ç¼“å­˜é—®é¢˜ï¼šæœ¬åœ°ç¼“å­˜å¯èƒ½å·²æŸåæˆ–ä¸å®Œæ•´ã€‚\")\n",
    "    print(\"     - å°è¯•æ¸…é™¤ Hugging Face ç¼“å­˜ (é€šå¸¸åœ¨ ~/.cache/huggingface/hub æˆ– ~/.cache/huggingface/transformers)ã€‚\")\n",
    "    print(\"  4. ç¯å¢ƒå˜é‡æœªç”Ÿæ•ˆï¼šå¦‚æœçœ‹åˆ°é”™è¯¯ä»ç„¶æŒ‡å‘ huggingface.coï¼Œå¯èƒ½éœ€è¦é‡å¯ Python å†…æ ¸/ç¯å¢ƒæˆ–åœ¨å¤–éƒ¨è®¾ç½®ç¯å¢ƒå˜é‡ã€‚\")\n",
    "    # å¯ä»¥é€‰æ‹©åœæ­¢æ‰§è¡Œ\n",
    "    raise e\n",
    "except Exception as e:\n",
    "    # æ•è·å…¶ä»–å¯èƒ½çš„å¼‚å¸¸\n",
    "    print(f\"\\n!!! åŠ è½½ SaProt æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "    print(f\"ä½¿ç”¨çš„æ¨¡å‹æ ‡è¯†ç¬¦: {SAPROT_MODEL_NAME}\")\n",
    "    print(f\"ä½¿ç”¨çš„é•œåƒç«¯ç‚¹: {os.environ.get('HF_ENDPOINT')}\")\n",
    "    raise # é‡æ–°å¼•å‘å¼‚å¸¸ï¼Œåœæ­¢æ‰§è¡Œ\n",
    "\n",
    "\n",
    "# === 5. å®šä¹‰ SaProt åµŒå…¥å‡½æ•° ===\n",
    "print(\"\\n[æ­¥éª¤ 3/9] æ­£åœ¨å®šä¹‰ SaProt åµŒå…¥å‡½æ•°...\")\n",
    "def get_saprot_embeddings(sequences, model, tokenizer, device, batch_size, use_compile=False):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ SaProt æ¨¡å‹ä¸ºåºåˆ—åˆ—è¡¨ç”ŸæˆåµŒå…¥ (é‡‡ç”¨å¹³å‡æ± åŒ–)ã€‚\n",
    "    é’ˆå¯¹ GPU è¿›è¡Œäº†ä¼˜åŒ–ï¼Œè‡ªåŠ¨å¤„ç†è®¾å¤‡è½¬ç§»å’Œæ‰¹å¤„ç†ã€‚\n",
    "    \"\"\"\n",
    "    embeddings = [] # ç”¨äºå­˜å‚¨æ¯ä¸ªæ‰¹æ¬¡çš„åµŒå…¥ç»“æœ\n",
    "    num_sequences = len(sequences)\n",
    "    if num_sequences == 0:\n",
    "        print(\"  è¾“å…¥åºåˆ—åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€ç”ŸæˆåµŒå…¥ã€‚\")\n",
    "        return torch.tensor([])\n",
    "\n",
    "    num_batches = (num_sequences + batch_size - 1) // batch_size\n",
    "    print(f\"  å‡†å¤‡ä¸º {num_sequences} ä¸ªåºåˆ—ç”Ÿæˆ SaProt åµŒå…¥ï¼Œå…± {num_batches} æ‰¹ (æ‰¹å¤§å°: {batch_size})...\")\n",
    "    start_time_embed = time.time()\n",
    "\n",
    "    model.eval() # å†æ¬¡ç¡®ä¿æ˜¯è¯„ä¼°æ¨¡å¼\n",
    "\n",
    "    with torch.no_grad(): # ä¼˜åŒ–æ¨ç†é€Ÿåº¦å’Œå†…å­˜\n",
    "        for i in range(0, num_sequences, batch_size):\n",
    "            batch_seqs = sequences[i:i + batch_size]\n",
    "            batch_seqs_spaced = [\" \".join(list(s)) for s in batch_seqs] # SaProt éœ€è¦ç©ºæ ¼åˆ†éš”\n",
    "            current_batch_num = i // batch_size + 1\n",
    "\n",
    "            try:\n",
    "                inputs = tokenizer(batch_seqs_spaced, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
    "                inputs = {key: val.to(device) for key, val in inputs.items()} # æ•°æ®ç§»åŠ¨åˆ° GPU/CPU\n",
    "                outputs = model(**inputs) # æ¨¡å‹æ¨ç†\n",
    "                last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "                # å¹³å‡æ± åŒ– (è€ƒè™‘ attention mask)\n",
    "                mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden_states.size()).float()\n",
    "                sum_hidden_states = torch.sum(last_hidden_states * mask, dim=1)\n",
    "                sum_mask = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "                mean_pooled_embeddings = sum_hidden_states / sum_mask\n",
    "\n",
    "                embeddings.append(mean_pooled_embeddings.cpu()) # ç»“æœç§»å› CPU\n",
    "\n",
    "                # æ‰“å°è¿›åº¦\n",
    "                if current_batch_num % max(1, num_batches // 10) == 0 or current_batch_num == num_batches:\n",
    "                     progress_percent = (current_batch_num / num_batches) * 100\n",
    "                     elapsed = time.time() - start_time_embed\n",
    "                     print(f\"    å·²å¤„ç†æ‰¹æ¬¡ {current_batch_num}/{num_batches} ({progress_percent:.1f}%) - è€—æ—¶: {elapsed:.2f} ç§’\")\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                # å¤„ç†å†…å­˜ä¸è¶³ç­‰è¿è¡Œæ—¶é”™è¯¯\n",
    "                if \"CUDA out of memory\" in str(e) and device == torch.device(\"cuda\"):\n",
    "                    print(f\"\\n    å¤„ç†æ‰¹æ¬¡ {current_batch_num} æ—¶å‘ç”Ÿ CUDA å†…å­˜ä¸è¶³é”™è¯¯!\")\n",
    "                    print(f\"    å½“å‰æ‰¹æ¬¡å¤§å°: {batch_size}ã€‚è¯·å°è¯•å‡å° 'SAPROT_BATCH_SIZE_GPU'ã€‚\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    hidden_size = model.config.hidden_size if hasattr(model, 'config') else 768 # å°è¯•è·å–ç»´åº¦\n",
    "                    error_placeholder = torch.full((len(batch_seqs), hidden_size), float('nan'), device='cpu')\n",
    "                    embeddings.append(error_placeholder)\n",
    "                else:\n",
    "                    print(f\"    å¤„ç† SaProt æ‰¹æ¬¡ {current_batch_num} æ—¶å‘ç”Ÿè¿è¡Œæ—¶é”™è¯¯: {e}\")\n",
    "                    hidden_size = model.config.hidden_size if hasattr(model, 'config') else 768\n",
    "                    error_placeholder = torch.full((len(batch_seqs), hidden_size), float('nan'), device='cpu')\n",
    "                    embeddings.append(error_placeholder)\n",
    "            except Exception as e:\n",
    "                # å¤„ç†å…¶ä»–é”™è¯¯\n",
    "                print(f\"    å¤„ç† SaProt æ‰¹æ¬¡ {current_batch_num} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "                hidden_size = model.config.hidden_size if hasattr(model, 'config') else 768\n",
    "                error_placeholder = torch.full((len(batch_seqs), hidden_size), float('nan'), device='cpu')\n",
    "                embeddings.append(error_placeholder)\n",
    "\n",
    "    total_embed_time = time.time() - start_time_embed\n",
    "    print(f\"  SaProt åµŒå…¥ç”Ÿæˆå®Œæˆï¼Œæ€»è€—æ—¶: {total_embed_time:.2f} ç§’ã€‚\")\n",
    "    if num_sequences > 0:\n",
    "        print(f\"  å¹³å‡æ¯ä¸ªåºåˆ—è€—æ—¶: {total_embed_time / num_sequences:.4f} ç§’ã€‚\")\n",
    "\n",
    "    # æ‹¼æ¥åµŒå…¥ç»“æœ\n",
    "    if not embeddings: return torch.tensor([])\n",
    "    try:\n",
    "        full_embeddings = torch.cat(embeddings, dim=0)\n",
    "    except Exception as cat_err:\n",
    "        print(f\"  æ‹¼æ¥åµŒå…¥æ‰¹æ¬¡æ—¶å‡ºé”™: {cat_err}ã€‚å°è¯•æ‹¼æ¥æœ‰æ•ˆéƒ¨åˆ†...\")\n",
    "        valid_embeddings = [emb for emb in embeddings if isinstance(emb, torch.Tensor) and emb.ndim == 2 and not torch.isnan(emb).all()]\n",
    "        if valid_embeddings:\n",
    "             try:\n",
    "                 expected_dim = valid_embeddings[0].shape[1]\n",
    "                 valid_embeddings = [emb for emb in valid_embeddings if emb.shape[1] == expected_dim]\n",
    "                 if valid_embeddings:\n",
    "                     full_embeddings = torch.cat(valid_embeddings, dim=0)\n",
    "                 else: return torch.tensor([]) # æ²¡æœ‰ç»´åº¦ä¸€è‡´çš„\n",
    "             except Exception: return torch.tensor([]) # æ‹¼æ¥æœ‰æ•ˆéƒ¨åˆ†ä¹Ÿå¤±è´¥\n",
    "        else: return torch.tensor([]) # æ²¡æœ‰æœ‰æ•ˆçš„\n",
    "\n",
    "    return full_embeddings\n",
    "\n",
    "print(\"SaProt åµŒå…¥å‡½æ•°å®šä¹‰å®Œæˆã€‚\")\n",
    "\n",
    "\n",
    "# === 6. ä¸ºè®­ç»ƒæ•°æ®ç”Ÿæˆ SaProt åµŒå…¥ ===\n",
    "print(f\"\\n[æ­¥éª¤ 4/9] æ­£åœ¨ä¸ºè®­ç»ƒæ•°æ®ç”Ÿæˆ SaProt åµŒå…¥...\")\n",
    "# (é‡‡æ ·é€»è¾‘ä¿æŒä¸å˜)\n",
    "if len(avGFP_train_df) > MAX_TRAIN_SAMPLES_FOR_EMBEDDING:\n",
    "    print(f\"  è®­ç»ƒæ•°æ®é‡ ({len(avGFP_train_df)}) è¾ƒå¤§ï¼Œå°†é‡‡æ · {MAX_TRAIN_SAMPLES_FOR_EMBEDDING} æ¡ç”¨äºåµŒå…¥å’Œè®­ç»ƒã€‚\")\n",
    "    sampled_train_df_saprot = avGFP_train_df.sample(n=MAX_TRAIN_SAMPLES_FOR_EMBEDDING, random_state=SEED)\n",
    "else:\n",
    "    print(f\"  ä½¿ç”¨å…¨éƒ¨ {len(avGFP_train_df)} æ¡è®­ç»ƒæ•°æ®è¿›è¡ŒåµŒå…¥ã€‚\")\n",
    "    sampled_train_df_saprot = avGFP_train_df.copy()\n",
    "\n",
    "train_sequences_saprot = sampled_train_df_saprot['full_sequence'].tolist()\n",
    "X_saprot = None # åˆå§‹åŒ–ä¸º None\n",
    "y_saprot = None\n",
    "\n",
    "if train_sequences_saprot:\n",
    "    X_saprot_tensor = get_saprot_embeddings(\n",
    "        train_sequences_saprot, saprot_model, saprot_tokenizer, DEVICE_SAPROT,\n",
    "        batch_size=SAPROT_BATCH_SIZE, use_compile=use_torch_compile\n",
    "    )\n",
    "    if X_saprot_tensor.numel() > 0:\n",
    "        print(f\"  ç”Ÿæˆçš„è®­ç»ƒæ•°æ®åµŒå…¥å¼ é‡å½¢çŠ¶: {X_saprot_tensor.shape}\")\n",
    "        X_saprot_np = X_saprot_tensor.numpy()\n",
    "        # å¤„ç† NaN\n",
    "        nan_rows_mask_train = np.isnan(X_saprot_np).any(axis=1)\n",
    "        if np.any(nan_rows_mask_train):\n",
    "            num_nan_rows = nan_rows_mask_train.sum()\n",
    "            print(f\"  è­¦å‘Š: åœ¨è®­ç»ƒåµŒå…¥ä¸­å‘ç° {num_nan_rows} è¡Œ NaN å€¼ã€‚å°†ç§»é™¤å®ƒä»¬ã€‚\")\n",
    "            X_saprot_np = X_saprot_np[~nan_rows_mask_train]\n",
    "            sampled_train_df_saprot = sampled_train_df_saprot[~nan_rows_mask_train]\n",
    "            print(f\"  ç§»é™¤ NaN åï¼Œå‰©ä½™è®­ç»ƒæ•°æ®: {len(sampled_train_df_saprot)} æ¡\")\n",
    "\n",
    "        if X_saprot_np.shape[0] > 0 and X_saprot_np.shape[0] == len(sampled_train_df_saprot):\n",
    "            X_saprot = X_saprot_np\n",
    "            y_saprot = sampled_train_df_saprot['Brightness'].values\n",
    "            print(f\"  å‡†å¤‡å¥½çš„ X_saprot (åµŒå…¥) å½¢çŠ¶: {X_saprot.shape}, y_saprot (äº®åº¦) å½¢çŠ¶: {y_saprot.shape}\")\n",
    "        else:\n",
    "            print(\"  é”™è¯¯: å¤„ç† NaN æˆ–åµŒå…¥å¤±è´¥åï¼ŒX å’Œ y æ•°æ®ä¸åŒ¹é…æˆ–ä¸ºç©ºã€‚\")\n",
    "    else:\n",
    "        print(\"  è­¦å‘Š: æœªèƒ½æˆåŠŸä¸ºè®­ç»ƒæ•°æ®ç”Ÿæˆ SaProt åµŒå…¥ã€‚\")\n",
    "else:\n",
    "    print(\"  æ²¡æœ‰æ‰¾åˆ°ç”¨äºç”ŸæˆåµŒå…¥çš„è®­ç»ƒåºåˆ—ã€‚\")\n",
    "\n",
    "if X_saprot is None or y_saprot is None:\n",
    "    print(\"!!! é”™è¯¯: æœªèƒ½å‡†å¤‡ SaProt è®­ç»ƒæ•°æ® (X_saprot æˆ– y_saprot ä¸ºç©º)ã€‚åç»­æ­¥éª¤å¯èƒ½å¤±è´¥ã€‚\")\n",
    "\n",
    "\n",
    "# === 7. ä½¿ç”¨ SaProt åµŒå…¥è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹ ===\n",
    "print(\"\\n[æ­¥éª¤ 5/9] æ­£åœ¨ä½¿ç”¨ SaProt åµŒå…¥è®­ç»ƒéšæœºæ£®æ—å›å½’å™¨...\")\n",
    "rf_model_saprot = None # åˆå§‹åŒ–æ¨¡å‹å˜é‡\n",
    "if X_saprot is not None and y_saprot is not None and X_saprot.shape[0] > 0:\n",
    "    if len(X_saprot) > 10:\n",
    "        X_train_saprot, X_val_saprot, y_train_saprot, y_val_saprot = train_test_split(\n",
    "            X_saprot, y_saprot, test_size=0.2, random_state=SEED\n",
    "        )\n",
    "        print(f\"  å·²å°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›† ({len(X_train_saprot)}) å’ŒéªŒè¯é›† ({len(X_val_saprot)})ã€‚\")\n",
    "    else:\n",
    "        print(\"  æ•°æ®é›†è¿‡å°ï¼Œæ— æ³•è¿›è¡ŒéªŒè¯åˆ†å‰²ï¼Œå°†ä½¿ç”¨æ‰€æœ‰æ•°æ®è¿›è¡Œè®­ç»ƒã€‚\")\n",
    "        X_train_saprot, y_train_saprot = X_saprot, y_saprot\n",
    "        X_val_saprot, y_val_saprot = None, None\n",
    "\n",
    "    rf_model_saprot = RandomForestRegressor(\n",
    "        n_estimators=100, random_state=SEED, n_jobs=-1, max_depth=20,\n",
    "        min_samples_leaf=3, oob_score=(X_val_saprot is None)\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    print(\"  å¼€å§‹è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...\")\n",
    "    rf_model_saprot.fit(X_train_saprot, y_train_saprot)\n",
    "    print(f\"  éšæœºæ£®æ—è®­ç»ƒå®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.2f} ç§’ã€‚\")\n",
    "\n",
    "    # æ¨¡å‹è¯„ä¼°\n",
    "    if X_val_saprot is not None and y_val_saprot is not None:\n",
    "        y_pred_val_saprot = rf_model_saprot.predict(X_val_saprot)\n",
    "        r2_saprot_val = r2_score(y_val_saprot, y_pred_val_saprot)\n",
    "        print(f\"  åŸºäº SaProt çš„æ¨¡å‹åœ¨ã€éªŒè¯é›†ã€‘ä¸Šçš„ RÂ² åˆ†æ•°: {r2_saprot_val:.4f}\")\n",
    "    elif hasattr(rf_model_saprot, 'oob_score_') and rf_model_saprot.oob_score_:\n",
    "         print(f\"  åŸºäº SaProt çš„æ¨¡å‹è¢‹å¤– (OOB) RÂ² åˆ†æ•°: {rf_model_saprot.oob_score_:.4f}\")\n",
    "    else:\n",
    "        y_pred_train_saprot = rf_model_saprot.predict(X_train_saprot)\n",
    "        r2_saprot_train = r2_score(y_train_saprot, y_pred_train_saprot)\n",
    "        print(f\"  åŸºäº SaProt çš„æ¨¡å‹åœ¨ã€è®­ç»ƒé›†ã€‘ä¸Šçš„ RÂ² åˆ†æ•°: {r2_saprot_train:.4f} (æ³¨æ„: å¯èƒ½åé«˜)\")\n",
    "else:\n",
    "    print(\"  ç”±äºä¹‹å‰çš„æ­¥éª¤æœªèƒ½æˆåŠŸå‡†å¤‡ X_saprot å’Œ y_saprotï¼Œè·³è¿‡æ¨¡å‹è®­ç»ƒã€‚\")\n",
    "\n",
    "\n",
    "# === 8. ç”Ÿæˆå€™é€‰åºåˆ— ===\n",
    "print(f\"\\n[æ­¥éª¤ 6/9] æ­£åœ¨ç”Ÿæˆ {N_CANDIDATES_TO_GENERATE} ä¸ªå€™é€‰åºåˆ—...\")\n",
    "candidate_sequences_saprot = {}\n",
    "generated_count = 0\n",
    "attempts = 0\n",
    "max_attempts = N_CANDIDATES_TO_GENERATE * 10\n",
    "start_time_gen = time.time()\n",
    "\n",
    "# !!! ç¡®ä¿ generate_single_candidate å‡½æ•°åœ¨æ­¤ä½œç”¨åŸŸå¯ç”¨ !!!\n",
    "if 'generate_single_candidate' not in globals() and 'generate_single_candidate' not in locals():\n",
    "     raise NameError(\"å‡½æ•° 'generate_single_candidate' æœªå®šä¹‰ã€‚è¯·ç¡®ä¿å®ƒåœ¨ä¹‹å‰çš„å•å…ƒæ ¼ä¸­å·²è¿è¡Œã€‚\")\n",
    "\n",
    "while generated_count < N_CANDIDATES_TO_GENERATE and attempts < max_attempts:\n",
    "    attempts += 1\n",
    "    try:\n",
    "        seq, mut_str = generate_single_candidate(\n",
    "            avGFP_WT_sequence, candidate_position_pool_0based, MAX_MUTATIONS\n",
    "        )\n",
    "        if seq not in candidate_sequences_saprot and seq != avGFP_WT_sequence:\n",
    "            candidate_sequences_saprot[seq] = mut_str\n",
    "            generated_count += 1\n",
    "            if generated_count % max(1, N_CANDIDATES_TO_GENERATE // 10) == 0 or generated_count == N_CANDIDATES_TO_GENERATE :\n",
    "                 print(f\"  å·²ç”Ÿæˆ {generated_count}/{N_CANDIDATES_TO_GENERATE} ä¸ªå”¯ä¸€å€™é€‰åºåˆ—...\")\n",
    "    except Exception as gen_err:\n",
    "        print(f\"ç”Ÿæˆå€™é€‰åºåˆ—æ—¶å‡ºé”™ (å°è¯• {attempts}): {gen_err}\")\n",
    "        # å¯ä»¥é€‰æ‹©ç»§ç»­æˆ–åœæ­¢\n",
    "        # break\n",
    "\n",
    "gen_duration = time.time() - start_time_gen\n",
    "if generated_count < N_CANDIDATES_TO_GENERATE:\n",
    "    print(f\"  è­¦å‘Š: å°è¯• {attempts} æ¬¡åï¼Œä»…ç”Ÿæˆäº† {generated_count} ä¸ªç‹¬ç‰¹çš„å€™é€‰åºåˆ— (ç›®æ ‡ {N_CANDIDATES_TO_GENERATE})ã€‚\")\n",
    "else:\n",
    "    print(f\"  æˆåŠŸç”Ÿæˆ {generated_count} ä¸ªç‹¬ç‰¹çš„å€™é€‰åºåˆ—ã€‚\")\n",
    "print(f\"  å€™é€‰åºåˆ—ç”Ÿæˆè€—æ—¶: {gen_duration:.2f} ç§’ã€‚\")\n",
    "\n",
    "candidate_list_saprot = list(candidate_sequences_saprot.keys())\n",
    "mutation_list_saprot = [candidate_sequences_saprot[seq] for seq in candidate_list_saprot]\n",
    "\n",
    "\n",
    "# === 9. ä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ SaProt åµŒå…¥ ===\n",
    "print(\"\\n[æ­¥éª¤ 7/9] æ­£åœ¨ä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ SaProt åµŒå…¥...\")\n",
    "candidate_embeddings_saprot_np = np.array([]) # åˆå§‹åŒ–\n",
    "if candidate_list_saprot:\n",
    "    print(f\"  å°†ä¸º {len(candidate_list_saprot)} ä¸ªå€™é€‰åºåˆ—ç”ŸæˆåµŒå…¥ã€‚\")\n",
    "    candidate_embeddings_saprot_tensor = get_saprot_embeddings(\n",
    "        candidate_list_saprot, saprot_model, saprot_tokenizer, DEVICE_SAPROT,\n",
    "        batch_size=SAPROT_BATCH_SIZE, use_compile=use_torch_compile\n",
    "    )\n",
    "    if candidate_embeddings_saprot_tensor.numel() > 0:\n",
    "        print(f\"  ç”Ÿæˆçš„å€™é€‰åºåˆ—åµŒå…¥å¼ é‡å½¢çŠ¶: {candidate_embeddings_saprot_tensor.shape}\")\n",
    "        candidate_embeddings_saprot_np = candidate_embeddings_saprot_tensor.numpy()\n",
    "        # å¤„ç† NaN\n",
    "        nan_mask_candidates = np.isnan(candidate_embeddings_saprot_np).any(axis=1)\n",
    "        if np.any(nan_mask_candidates):\n",
    "            num_nan_candidates = nan_mask_candidates.sum()\n",
    "            print(f\"  è­¦å‘Š: åœ¨å€™é€‰åµŒå…¥ä¸­å‘ç° {num_nan_candidates} ä¸ª NaN å€¼ã€‚å°†ç§»é™¤å®ƒä»¬ã€‚\")\n",
    "            original_count = len(candidate_list_saprot)\n",
    "            valid_indices = ~nan_mask_candidates\n",
    "            candidate_embeddings_saprot_np = candidate_embeddings_saprot_np[valid_indices]\n",
    "            # ç¡®ä¿åˆ—è¡¨ä¹Ÿä½¿ç”¨ç›¸åŒçš„å¸ƒå°”ç´¢å¼•æˆ–ç­‰æ•ˆé€»è¾‘è¿›è¡Œè¿‡æ»¤\n",
    "            candidate_list_saprot = [seq for i, seq in enumerate(candidate_list_saprot) if valid_indices[i]]\n",
    "            mutation_list_saprot = [mut for i, mut in enumerate(mutation_list_saprot) if valid_indices[i]]\n",
    "            print(f\"  ç§»é™¤äº† {original_count - len(candidate_list_saprot)} ä¸ªå›  NaN åµŒå…¥è¢«ç§»é™¤çš„å€™é€‰åºåˆ—ã€‚\")\n",
    "            print(f\"  å‰©ä½™æœ‰æ•ˆå€™é€‰åºåˆ—æ•°é‡: {len(candidate_list_saprot)}\")\n",
    "            if candidate_embeddings_saprot_np.shape[0] > 0:\n",
    "                print(f\"  è¿‡æ»¤åçš„å€™é€‰åµŒå…¥å½¢çŠ¶: {candidate_embeddings_saprot_np.shape}\")\n",
    "            else:\n",
    "                print(\"  è¿‡æ»¤åæ²¡æœ‰å‰©ä½™çš„æœ‰æ•ˆå€™é€‰åµŒå…¥ã€‚\")\n",
    "    else:\n",
    "        print(\"  è­¦å‘Š: æœªèƒ½æˆåŠŸä¸ºå€™é€‰åºåˆ—ç”Ÿæˆ SaProt åµŒå…¥ã€‚\")\n",
    "else:\n",
    "    print(\"  ä¸Šä¸€æ­¥æœªèƒ½ç”Ÿæˆä»»ä½•å€™é€‰åºåˆ—ï¼Œè·³è¿‡åµŒå…¥æ­¥éª¤ã€‚\")\n",
    "\n",
    "if candidate_embeddings_saprot_np.shape[0] == 0 and candidate_list_saprot:\n",
    "    print(\"!!! é”™è¯¯: æœ‰å€™é€‰åºåˆ—ä½†æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åµŒå…¥ã€‚åç»­æ­¥éª¤å°†å¤±è´¥ã€‚\")\n",
    "\n",
    "\n",
    "# === 10. é¢„æµ‹å€™é€‰åºåˆ—çš„äº®åº¦ ===\n",
    "print(\"\\n[æ­¥éª¤ 8/9] æ­£åœ¨ä½¿ç”¨åŸºäº SaProt çš„éšæœºæ£®æ—æ¨¡å‹é¢„æµ‹å€™é€‰åºåˆ—çš„äº®åº¦...\")\n",
    "predicted_brightness_saprot = [] # ä¿æŒåˆå§‹åŒ–ä¸ºåˆ—è¡¨\n",
    "if rf_model_saprot is not None and candidate_embeddings_saprot_np.shape[0] > 0:\n",
    "    if len(candidate_list_saprot) == candidate_embeddings_saprot_np.shape[0]:\n",
    "        try:\n",
    "            start_time_pred = time.time()\n",
    "            # .predict() è¿”å› NumPy array\n",
    "            predicted_brightness_saprot = rf_model_saprot.predict(candidate_embeddings_saprot_np)\n",
    "            pred_duration = time.time() - start_time_pred\n",
    "            print(f\"  äº®åº¦é¢„æµ‹å®Œæˆï¼Œè€—æ—¶ {pred_duration:.2f} ç§’ã€‚\")\n",
    "            print(f\"  æˆåŠŸé¢„æµ‹äº† {len(predicted_brightness_saprot)} ä¸ªå€™é€‰åºåˆ—çš„äº®åº¦ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ä½¿ç”¨ SaProt éšæœºæ£®æ—æ¨¡å‹è¿›è¡Œé¢„æµ‹æ—¶å‡ºé”™: {e}\")\n",
    "            predicted_brightness_saprot = [] # å‡ºé”™æ—¶é‡ç½®ä¸ºç©ºåˆ—è¡¨\n",
    "    else:\n",
    "        print(f\"  é”™è¯¯: å€™é€‰åºåˆ—åˆ—è¡¨ ({len(candidate_list_saprot)}) ä¸å…¶åµŒå…¥ ({candidate_embeddings_saprot_np.shape[0]}) æ•°é‡ä¸åŒ¹é…ã€‚æ— æ³•é¢„æµ‹ã€‚\")\n",
    "elif rf_model_saprot is None:\n",
    "     print(\"  éšæœºæ£®æ—æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•é¢„æµ‹ã€‚\")\n",
    "elif not candidate_list_saprot:\n",
    "     print(\"  æ²¡æœ‰å€™é€‰åºåˆ—å¯ä¾›é¢„æµ‹ã€‚\")\n",
    "elif candidate_embeddings_saprot_np.shape[0] == 0:\n",
    "     print(\"  æ²¡æœ‰æœ‰æ•ˆçš„å€™é€‰åºåˆ— SaProt åµŒå…¥å¯ç”¨äºé¢„æµ‹ã€‚\")\n",
    "\n",
    "\n",
    "# === 11. è¿‡æ»¤ã€é€‰æ‹© Top N å€™é€‰å¹¶ä¿å­˜ç»“æœ ===\n",
    "print(\"\\n[æ­¥éª¤ 9/9] æ­£åœ¨è¿‡æ»¤ã€é€‰æ‹© Top N å€™é€‰åºåˆ—å¹¶ä¿å­˜ç»“æœ...\")\n",
    "final_candidates_saprot_formatted = pd.DataFrame() # åˆå§‹åŒ–\n",
    "\n",
    "# --- FIX: ä½¿ç”¨ len() æ£€æŸ¥ predicted_brightness_saprot ---\n",
    "if candidate_list_saprot and len(predicted_brightness_saprot) > 0 and len(candidate_list_saprot) == len(predicted_brightness_saprot):\n",
    "# --- End FIX ---\n",
    "    results_saprot_df = pd.DataFrame({\n",
    "        'Sequence': candidate_list_saprot,\n",
    "        'Mutations': mutation_list_saprot,\n",
    "        'PredictedBrightness_SaProt': predicted_brightness_saprot # NumPy array å¯ä»¥ç›´æ¥æ”¾å…¥DataFrame\n",
    "    })\n",
    "    print(f\"  å·²åˆ›å»ºåŒ…å« {len(results_saprot_df)} ä¸ªå€™é€‰åºåˆ—åŠå…¶é¢„æµ‹äº®åº¦çš„ DataFrameã€‚\")\n",
    "\n",
    "    # è¿‡æ»¤æ’é™¤åˆ—è¡¨\n",
    "    exclusion_set = set(exclusion_sequences)\n",
    "    initial_candidate_count = len(results_saprot_df)\n",
    "    print(f\"  æ­£åœ¨æ ¹æ®æ’é™¤åˆ—è¡¨ ({len(exclusion_set)} æ¡) è¿›è¡Œè¿‡æ»¤...\")\n",
    "    results_saprot_df = results_saprot_df[~results_saprot_df['Sequence'].isin(exclusion_set)]\n",
    "    removed_count = initial_candidate_count - len(results_saprot_df)\n",
    "    if removed_count > 0: print(f\"  ç§»é™¤äº† {removed_count} ä¸ªåœ¨æ’é™¤åˆ—è¡¨ä¸­çš„åºåˆ—ã€‚\")\n",
    "    else: print(\"  å€™é€‰åºåˆ—å‡ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ã€‚\")\n",
    "    print(f\"  è¿‡æ»¤åå‰©ä½™å€™é€‰åºåˆ—: {len(results_saprot_df)} æ¡ã€‚\")\n",
    "\n",
    "    if not results_saprot_df.empty:\n",
    "        results_saprot_df = results_saprot_df.sort_values(by='PredictedBrightness_SaProt', ascending=False)\n",
    "        final_candidates_saprot = results_saprot_df.head(TOP_N_SELECT).copy()\n",
    "        num_selected = len(final_candidates_saprot)\n",
    "        print(f\"\\n  ç­›é€‰å‡ºçš„ Top {num_selected} (æœ€å¤š {TOP_N_SELECT}) ä¸ª SaProt é¢„æµ‹å€™é€‰ (å·²æ’é™¤):\")\n",
    "\n",
    "        if num_selected > 0:\n",
    "            final_candidates_saprot.insert(0, 'Sequence ID', [f'SaProt_Candidate_{i+1}' for i in range(num_selected)])\n",
    "            final_candidates_saprot_formatted = final_candidates_saprot[['Sequence ID', 'Mutations', 'Sequence', 'PredictedBrightness_SaProt']]\n",
    "\n",
    "            print(\"--- SaProt Top Candidates ---\")\n",
    "            display(final_candidates_saprot_formatted)\n",
    "            print(\"----------------------------\")\n",
    "\n",
    "            submission_df_saprot = final_candidates_saprot_formatted[['Sequence ID', 'Mutations', 'Sequence']].copy()\n",
    "            output_filename_saprot = \"my_top_saprot_candidates.csv\"\n",
    "            try:\n",
    "                submission_df_saprot.to_csv(output_filename_saprot, index=False)\n",
    "                print(f\"\\n  å·²æˆåŠŸå°† Top {len(submission_df_saprot)} ä¸ª SaProt å€™é€‰åºåˆ—ä¿å­˜åˆ°æ–‡ä»¶: {output_filename_saprot}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n  ä¿å­˜ç»“æœåˆ° CSV æ–‡ä»¶æ—¶å‡ºé”™: {e}\")\n",
    "        else:\n",
    "            print(\"  ç»è¿‡æ»¤å’Œæ’åºåï¼Œæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ Top N SaProt å€™é€‰åºåˆ—ã€‚\")\n",
    "    else:\n",
    "        print(\"  æ ¹æ®æ’é™¤åˆ—è¡¨è¿‡æ»¤åï¼Œæ²¡æœ‰å‰©ä½™çš„å€™é€‰åºåˆ—ã€‚\")\n",
    "\n",
    "# --- æ›´æ–°è¿™é‡Œçš„ elif æ¡ä»¶ä»¥åŒ¹é… if ---\n",
    "elif not candidate_list_saprot:\n",
    "     print(\"  ç”±äºæ²¡æœ‰ç”Ÿæˆæˆ–æœ‰æ•ˆè¿‡æ»¤å€™é€‰åºåˆ—ï¼Œæ— æ³•è¿›è¡Œæœ€ç»ˆé€‰æ‹©å’Œä¿å­˜ã€‚\")\n",
    "elif not (len(predicted_brightness_saprot) > 0): # åŒ¹é… if æ¡ä»¶çš„æ£€æŸ¥æ–¹å¼\n",
    "     print(\"  ç”±äº SaProt äº®åº¦é¢„æµ‹å¤±è´¥æˆ–æœªäº§ç”Ÿç»“æœ (predicted_brightness_saprot ä¸ºç©º)ï¼Œæ— æ³•è¿›è¡Œæœ€ç»ˆé€‰æ‹©å’Œä¿å­˜ã€‚\")\n",
    "else: # è¿™ä¸ªåˆ†æ”¯å¯¹åº” len(candidate_list_saprot) != len(predicted_brightness_saprot)\n",
    "     print(\"  é”™è¯¯: æœ€ç»ˆå€™é€‰åºåˆ—åˆ—è¡¨ä¸é¢„æµ‹ç»“æœæ•°é‡ä¸åŒ¹é…ã€‚æ— æ³•è¿›è¡Œæœ€ç»ˆé€‰æ‹©å’Œä¿å­˜ã€‚\")\n",
    "\n",
    "\n",
    "# === 12. æ¸…ç†å†…å­˜ (å¯é€‰) ===\n",
    "# print(\"\\n--- æ­£åœ¨æ¸…ç† SaProt æ¨¡å‹å’Œç›¸å…³å¼ é‡ä»¥é‡Šæ”¾å†…å­˜ ---\")\n",
    "# try:\n",
    "#     # Safely delete variables if they exist\n",
    "#     vars_to_delete = ['saprot_model', 'saprot_tokenizer', 'rf_model_saprot',\n",
    "#                       'X_saprot_tensor', 'X_saprot', 'y_saprot',\n",
    "#                       'X_train_saprot', 'y_train_saprot', 'X_val_saprot', 'y_val_saprot',\n",
    "#                       'candidate_embeddings_saprot_tensor', 'candidate_embeddings_saprot_np',\n",
    "#                       'results_saprot_df', 'final_candidates_saprot', 'final_candidates_saprot_formatted',\n",
    "#                       'submission_df_saprot']\n",
    "#     for var_name in vars_to_delete:\n",
    "#         # Use try-except for deletion as variables might be local or global\n",
    "#         try:\n",
    "#             if var_name in locals(): del locals()[var_name]\n",
    "#             if var_name in globals(): del globals()[var_name]\n",
    "#         except NameError:\n",
    "#             pass # Variable already deleted or never existed\n",
    "\n",
    "#     # å¦‚æœä½¿ç”¨äº† GPUï¼Œæ¸…ç©º PyTorch çš„ CUDA ç¼“å­˜\n",
    "#     if DEVICE_SAPROT == torch.device(\"cuda\"):\n",
    "#         print(\"  æ­£åœ¨æ¸…ç©º CUDA ç¼“å­˜...\")\n",
    "#         torch.cuda.empty_cache()\n",
    "#     print(\"å†…å­˜æ¸…ç†å®Œæˆã€‚\")\n",
    "# except Exception as e:\n",
    "#     print(f\"æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- SaProt å·¥ä½œæµç¨‹ç»“æŸ ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604ad8a-07b8-48d0-b745-67c6ac1bebc0",
   "metadata": {},
   "source": [
    "å¸Œæœ›è¿™ä¸ªåˆ†æ­¥è®²è§£èƒ½å¸®åŠ©å¤§å®¶ç†è§£æ•´ä¸ªæµç¨‹ï¼ç¥å¤§å®¶åœ¨è›‹ç™½è´¨è®¾è®¡çš„æ¢ç´¢ä¸­ç©å¾—å¼€å¿ƒï¼Œå¹¶åœ¨æ¯”èµ›ä¸­å–å¾—å¥½æˆç»©ï¼âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
