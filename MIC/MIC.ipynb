{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9657ee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始GRAMPA数据集预处理流程...\n",
      "正在加载数据...\n",
      "数据集形状: (44797, 6)\n",
      "列名: ['bacterium', 'sequence', 'unit', 'value', 'censor', 'database']\n",
      "缺失值统计:\n",
      "bacterium       84\n",
      "sequence         0\n",
      "unit             0\n",
      "value            0\n",
      "censor       43932\n",
      "database         0\n",
      "dtype: int64\n",
      "\n",
      "数据类型:\n",
      "bacterium     object\n",
      "sequence      object\n",
      "unit          object\n",
      "value        float64\n",
      "censor        object\n",
      "database      object\n",
      "dtype: object\n",
      "\n",
      "value字段统计:\n",
      "count    44797.000000\n",
      "mean         0.105690\n",
      "std          0.539219\n",
      "min         -3.558834\n",
      "25%         -0.151399\n",
      "50%          0.098738\n",
      "75%          0.267724\n",
      "max          3.657577\n",
      "Name: value, dtype: float64\n",
      "\n",
      "censor字段统计:\n",
      "censor\n",
      "NaN    43932\n",
      ">        865\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== 步骤1: 序列合法化 ===\n",
      "原始样本数: 44797\n",
      "空序列样本数: 0\n",
      "X占比>10%的样本数: 222\n",
      "长度<5的样本数: 680\n",
      "长度5-48的样本数: 42840\n",
      "长度>48的样本数: 1277\n",
      "主训练集样本数: 42626\n",
      "短肽样本数: 672\n",
      "长肽样本数: 1277\n",
      "排除样本数: 222\n",
      "\n",
      "=== 步骤2: 菌株归一化 ===\n",
      "唯一菌株数: 1025\n",
      "Top 10菌株:\n",
      "normalized_bacterium\n",
      "escherichia_coli              7795\n",
      "staphylococcus_aureus         7329\n",
      "pseudomonas_aeruginosa        4170\n",
      "candida_albicans              2664\n",
      "bacillus_subtilis             2179\n",
      "staphylococcus_epidermidis    1242\n",
      "salmonella_typhimurium         973\n",
      "klebsiella_pneumoniae          972\n",
      "micrococcus_luteus             965\n",
      "enterococcus_faecalis          942\n",
      "Name: count, dtype: int64\n",
      "低频菌株数（<10次）: 757\n",
      "最终菌株数: 269\n",
      "归为other的样本数: 2022\n",
      "\n",
      "=== 步骤3: 重复测定处理 ===\n",
      "唯一(sequence, bacterium)对数: 31545\n",
      "重复测定统计:\n",
      "1     24514\n",
      "2      4473\n",
      "3      1636\n",
      "4       685\n",
      "5       146\n",
      "6        20\n",
      "7        24\n",
      "8        11\n",
      "9        14\n",
      "10        9\n",
      "11        2\n",
      "12        3\n",
      "13        2\n",
      "14        1\n",
      "16        1\n",
      "17        1\n",
      "18        1\n",
      "23        1\n",
      "24        1\n",
      "Name: count, dtype: int64\n",
      "最大重复次数: 24\n",
      "聚合后样本数: 31545\n",
      "平均重复测定次数: 1.35\n",
      "删失样本数: 733\n",
      "完全删失样本数: 538\n",
      "\n",
      "=== 步骤4: 删失样本处理（改进版） ===\n",
      "包含删失信息的样本数: 733\n",
      "完全删失样本数: 538\n",
      "删失样本占比: 2.32%\n",
      "删失阈值分布:\n",
      "  - 最小删失阈值: 0.907\n",
      "  - 最大删失阈值: 2.907\n",
      "  - 平均删失阈值: 1.840\n",
      "警告: 194个样本的聚合值低于删失阈值（数据不一致）\n",
      "\n",
      "=== 步骤5: 异常值稳健化 ===\n",
      "原始value范围: [-3.222, 3.180]\n",
      "Winsorize范围 (1%-99%): [-1.101, 1.920]\n",
      "被调整的样本数: 低端270个, 高端313个\n",
      "\n",
      "=== 创建序列聚合数据集 ===\n",
      "序列聚合数据集样本数: 7055\n",
      "\n",
      "=== 步骤6: 数据划分（改进版GroupKFold） ===\n",
      "唯一序列数: 7055\n",
      "各菌株的序列数分布 (Top 10):\n",
      "escherichia_coli           1812\n",
      "bacillus_subtilis          1148\n",
      "candida_albicans            872\n",
      "bacillus_cereus             292\n",
      "acinetobacter_baumannii     290\n",
      "pseudomonas_aeruginosa      252\n",
      "staphylococcus_aureus       178\n",
      "enterococcus_faecalis       147\n",
      "e._amylovora                122\n",
      "bacillus_megaterium         118\n",
      "Name: count, dtype: int64\n",
      "高频菌株数 (>=50序列): 16\n",
      "中频菌株数 (10-49序列): 50\n",
      "低频菌株数 (<10序列): 82\n",
      "训练集序列数: 4966\n",
      "验证集序列数: 706\n",
      "测试集序列数: 1383\n",
      "各split统计:\n",
      "      sequence bacterium value_winsorized       \n",
      "         count   nunique             mean    std\n",
      "split                                           \n",
      "test      6054       257            0.116  0.479\n",
      "train    22427       269            0.095  0.476\n",
      "val       3064       248            0.101  0.486\n",
      "\n",
      "各split菌株分布平衡性检查:\n",
      "train集 Top 5菌株: {'escherichia_coli': 3561, 'staphylococcus_aureus': 3244, 'pseudomonas_aeruginosa': 2025, 'candida_albicans': 1287, 'bacillus_subtilis': 1045}\n",
      "val集 Top 5菌株: {'escherichia_coli': 508, 'staphylococcus_aureus': 477, 'pseudomonas_aeruginosa': 278, 'candida_albicans': 184, 'bacillus_subtilis': 140}\n",
      "test集 Top 5菌株: {'escherichia_coli': 1000, 'staphylococcus_aureus': 888, 'pseudomonas_aeruginosa': 529, 'candida_albicans': 355, 'bacillus_subtilis': 297}\n",
      "\n",
      "=== 保存数据集 ===\n",
      "完整聚合数据集已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_aggregated_full.csv\n",
      "序列聚合数据集已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_aggregated.csv\n",
      "train集（条件回归）已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_conditional_train.csv (22427 样本)\n",
      "train集（序列回归）已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_train.csv (4966 样本)\n",
      "val集（条件回归）已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_conditional_val.csv (3064 样本)\n",
      "val集（序列回归）已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_val.csv (706 样本)\n",
      "test集（条件回归）已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_conditional_test.csv (6054 样本)\n",
      "test集（序列回归）已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_test.csv (1383 样本)\n",
      "其他长度数据集已保存: /root/NKU-TMU_AMP_project/processed_data/grampa_other_lengths.csv (1949 样本)\n",
      "处理报告已保存: /root/NKU-TMU_AMP_project/processed_data/processing_report.md\n",
      "\n",
      "数据预处理完成！\n",
      "所有文件已保存到: /root/NKU-TMU_AMP_project/processed_data\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "GRAMPA数据集预处理脚本\n",
    "根据筛选器设计.md的要求进行数据清洗与标准化\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class GRAMPAPreprocessor:\n",
    "    def __init__(self, input_file, output_dir='processed_data'):\n",
    "        self.input_file = input_file\n",
    "        self.output_dir = output_dir\n",
    "        self.df = None\n",
    "        self.processed_df = None\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 标准氨基酸字母表\n",
    "        self.standard_aa = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "        \n",
    "        # 菌株名称标准化映射\n",
    "        self.bacteria_mapping = {\n",
    "            'escherichia coli': 'escherichia_coli',\n",
    "            'e. coli': 'escherichia_coli',\n",
    "            'e.coli': 'escherichia_coli',\n",
    "            'staphylococcus aureus': 'staphylococcus_aureus',\n",
    "            'staph. aureus': 'staphylococcus_aureus',\n",
    "            's. aureus': 'staphylococcus_aureus',\n",
    "            's.aureus': 'staphylococcus_aureus',\n",
    "            'pseudomonas aeruginosa': 'pseudomonas_aeruginosa',\n",
    "            'p. aeruginosa': 'pseudomonas_aeruginosa',\n",
    "            'p.aeruginosa': 'pseudomonas_aeruginosa',\n",
    "            'klebsiella pneumoniae': 'klebsiella_pneumoniae',\n",
    "            'k. pneumoniae': 'klebsiella_pneumoniae',\n",
    "            'k.pneumoniae': 'klebsiella_pneumoniae',\n",
    "            'candida albicans': 'candida_albicans',\n",
    "            'c. albicans': 'candida_albicans',\n",
    "            'c.albicans': 'candida_albicans',\n",
    "            'bacillus subtilis': 'bacillus_subtilis',\n",
    "            'b. subtilis': 'bacillus_subtilis',\n",
    "            'enterococcus faecalis': 'enterococcus_faecalis',\n",
    "            'e. faecalis': 'enterococcus_faecalis',\n",
    "            'streptococcus pyogenes': 'streptococcus_pyogenes',\n",
    "            's. pyogenes': 'streptococcus_pyogenes',\n",
    "        }\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"加载数据并进行基本分析\"\"\"\n",
    "        print(\"正在加载数据...\")\n",
    "        self.df = pd.read_csv(self.input_file)\n",
    "        \n",
    "        print(f\"数据集形状: {self.df.shape}\")\n",
    "        print(f\"列名: {self.df.columns.tolist()}\")\n",
    "        print(f\"缺失值统计:\")\n",
    "        print(self.df.isnull().sum())\n",
    "        print(f\"\\n数据类型:\")\n",
    "        print(self.df.dtypes)\n",
    "        print(f\"\\nvalue字段统计:\")\n",
    "        print(self.df['value'].describe())\n",
    "        print(f\"\\ncensor字段统计:\")\n",
    "        print(self.df['censor'].value_counts(dropna=False))\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def normalize_sequence(self, sequence):\n",
    "        \"\"\"序列合法化处理\"\"\"\n",
    "        if pd.isna(sequence):\n",
    "            return None, 1.0  # 返回序列和X占比\n",
    "            \n",
    "        # 转为大写\n",
    "        seq = str(sequence).upper().strip()\n",
    "        \n",
    "        # 移除非字母字符（空格、标点等）\n",
    "        seq = re.sub(r'[^A-Z]', '', seq)\n",
    "        \n",
    "        if len(seq) == 0:\n",
    "            return None, 1.0\n",
    "            \n",
    "        # 将非标准氨基酸映射为X\n",
    "        normalized_seq = ''\n",
    "        for aa in seq:\n",
    "            if aa in self.standard_aa:\n",
    "                normalized_seq += aa\n",
    "            else:\n",
    "                normalized_seq += 'X'\n",
    "        \n",
    "        # 计算X占比\n",
    "        x_ratio = normalized_seq.count('X') / len(normalized_seq) if len(normalized_seq) > 0 else 1.0\n",
    "        \n",
    "        return normalized_seq, x_ratio\n",
    "    \n",
    "    def normalize_bacterium(self, bacterium_name):\n",
    "        \"\"\"菌株名称标准化\"\"\"\n",
    "        if pd.isna(bacterium_name):\n",
    "            return 'unknown'\n",
    "            \n",
    "        name = str(bacterium_name).lower().strip()\n",
    "        \n",
    "        # 移除株系信息（括号内容、数字、特殊符号等）\n",
    "        name = re.sub(r'\\([^)]*\\)', '', name)  # 移除括号内容\n",
    "        name = re.sub(r'\\s+\\d+.*$', '', name)  # 移除数字及后续内容\n",
    "        name = re.sub(r'\\s+strain.*$', '', name, flags=re.IGNORECASE)  # 移除strain信息\n",
    "        name = re.sub(r'\\s+atcc.*$', '', name, flags=re.IGNORECASE)  # 移除ATCC信息\n",
    "        name = name.strip()\n",
    "        \n",
    "        # 标准化映射\n",
    "        if name in self.bacteria_mapping:\n",
    "            return self.bacteria_mapping[name]\n",
    "        \n",
    "        # 对于未映射的，保留属种名\n",
    "        parts = name.split()\n",
    "        if len(parts) >= 2:\n",
    "            genus_species = f\"{parts[0]}_{parts[1]}\"\n",
    "            return genus_species.replace(' ', '_').replace('-', '_')\n",
    "        \n",
    "        return name.replace(' ', '_').replace('-', '_')\n",
    "    \n",
    "    def sequence_cleaning(self):\n",
    "        \"\"\"步骤1: 序列合法化\"\"\"\n",
    "        print(\"\\n=== 步骤1: 序列合法化 ===\")\n",
    "        \n",
    "        # 处理序列\n",
    "        seq_info = self.df['sequence'].apply(self.normalize_sequence)\n",
    "        self.df['normalized_sequence'] = [x[0] for x in seq_info]\n",
    "        self.df['x_ratio'] = [x[1] for x in seq_info]\n",
    "        \n",
    "        # 统计\n",
    "        print(f\"原始样本数: {len(self.df)}\")\n",
    "        \n",
    "        # 移除空序列\n",
    "        valid_seq_mask = self.df['normalized_sequence'].notna()\n",
    "        print(f\"空序列样本数: {(~valid_seq_mask).sum()}\")\n",
    "        \n",
    "        # 移除X占比>10%的序列\n",
    "        x_ratio_mask = self.df['x_ratio'] <= 0.1\n",
    "        print(f\"X占比>10%的样本数: {(~x_ratio_mask).sum()}\")\n",
    "        \n",
    "        # 长度筛选\n",
    "        self.df['seq_length'] = self.df['normalized_sequence'].fillna('').str.len()\n",
    "        length_5_48_mask = (self.df['seq_length'] >= 5) & (self.df['seq_length'] <= 48)\n",
    "        length_lt5_mask = (self.df['seq_length'] > 0) & (self.df['seq_length'] < 5)\n",
    "        length_gt48_mask = self.df['seq_length'] > 48\n",
    "        \n",
    "        print(f\"长度<5的样本数: {length_lt5_mask.sum()}\")\n",
    "        print(f\"长度5-48的样本数: {length_5_48_mask.sum()}\")\n",
    "        print(f\"长度>48的样本数: {length_gt48_mask.sum()}\")\n",
    "        \n",
    "        # 主训练集：5-48 aa，X占比<=10%\n",
    "        main_mask = valid_seq_mask & x_ratio_mask & length_5_48_mask\n",
    "        self.df['dataset_split'] = 'exclude'\n",
    "        self.df.loc[main_mask, 'dataset_split'] = 'main'\n",
    "        self.df.loc[valid_seq_mask & x_ratio_mask & length_lt5_mask, 'dataset_split'] = 'short'\n",
    "        self.df.loc[valid_seq_mask & x_ratio_mask & length_gt48_mask, 'dataset_split'] = 'long'\n",
    "        \n",
    "        print(f\"主训练集样本数: {main_mask.sum()}\")\n",
    "        print(f\"短肽样本数: {(self.df['dataset_split'] == 'short').sum()}\")\n",
    "        print(f\"长肽样本数: {(self.df['dataset_split'] == 'long').sum()}\")\n",
    "        print(f\"排除样本数: {(self.df['dataset_split'] == 'exclude').sum()}\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def bacteria_normalization(self):\n",
    "        \"\"\"步骤2: 菌株归一化\"\"\"\n",
    "        print(\"\\n=== 步骤2: 菌株归一化 ===\")\n",
    "        \n",
    "        # 标准化菌株名\n",
    "        self.df['normalized_bacterium'] = self.df['bacterium'].apply(self.normalize_bacterium)\n",
    "        \n",
    "        # 统计菌株频次\n",
    "        bacteria_counts = self.df['normalized_bacterium'].value_counts()\n",
    "        print(f\"唯一菌株数: {len(bacteria_counts)}\")\n",
    "        print(f\"Top 10菌株:\")\n",
    "        print(bacteria_counts.head(10))\n",
    "        \n",
    "        # 长尾菌株处理（频次<10的归为other）\n",
    "        low_freq_bacteria = bacteria_counts[bacteria_counts < 10].index\n",
    "        print(f\"低频菌株数（<10次）: {len(low_freq_bacteria)}\")\n",
    "        \n",
    "        self.df['final_bacterium'] = self.df['normalized_bacterium'].copy()\n",
    "        self.df.loc[self.df['normalized_bacterium'].isin(low_freq_bacteria), 'final_bacterium'] = 'other'\n",
    "        \n",
    "        final_bacteria_counts = self.df['final_bacterium'].value_counts()\n",
    "        print(f\"最终菌株数: {len(final_bacteria_counts)}\")\n",
    "        print(f\"归为other的样本数: {(self.df['final_bacterium'] == 'other').sum()}\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def handle_duplicates(self):\n",
    "        \"\"\"步骤3: 重复测定处理\"\"\"\n",
    "        print(\"\\n=== 步骤3: 重复测定处理 ===\")\n",
    "        \n",
    "        # 只处理主训练集\n",
    "        main_df = self.df[self.df['dataset_split'] == 'main'].copy()\n",
    "        \n",
    "        # 统计重复情况\n",
    "        duplicate_groups = main_df.groupby(['normalized_sequence', 'final_bacterium'])\n",
    "        duplicate_stats = duplicate_groups.size()\n",
    "        \n",
    "        print(f\"唯一(sequence, bacterium)对数: {len(duplicate_stats)}\")\n",
    "        print(f\"重复测定统计:\")\n",
    "        print(duplicate_stats.value_counts().sort_index())\n",
    "        print(f\"最大重复次数: {duplicate_stats.max()}\")\n",
    "        \n",
    "        # 对每个(sequence, bacterium)组合计算几何均值\n",
    "        def geometric_mean_log(values):\n",
    "            \"\"\"对log值计算几何均值（先转回原值，算几何均值，再取log）\"\"\"\n",
    "            # value是log10(uM)，需要转回uM\n",
    "            original_values = 10 ** values\n",
    "            # 计算几何均值\n",
    "            geom_mean = np.exp(np.mean(np.log(original_values)))\n",
    "            # 转回log10\n",
    "            return np.log10(geom_mean)\n",
    "        \n",
    "        aggregated_data = []\n",
    "        for (seq, bact), group in duplicate_groups:\n",
    "            values = group['value'].values\n",
    "            n_measurements = len(values)\n",
    "            \n",
    "            # 删失信息处理 - 改进版\n",
    "            censor_info = group['censor'].fillna('').values\n",
    "            censored_mask = censor_info == '>'\n",
    "            has_censoring = censored_mask.any()\n",
    "            \n",
    "            # 计算聚合值\n",
    "            if has_censoring:\n",
    "                # 有删失的情况：分别处理删失和非删失值\n",
    "                censored_values = values[censored_mask]\n",
    "                uncensored_values = values[~censored_mask]\n",
    "                \n",
    "                # 删失阈值：删失样本中的最大值作为下界约束\n",
    "                censoring_threshold = censored_values.max() if len(censored_values) > 0 else None\n",
    "                \n",
    "                # 聚合值：只用非删失值计算几何均值\n",
    "                if len(uncensored_values) > 0:\n",
    "                    agg_value = geometric_mean_log(uncensored_values)\n",
    "                else:\n",
    "                    # 全是删失值的情况，用删失阈值作为下界估计\n",
    "                    agg_value = censoring_threshold\n",
    "                    \n",
    "                # 标准差：只用非删失值\n",
    "                value_std = np.std(uncensored_values) if len(uncensored_values) > 1 else 0.0\n",
    "                \n",
    "            else:\n",
    "                # 无删失的情况：正常处理\n",
    "                agg_value = geometric_mean_log(values)\n",
    "                value_std = np.std(values)\n",
    "                censoring_threshold = None\n",
    "            \n",
    "            # 其他信息\n",
    "            database = group['database'].iloc[0]\n",
    "            unit = group['unit'].iloc[0]\n",
    "            seq_length = group['seq_length'].iloc[0]\n",
    "            x_ratio = group['x_ratio'].iloc[0]\n",
    "            \n",
    "            aggregated_data.append({\n",
    "                'sequence': seq,\n",
    "                'bacterium': bact,\n",
    "                'value': agg_value,\n",
    "                'n_measurements': n_measurements,\n",
    "                'n_censored': censored_mask.sum(),\n",
    "                'n_uncensored': (~censored_mask).sum(),\n",
    "                'value_std': value_std,\n",
    "                'has_censoring': has_censoring,\n",
    "                'censoring_threshold': censoring_threshold,  # 删失下界约束\n",
    "                'unit': unit,\n",
    "                'database': database,\n",
    "                'seq_length': seq_length,\n",
    "                'x_ratio': x_ratio\n",
    "            })\n",
    "        \n",
    "        self.aggregated_df = pd.DataFrame(aggregated_data)\n",
    "        print(f\"聚合后样本数: {len(self.aggregated_df)}\")\n",
    "        print(f\"平均重复测定次数: {self.aggregated_df['n_measurements'].mean():.2f}\")\n",
    "        print(f\"删失样本数: {self.aggregated_df['has_censoring'].sum()}\")\n",
    "        print(f\"完全删失样本数: {(self.aggregated_df['n_uncensored'] == 0).sum()}\")\n",
    "        \n",
    "        return self.aggregated_df\n",
    "    \n",
    "    def handle_censoring(self):\n",
    "        \"\"\"步骤4: 删失样本处理 - 改进版\"\"\"\n",
    "        print(\"\\n=== 步骤4: 删失样本处理（改进版） ===\")\n",
    "        \n",
    "        censored_count = self.aggregated_df['has_censoring'].sum()\n",
    "        fully_censored_count = (self.aggregated_df['n_uncensored'] == 0).sum()\n",
    "        \n",
    "        print(f\"包含删失信息的样本数: {censored_count}\")\n",
    "        print(f\"完全删失样本数: {fully_censored_count}\")\n",
    "        print(f\"删失样本占比: {censored_count / len(self.aggregated_df) * 100:.2f}%\")\n",
    "        \n",
    "        # 删失信息统计\n",
    "        if censored_count > 0:\n",
    "            censored_df = self.aggregated_df[self.aggregated_df['has_censoring']]\n",
    "            print(f\"删失阈值分布:\")\n",
    "            print(f\"  - 最小删失阈值: {censored_df['censoring_threshold'].min():.3f}\")\n",
    "            print(f\"  - 最大删失阈值: {censored_df['censoring_threshold'].max():.3f}\")\n",
    "            print(f\"  - 平均删失阈值: {censored_df['censoring_threshold'].mean():.3f}\")\n",
    "            \n",
    "            # 检查删失一致性：聚合值不应低于删失阈值\n",
    "            inconsistent_mask = censored_df['value'] < censored_df['censoring_threshold']\n",
    "            inconsistent_count = inconsistent_mask.sum()\n",
    "            if inconsistent_count > 0:\n",
    "                print(f\"警告: {inconsistent_count}个样本的聚合值低于删失阈值（数据不一致）\")\n",
    "        \n",
    "        # 为损失函数准备删失标记\n",
    "        self.aggregated_df['is_censored'] = self.aggregated_df['has_censoring']\n",
    "        \n",
    "        return self.aggregated_df\n",
    "    \n",
    "    def winsorize_values(self, percentile_range=(1, 99)):\n",
    "        \"\"\"步骤5: 异常值稳健化\"\"\"\n",
    "        print(\"\\n=== 步骤5: 异常值稳健化 ===\")\n",
    "        \n",
    "        values = self.aggregated_df['value']\n",
    "        \n",
    "        # 计算分位数\n",
    "        p_low = np.percentile(values, percentile_range[0])\n",
    "        p_high = np.percentile(values, percentile_range[1])\n",
    "        \n",
    "        print(f\"原始value范围: [{values.min():.3f}, {values.max():.3f}]\")\n",
    "        print(f\"Winsorize范围 ({percentile_range[0]}%-{percentile_range[1]}%): [{p_low:.3f}, {p_high:.3f}]\")\n",
    "        \n",
    "        # Winsorize处理\n",
    "        winsorized_values = np.clip(values, p_low, p_high)\n",
    "        \n",
    "        # 统计影响的样本数\n",
    "        affected_low = (values < p_low).sum()\n",
    "        affected_high = (values > p_high).sum()\n",
    "        print(f\"被调整的样本数: 低端{affected_low}个, 高端{affected_high}个\")\n",
    "        \n",
    "        self.aggregated_df['value_winsorized'] = winsorized_values\n",
    "        self.aggregated_df['value_original'] = values\n",
    "        \n",
    "        return self.aggregated_df\n",
    "    \n",
    "    def create_sequence_aggregated_dataset(self):\n",
    "        \"\"\"创建序列聚合数据集（用于模型A）\"\"\"\n",
    "        print(\"\\n=== 创建序列聚合数据集 ===\")\n",
    "        \n",
    "        # 按序列聚合，计算所有菌株的平均活性\n",
    "        seq_groups = self.aggregated_df.groupby('sequence')\n",
    "        \n",
    "        seq_aggregated_data = []\n",
    "        for seq, group in seq_groups:\n",
    "            # 使用winsorized值计算均值\n",
    "            mean_value = group['value_winsorized'].mean()\n",
    "            std_value = group['value_winsorized'].std()\n",
    "            n_bacteria = len(group)\n",
    "            total_measurements = group['n_measurements'].sum()\n",
    "            \n",
    "            # 序列特征\n",
    "            seq_length = group['seq_length'].iloc[0]\n",
    "            x_ratio = group['x_ratio'].iloc[0]\n",
    "            \n",
    "            # 删失信息\n",
    "            has_any_censoring = group['has_censoring'].any()\n",
    "            \n",
    "            seq_aggregated_data.append({\n",
    "                'sequence': seq,\n",
    "                'mean_log_mic': mean_value,\n",
    "                'std_log_mic': std_value,\n",
    "                'n_bacteria_tested': n_bacteria,\n",
    "                'total_measurements': total_measurements,\n",
    "                'seq_length': seq_length,\n",
    "                'x_ratio': x_ratio,\n",
    "                'has_censoring': has_any_censoring\n",
    "            })\n",
    "        \n",
    "        self.seq_aggregated_df = pd.DataFrame(seq_aggregated_data)\n",
    "        print(f\"序列聚合数据集样本数: {len(self.seq_aggregated_df)}\")\n",
    "        \n",
    "        return self.seq_aggregated_df\n",
    "    \n",
    "    def create_stratified_bacteria_splits(self):\n",
    "        \"\"\"创建按菌株分层的序列分组\"\"\"\n",
    "        # 为每个序列计算主要菌株（出现最多的菌株）\n",
    "        seq_bacteria_mapping = {}\n",
    "        for seq in self.aggregated_df['sequence'].unique():\n",
    "            seq_data = self.aggregated_df[self.aggregated_df['sequence'] == seq]\n",
    "            main_bacterium = seq_data['bacterium'].value_counts().index[0]\n",
    "            seq_bacteria_mapping[seq] = main_bacterium\n",
    "        \n",
    "        return seq_bacteria_mapping\n",
    "    \n",
    "    def create_train_val_test_splits(self, n_splits=5, test_size=0.2, val_size=0.1):\n",
    "        \"\"\"步骤6: 创建数据划分 - 改进版使用真正的GroupKFold\"\"\"\n",
    "        print(\"\\n=== 步骤6: 数据划分（改进版GroupKFold） ===\")\n",
    "        \n",
    "        # 准备序列级数据用于划分\n",
    "        sequences = self.aggregated_df['sequence'].unique()\n",
    "        print(f\"唯一序列数: {len(sequences)}\")\n",
    "        \n",
    "        # 创建序列-主要菌株映射，用于分层\n",
    "        seq_bacteria_mapping = self.create_stratified_bacteria_splits()\n",
    "        \n",
    "        # 统计每个菌株的序列数\n",
    "        bacteria_seq_counts = pd.Series(seq_bacteria_mapping.values()).value_counts()\n",
    "        print(f\"各菌株的序列数分布 (Top 10):\")\n",
    "        print(bacteria_seq_counts.head(10))\n",
    "        \n",
    "        # 为了保证菌株分布平衡，我们使用分层策略\n",
    "        # 首先按菌株频次分组\n",
    "        high_freq_bacteria = bacteria_seq_counts[bacteria_seq_counts >= 50].index  # 高频菌株\n",
    "        medium_freq_bacteria = bacteria_seq_counts[(bacteria_seq_counts >= 10) & (bacteria_seq_counts < 50)].index\n",
    "        low_freq_bacteria = bacteria_seq_counts[bacteria_seq_counts < 10].index\n",
    "        \n",
    "        print(f\"高频菌株数 (>=50序列): {len(high_freq_bacteria)}\")\n",
    "        print(f\"中频菌株数 (10-49序列): {len(medium_freq_bacteria)}\")  \n",
    "        print(f\"低频菌株数 (<10序列): {len(low_freq_bacteria)}\")\n",
    "        \n",
    "        # 分别对每个频次组使用GroupKFold\n",
    "        def stratified_group_split(sequences, bacteria_mapping, test_size, val_size, random_state=42):\n",
    "            \"\"\"按菌株分层的GroupKFold划分\"\"\"\n",
    "            np.random.seed(random_state)\n",
    "            \n",
    "            # 按菌株分组序列\n",
    "            bacteria_sequences = {}\n",
    "            for seq, bacterium in bacteria_mapping.items():\n",
    "                if bacterium not in bacteria_sequences:\n",
    "                    bacteria_sequences[bacterium] = []\n",
    "                bacteria_sequences[bacterium].append(seq)\n",
    "            \n",
    "            train_seqs, val_seqs, test_seqs = [], [], []\n",
    "            \n",
    "            # 对每个菌株的序列进行划分\n",
    "            for bacterium, seqs in bacteria_sequences.items():\n",
    "                seqs = np.array(seqs)\n",
    "                n_seqs = len(seqs)\n",
    "                \n",
    "                if n_seqs == 1:\n",
    "                    # 只有1个序列，随机分配\n",
    "                    split_choice = np.random.choice(['train', 'val', 'test'], p=[1-test_size-val_size, val_size, test_size])\n",
    "                    if split_choice == 'train':\n",
    "                        train_seqs.extend(seqs)\n",
    "                    elif split_choice == 'val':\n",
    "                        val_seqs.extend(seqs)\n",
    "                    else:\n",
    "                        test_seqs.extend(seqs)\n",
    "                elif n_seqs == 2:\n",
    "                    # 2个序列，一个给train，一个随机分配给val或test\n",
    "                    train_seqs.append(seqs[0])\n",
    "                    split_choice = np.random.choice(['val', 'test'])\n",
    "                    if split_choice == 'val':\n",
    "                        val_seqs.append(seqs[1])\n",
    "                    else:\n",
    "                        test_seqs.append(seqs[1])\n",
    "                else:\n",
    "                    # 多个序列，按比例划分\n",
    "                    shuffled = np.random.permutation(seqs)\n",
    "                    n_test = max(1, int(n_seqs * test_size))\n",
    "                    n_val = max(1, int(n_seqs * val_size))\n",
    "                    n_train = n_seqs - n_test - n_val\n",
    "                    \n",
    "                    if n_train < 1:  # 确保至少有1个训练样本\n",
    "                        n_train = 1\n",
    "                        n_test = max(1, n_seqs - n_train - n_val)\n",
    "                        n_val = n_seqs - n_train - n_test\n",
    "                    \n",
    "                    train_seqs.extend(shuffled[:n_train])\n",
    "                    val_seqs.extend(shuffled[n_train:n_train+n_val])\n",
    "                    test_seqs.extend(shuffled[n_train+n_val:])\n",
    "            \n",
    "            return set(train_seqs), set(val_seqs), set(test_seqs)\n",
    "        \n",
    "        # 执行分层划分\n",
    "        train_sequences, val_sequences, test_sequences = stratified_group_split(\n",
    "            sequences, seq_bacteria_mapping, test_size, val_size\n",
    "        )\n",
    "        \n",
    "        print(f\"训练集序列数: {len(train_sequences)}\")\n",
    "        print(f\"验证集序列数: {len(val_sequences)}\")\n",
    "        print(f\"测试集序列数: {len(test_sequences)}\")\n",
    "        \n",
    "        # 验证没有重叠\n",
    "        assert len(train_sequences & val_sequences) == 0, \"训练集和验证集有重叠序列\"\n",
    "        assert len(train_sequences & test_sequences) == 0, \"训练集和测试集有重叠序列\"\n",
    "        assert len(val_sequences & test_sequences) == 0, \"验证集和测试集有重叠序列\"\n",
    "        \n",
    "        # 为聚合数据集添加split标记\n",
    "        def assign_split(seq):\n",
    "            if seq in train_sequences:\n",
    "                return 'train'\n",
    "            elif seq in val_sequences:\n",
    "                return 'val'\n",
    "            else:\n",
    "                return 'test'\n",
    "        \n",
    "        self.aggregated_df['split'] = self.aggregated_df['sequence'].apply(assign_split)\n",
    "        self.seq_aggregated_df['split'] = self.seq_aggregated_df['sequence'].apply(assign_split)\n",
    "        \n",
    "        # 统计每个split的样本数和菌株分布\n",
    "        split_stats = self.aggregated_df.groupby('split').agg({\n",
    "            'sequence': 'count',\n",
    "            'bacterium': 'nunique',\n",
    "            'value_winsorized': ['mean', 'std']\n",
    "        }).round(3)\n",
    "        \n",
    "        print(f\"各split统计:\")\n",
    "        print(split_stats)\n",
    "        \n",
    "        # 检查菌株分布平衡性\n",
    "        print(f\"\\n各split菌株分布平衡性检查:\")\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_bacteria = self.aggregated_df[self.aggregated_df['split'] == split]['bacterium'].value_counts()\n",
    "            print(f\"{split}集 Top 5菌株: {dict(split_bacteria.head(5))}\")\n",
    "        \n",
    "        return train_sequences, val_sequences, test_sequences\n",
    "    \n",
    "    def save_processed_datasets(self):\n",
    "        \"\"\"保存处理后的数据集\"\"\"\n",
    "        print(\"\\n=== 保存数据集 ===\")\n",
    "        \n",
    "        # 保存完整的聚合数据集\n",
    "        output_file = os.path.join(self.output_dir, 'grampa_aggregated_full.csv')\n",
    "        self.aggregated_df.to_csv(output_file, index=False)\n",
    "        print(f\"完整聚合数据集已保存: {output_file}\")\n",
    "        \n",
    "        # 保存序列聚合数据集\n",
    "        seq_output_file = os.path.join(self.output_dir, 'grampa_sequence_aggregated.csv')\n",
    "        self.seq_aggregated_df.to_csv(seq_output_file, index=False)\n",
    "        print(f\"序列聚合数据集已保存: {seq_output_file}\")\n",
    "        \n",
    "        # 按split保存\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            # 条件回归数据集（包含菌株信息）\n",
    "            split_df = self.aggregated_df[self.aggregated_df['split'] == split].copy()\n",
    "            split_file = os.path.join(self.output_dir, f'grampa_conditional_{split}.csv')\n",
    "            split_df.to_csv(split_file, index=False)\n",
    "            print(f\"{split}集（条件回归）已保存: {split_file} ({len(split_df)} 样本)\")\n",
    "            \n",
    "            # 序列回归数据集\n",
    "            seq_split_df = self.seq_aggregated_df[self.seq_aggregated_df['split'] == split].copy()\n",
    "            seq_split_file = os.path.join(self.output_dir, f'grampa_sequence_{split}.csv')\n",
    "            seq_split_df.to_csv(seq_split_file, index=False)\n",
    "            print(f\"{split}集（序列回归）已保存: {seq_split_file} ({len(seq_split_df)} 样本)\")\n",
    "        \n",
    "        # 保存其他长度的数据集\n",
    "        other_splits = self.df[self.df['dataset_split'].isin(['short', 'long'])].copy()\n",
    "        if len(other_splits) > 0:\n",
    "            other_file = os.path.join(self.output_dir, 'grampa_other_lengths.csv')\n",
    "            other_splits.to_csv(other_file, index=False)\n",
    "            print(f\"其他长度数据集已保存: {other_file} ({len(other_splits)} 样本)\")\n",
    "        \n",
    "        # 保存处理报告\n",
    "        self.save_processing_report()\n",
    "    \n",
    "    def save_processing_report(self):\n",
    "        \"\"\"保存处理报告\"\"\"\n",
    "        report_file = os.path.join(self.output_dir, 'processing_report.md')\n",
    "        \n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# GRAMPA数据集处理报告\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 原始数据统计\\n\")\n",
    "            f.write(f\"- 原始样本数: {len(self.df)}\\n\")\n",
    "            f.write(f\"- 唯一序列数: {self.df['normalized_sequence'].nunique()}\\n\")\n",
    "            f.write(f\"- 唯一菌株数: {self.df['normalized_bacterium'].nunique()}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 序列长度分布\\n\")\n",
    "            length_dist = self.df['dataset_split'].value_counts()\n",
    "            for category, count in length_dist.items():\n",
    "                f.write(f\"- {category}: {count}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"## 聚合后数据统计\\n\")\n",
    "            f.write(f\"- 聚合样本数: {len(self.aggregated_df)}\\n\")\n",
    "            f.write(f\"- 序列聚合样本数: {len(self.seq_aggregated_df)}\\n\")\n",
    "            f.write(f\"- 平均重复测定次数: {self.aggregated_df['n_measurements'].mean():.2f}\\n\")\n",
    "            f.write(f\"- 删失样本数: {self.aggregated_df['has_censoring'].sum()}\\n\")\n",
    "            f.write(f\"- 完全删失样本数: {(self.aggregated_df['n_uncensored'] == 0).sum()}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 数据划分统计\\n\")\n",
    "            split_stats = self.aggregated_df['split'].value_counts()\n",
    "            for split, count in split_stats.items():\n",
    "                f.write(f\"- {split}: {count}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"## Value分布统计\\n\")\n",
    "            f.write(f\"- 原始范围: [{self.aggregated_df['value_original'].min():.3f}, {self.aggregated_df['value_original'].max():.3f}]\\n\")\n",
    "            f.write(f\"- Winsorized范围: [{self.aggregated_df['value_winsorized'].min():.3f}, {self.aggregated_df['value_winsorized'].max():.3f}]\\n\")\n",
    "            f.write(f\"- 均值: {self.aggregated_df['value_winsorized'].mean():.3f}\\n\")\n",
    "            f.write(f\"- 标准差: {self.aggregated_df['value_winsorized'].std():.3f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 菌株分布（Top 10）\\n\")\n",
    "            bacteria_counts = self.aggregated_df['bacterium'].value_counts().head(10)\n",
    "            for bacterium, count in bacteria_counts.items():\n",
    "                f.write(f\"- {bacterium}: {count}\\n\")\n",
    "        \n",
    "        print(f\"处理报告已保存: {report_file}\")\n",
    "    \n",
    "    def run_full_pipeline(self):\n",
    "        \"\"\"运行完整的预处理流程\"\"\"\n",
    "        print(\"开始GRAMPA数据集预处理流程...\")\n",
    "        \n",
    "        # 加载数据\n",
    "        self.load_data()\n",
    "        \n",
    "        # 步骤1: 序列合法化\n",
    "        self.sequence_cleaning()\n",
    "        \n",
    "        # 步骤2: 菌株归一化\n",
    "        self.bacteria_normalization()\n",
    "        \n",
    "        # 步骤3: 重复测定处理\n",
    "        self.handle_duplicates()\n",
    "        \n",
    "        # 步骤4: 删失样本处理\n",
    "        self.handle_censoring()\n",
    "        \n",
    "        # 步骤5: 异常值稳健化\n",
    "        self.winsorize_values()\n",
    "        \n",
    "        # 创建序列聚合数据集\n",
    "        self.create_sequence_aggregated_dataset()\n",
    "        \n",
    "        # 步骤6: 数据划分\n",
    "        self.create_train_val_test_splits()\n",
    "        \n",
    "        # 保存所有数据集\n",
    "        self.save_processed_datasets()\n",
    "        \n",
    "        print(\"\\n数据预处理完成！\")\n",
    "        print(f\"所有文件已保存到: {self.output_dir}\")\n",
    "\n",
    "def main():\n",
    "    # 配置参数\n",
    "    input_file = \"/root/NKU-TMU_AMP_project/data/AMP/grampa_merged_dataset.csv\"\n",
    "    output_dir = \"/root/NKU-TMU_AMP_project/processed_data\"\n",
    "    \n",
    "    # 创建预处理器\n",
    "    preprocessor = GRAMPAPreprocessor(input_file, output_dir)\n",
    "    \n",
    "    # 运行完整流程\n",
    "    preprocessor.run_full_pipeline()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e850d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6c0410c8754395ab4d9fb0f8654705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a076aa6d904d848b8b7fe798bf3d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b7649ec6af408f954f38fb4fb184d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e673416bb2594126aada0756c2749412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bf920a04c64bf98623c03cc8696f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba165d87cb74879906df37a3047894b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d6148251b3440dacde602530482b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52005e71d70e4833aad75d9f87668968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/2.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ad20287813479b843667563e9ac06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa63009930c44914acaac27eed2e6d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-08-16T11:43:56.304458Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31merror downloading range, error: ReqwestMiddlewareError(Reqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/43880025952904ce3c6d2219670148db97493638d0f6326494c00d9db901405f?X-Xet-Signed-Range=bytes%3D40035151-44433683&Expires=1755348175&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC80Mzg4MDAyNTk1MjkwNGNlM2M2ZDIyMTk2NzAxNDhkYjk3NDkzNjM4ZDBmNjMyNjQ5NGMwMGQ5ZGI5MDE0MDVmP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDQwMDM1MTUxLTQ0NDMzNjgzIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzU1MzQ4MTc1fX19XX0_&Signature=DkgiGkjHiZblmYANVjUfJxhe76~Q1lnoRkrjuyiJLqEFs49xMwfOdDUfP87o9seRXRo0fYtp-bzYj6sQbmCoFK0vpJIx5cOGk3vbnQteLyeVqh6lI9vviHMGw2Ewb4ULnYbzhE8nKzQw038gK4QHJxcxPNgM2jsMdVouKDMGT-BSyxXJZAwXMa8RU0avMAWypNDt4wFKfrszV48455QNPUDj6LHTdffFgDS0DDragJY2POgxgXSQf915-uqP0IZT4bkzpghXUe1lBfHPdxdjDepnM8jSJZDTjDtqVob29sqDXngyABf8LhL76UZdrk11YJAFUF7xX~~Bd2WCVmFKJQ__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Custom { kind: UnexpectedEof, error: \"peer closed connection without sending TLS close_notify: https://docs.rs/rustls/latest/rustls/manual/_03_howto/index.html#unexpected-eof\" })) })), \u001b[1;31mcaller\u001b[0m\u001b[31m: \"/home/runner/work/xet-core/xet-core/cas_client/src/download_utils.rs:528\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "  \u001b[2m2025-08-16T11:45:06.574779Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/b59573c564c65f81f7bbcabc6f2c138078a0739c4d2e4e944cc341f73ccc0533?X-Xet-Signed-Range=bytes%3D39961163-45081638&Expires=1755348290&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC9iNTk1NzNjNTY0YzY1ZjgxZjdiYmNhYmM2ZjJjMTM4MDc4YTA3MzljNGQyZTRlOTQ0Y2MzNDFmNzNjY2MwNTMzP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDM5OTYxMTYzLTQ1MDgxNjM4IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzU1MzQ4MjkwfX19XX0_&Signature=p9Trd9n0ODjfrOvurdxyMSoOZrKCOAX7PQMxfwVvhlvzsThr0cyaQFZMJ6u94SKo7iHOt1AJQezu-g0V~C3erfnldmeERIFqs7EbDuW7m8Y~zYPkFxxkYjSh76D2tX23GPmhSO-l-JadFT8aESGE4rQMoj-Hpsm9v8at1PF3GTBNNqlIgND~gj1d4Lyj~JUBzW5GSK4Xn~AcOzuSrYBATEkyVT4MJaxZ2q-WnPFcwMXuEepfD0qvvF~xt5ftqDvpop7nPJjzZYc32Rg5CLkjQQi7hL3XF0P~2xwMQTKn7OqAnJdT--njDVvFXuOee2xIpMlvTjsmBDRRf4JpxdLb8Q__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Os { code: 104, kind: ConnectionReset, message: \"Connection reset by peer\" })) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:213\n",
      "\n",
      "  \u001b[2m2025-08-16T11:45:06.574823Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31merror downloading range, error: ReqwestMiddlewareError(Reqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/b59573c564c65f81f7bbcabc6f2c138078a0739c4d2e4e944cc341f73ccc0533?X-Xet-Signed-Range=bytes%3D39961163-45081638&Expires=1755348290&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC9iNTk1NzNjNTY0YzY1ZjgxZjdiYmNhYmM2ZjJjMTM4MDc4YTA3MzljNGQyZTRlOTQ0Y2MzNDFmNzNjY2MwNTMzP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDM5OTYxMTYzLTQ1MDgxNjM4IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzU1MzQ4MjkwfX19XX0_&Signature=p9Trd9n0ODjfrOvurdxyMSoOZrKCOAX7PQMxfwVvhlvzsThr0cyaQFZMJ6u94SKo7iHOt1AJQezu-g0V~C3erfnldmeERIFqs7EbDuW7m8Y~zYPkFxxkYjSh76D2tX23GPmhSO-l-JadFT8aESGE4rQMoj-Hpsm9v8at1PF3GTBNNqlIgND~gj1d4Lyj~JUBzW5GSK4Xn~AcOzuSrYBATEkyVT4MJaxZ2q-WnPFcwMXuEepfD0qvvF~xt5ftqDvpop7nPJjzZYc32Rg5CLkjQQi7hL3XF0P~2xwMQTKn7OqAnJdT--njDVvFXuOee2xIpMlvTjsmBDRRf4JpxdLb8Q__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Os { code: 104, kind: ConnectionReset, message: \"Connection reset by peer\" })) })), \u001b[1;31mcaller\u001b[0m\u001b[31m: \"/home/runner/work/xet-core/xet-core/cas_client/src/download_utils.rs:528\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "  \u001b[2m2025-08-16T11:45:42.111871Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/43880025952904ce3c6d2219670148db97493638d0f6326494c00d9db901405f?X-Xet-Signed-Range=bytes%3D4513212-22204309&Expires=1755348332&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC80Mzg4MDAyNTk1MjkwNGNlM2M2ZDIyMTk2NzAxNDhkYjk3NDkzNjM4ZDBmNjMyNjQ5NGMwMGQ5ZGI5MDE0MDVmP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDQ1MTMyMTItMjIyMDQzMDkiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTUzNDgzMzJ9fX1dfQ__&Signature=P9xjgwY0B7lndVW7kUO5n~JlmuiRcJWjh1vWUUWSKnYIwab9zGE3rpi0cH5NY~mZzVxealxMc8O1lG3jumgsOXRxkf966WIrqjWqkgf~2WxxP1GKjXvbXyY6PCu9BLpWNaBxIBvJj0POsGX2AfU0b2DNTg2BOi7kGesL8kV-XKrq6uJ0ZI6JlqPrjhjWHGhdmva4j86g8jl6cR~qfDNBCTR5~SGzSArK3CA2Aimv4wPERPm2frTYbaF3QO4F7tepofZyogU2Ni0xBVN00XalAAWsHqB6TSadGzAN9XHquNnQmc0V9uj8mU8nOvs91aUeniM8uWrPaRj1PvuHvzLjAA__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Os { code: 104, kind: ConnectionReset, message: \"Connection reset by peer\" })) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:213\n",
      "\n",
      "  \u001b[2m2025-08-16T11:45:42.111924Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31merror downloading range, error: ReqwestMiddlewareError(Reqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/43880025952904ce3c6d2219670148db97493638d0f6326494c00d9db901405f?X-Xet-Signed-Range=bytes%3D4513212-22204309&Expires=1755348332&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC80Mzg4MDAyNTk1MjkwNGNlM2M2ZDIyMTk2NzAxNDhkYjk3NDkzNjM4ZDBmNjMyNjQ5NGMwMGQ5ZGI5MDE0MDVmP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDQ1MTMyMTItMjIyMDQzMDkiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTUzNDgzMzJ9fX1dfQ__&Signature=P9xjgwY0B7lndVW7kUO5n~JlmuiRcJWjh1vWUUWSKnYIwab9zGE3rpi0cH5NY~mZzVxealxMc8O1lG3jumgsOXRxkf966WIrqjWqkgf~2WxxP1GKjXvbXyY6PCu9BLpWNaBxIBvJj0POsGX2AfU0b2DNTg2BOi7kGesL8kV-XKrq6uJ0ZI6JlqPrjhjWHGhdmva4j86g8jl6cR~qfDNBCTR5~SGzSArK3CA2Aimv4wPERPm2frTYbaF3QO4F7tepofZyogU2Ni0xBVN00XalAAWsHqB6TSadGzAN9XHquNnQmc0V9uj8mU8nOvs91aUeniM8uWrPaRj1PvuHvzLjAA__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Os { code: 104, kind: ConnectionReset, message: \"Connection reset by peer\" })) })), \u001b[1;31mcaller\u001b[0m\u001b[31m: \"/home/runner/work/xet-core/xet-core/cas_client/src/download_utils.rs:528\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "[retry 1/5] Data processing error: CAS service error : Error : single flight error: Real call failed: ReqwestMiddlewareError(Reqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/43880025952904ce3c6d2219670148db97493638d0f6326494c00d9db901405f?X-Xet-Signed-Range=bytes%3D40035151-44433683&Expires=1755348175&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC80Mzg4MDAyNTk1MjkwNGNlM2M2ZDIyMTk2NzAxNDhkYjk3NDkzNjM4ZDBmNjMyNjQ5NGMwMGQ5ZGI5MDE0MDVmP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDQwMDM1MTUxLTQ0NDMzNjgzIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzU1MzQ4MTc1fX19XX0_&Signature=DkgiGkjHiZblmYANVjUfJxhe76~Q1lnoRkrjuyiJLqEFs49xMwfOdDUfP87o9seRXRo0fYtp-bzYj6sQbmCoFK0vpJIx5cOGk3vbnQteLyeVqh6lI9vviHMGw2Ewb4ULnYbzhE8nKzQw038gK4QHJxcxPNgM2jsMdVouKDMGT-BSyxXJZAwXMa8RU0avMAWypNDt4wFKfrszV48455QNPUDj6LHTdffFgDS0DDragJY2POgxgXSQf915-uqP0IZT4bkzpghXUe1lBfHPdxdjDepnM8jSJZDTjDtqVob29sqDXngyABf8LhL76UZdrk11YJAFUF7xX~~Bd2WCVmFKJQ__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Custom { kind: UnexpectedEof, error: \"peer closed connection without sending TLS close_notify: https://docs.rs/rustls/latest/rustls/manual/_03_howto/index.html#unexpected-eof\" })) }))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e3c94f2b7a438ead478c51b35b1360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c14132d66cd42c5ab1de0188caa0d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/2.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881f9b48965f4f438ea5e5faba10577e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3936cb34d95244478c924a79bcadff5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored at: /root/autodl-tmp/esm2_t33_650M_UR50D\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, time\n",
    "\n",
    "# ---- 放在任何 import 之前 ----\n",
    "# 缓存/目录\n",
    "os.environ[\"HF_HOME\"] = \"/root/autodl-tmp/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/root/autodl-tmp/huggingface/transformers\"\n",
    "pathlib.Path(os.environ[\"HF_HOME\"]).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(os.environ[\"TRANSFORMERS_CACHE\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 代理\n",
    "proxy = \"http://127.0.0.1:7890\"\n",
    "for v in [\"HTTP_PROXY\",\"HTTPS_PROXY\",\"http_proxy\",\"https_proxy\",\"ALL_PROXY\"]:\n",
    "    os.environ[v] = proxy\n",
    "\n",
    "# --------------------------------\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = \"facebook/esm2_t33_650M_UR50D\"\n",
    "dest_dir = \"/root/autodl-tmp/esm2_t33_650M_UR50D\"\n",
    "token = None  # 公开模型可 None；若需要私有库，填你的 token\n",
    "\n",
    "retries, delay_s = 5, 15\n",
    "last_err = None\n",
    "\n",
    "for i in range(1, retries + 1):\n",
    "    try:\n",
    "        local_dir = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            local_dir=dest_dir,\n",
    "            local_dir_use_symlinks=False,   # 关键：写入真实文件到你指定硬盘\n",
    "            resume_download=True,\n",
    "            max_workers=4,                  # 网络稳定可开大一点\n",
    "            etag_timeout=60,\n",
    "            token=token\n",
    "        )\n",
    "        print(f\"Model stored at: {local_dir}\")\n",
    "        last_err = None\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "        print(f\"[retry {i}/{retries}] {e}\")\n",
    "        time.sleep(delay_s)\n",
    "\n",
    "if last_err:\n",
    "    raise last_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6dd8463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "正在加载ESM-2模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at /root/autodl-tmp/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM-2模型加载完成\n",
      "开始特征工程流程...\n",
      "加载 /root/NKU-TMU_AMP_project/processed_data/grampa_conditional_train.csv: 22427 样本\n",
      "加载 /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_train.csv: 4966 样本\n",
      "加载 /root/NKU-TMU_AMP_project/processed_data/grampa_conditional_val.csv: 3064 样本\n",
      "加载 /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_val.csv: 706 样本\n",
      "加载 /root/NKU-TMU_AMP_project/processed_data/grampa_conditional_test.csv: 6054 样本\n",
      "加载 /root/NKU-TMU_AMP_project/processed_data/grampa_sequence_test.csv: 1383 样本\n",
      "总共 7055 个唯一序列\n",
      "\n",
      "=== 提取PLM embeddings ===\n",
      "正在提取 7055 个序列的PLM embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "提取PLM embeddings: 100%|██████████| 221/221 [00:14<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLM embeddings shape: torch.Size([7055, 2560])\n",
      "\n",
      "=== 计算理化特征 ===\n",
      "正在计算 7055 个序列的理化特征...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算理化特征: 100%|██████████| 7055/7055 [00:00<00:00, 9810.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "理化特征 shape: (7055, 30)\n",
      "\n",
      "=== 创建菌株embeddings ===\n",
      "正在创建菌株embeddings...\n",
      "唯一菌株数: 269\n",
      "菌株embedding shape: (269, 32)\n",
      "\n",
      "=== 为各数据集生成特征 ===\n",
      "\n",
      "处理数据集: conditional_train\n",
      "保存特征文件: /root/NKU-TMU_AMP_project/features/conditional_train_features.pkl\n",
      "  - PLM embeddings: (22427, 2560)\n",
      "  - 理化特征: (22427, 30)\n",
      "  - 菌株IDs: (22427,)\n",
      "\n",
      "处理数据集: sequence_train\n",
      "保存特征文件: /root/NKU-TMU_AMP_project/features/sequence_train_features.pkl\n",
      "  - PLM embeddings: (4966, 2560)\n",
      "  - 理化特征: (4966, 30)\n",
      "\n",
      "处理数据集: conditional_val\n",
      "保存特征文件: /root/NKU-TMU_AMP_project/features/conditional_val_features.pkl\n",
      "  - PLM embeddings: (3064, 2560)\n",
      "  - 理化特征: (3064, 30)\n",
      "  - 菌株IDs: (3064,)\n",
      "\n",
      "处理数据集: sequence_val\n",
      "保存特征文件: /root/NKU-TMU_AMP_project/features/sequence_val_features.pkl\n",
      "  - PLM embeddings: (706, 2560)\n",
      "  - 理化特征: (706, 30)\n",
      "\n",
      "处理数据集: conditional_test\n",
      "保存特征文件: /root/NKU-TMU_AMP_project/features/conditional_test_features.pkl\n",
      "  - PLM embeddings: (6054, 2560)\n",
      "  - 理化特征: (6054, 30)\n",
      "  - 菌株IDs: (6054,)\n",
      "\n",
      "处理数据集: sequence_test\n",
      "保存特征文件: /root/NKU-TMU_AMP_project/features/sequence_test_features.pkl\n",
      "  - PLM embeddings: (1383, 2560)\n",
      "  - 理化特征: (1383, 30)\n",
      "\n",
      "=== 保存全局映射 ===\n",
      "\n",
      "特征工程完成！所有文件保存在: /root/NKU-TMU_AMP_project/features\n",
      "特征工程报告已保存: /root/NKU-TMU_AMP_project/features/feature_engineering_report.md\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "特征构建脚本\n",
    "实现PLM表征、理化特征和菌株表示的生成\n",
    "基于筛选器设计.md的第三部分要求\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 理化特征计算\n",
    "from Bio.SeqUtils import molecular_weight\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import math\n",
    "\n",
    "class AMP_FeatureExtractor:\n",
    "    def __init__(self, \n",
    "                 processed_data_dir='processed_data',\n",
    "                 features_output_dir='features',\n",
    "                 esm_model_name='facebook/esm2_t33_650M_UR50D',\n",
    "                 device='auto'):\n",
    "        \"\"\"\n",
    "        初始化特征提取器\n",
    "        \n",
    "        Args:\n",
    "            processed_data_dir: 处理后数据目录\n",
    "            features_output_dir: 特征输出目录\n",
    "            esm_model_name: ESM模型名称\n",
    "            device: 计算设备\n",
    "        \"\"\"\n",
    "        self.processed_data_dir = processed_data_dir\n",
    "        self.features_output_dir = features_output_dir\n",
    "        self.esm_model_name = esm_model_name\n",
    "        \n",
    "        # 设备配置\n",
    "        if device == 'auto':\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = torch.device(device)\n",
    "        \n",
    "        print(f\"使用设备: {self.device}\")\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(features_output_dir, exist_ok=True)\n",
    "        \n",
    "        # 初始化ESM模型和tokenizer\n",
    "        print(\"正在加载ESM-2模型...\")\n",
    "        local_dir = \"/root/autodl-tmp/esm2_t33_650M_UR50D\"\n",
    "        self.tokenizer = EsmTokenizer.from_pretrained(local_dir, local_files_only=True)\n",
    "        self.esm_model = EsmModel.from_pretrained(local_dir, local_files_only=True).to(self.device)\n",
    "        self.esm_model.eval()\n",
    "        print(\"ESM-2模型加载完成\")\n",
    "        \n",
    "        # 氨基酸属性字典\n",
    "        self.aa_properties = {\n",
    "            # 疏水性 (Kyte-Doolittle scale)\n",
    "            'hydrophobicity': {\n",
    "                'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "                'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "                'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "                'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "            },\n",
    "            # 电荷 (pH 7.4)\n",
    "            'charge': {\n",
    "                'A': 0, 'R': 1, 'N': 0, 'D': -1, 'C': 0,\n",
    "                'Q': 0, 'E': -1, 'G': 0, 'H': 0, 'I': 0,\n",
    "                'L': 0, 'K': 1, 'M': 0, 'F': 0, 'P': 0,\n",
    "                'S': 0, 'T': 0, 'W': 0, 'Y': 0, 'V': 0\n",
    "            },\n",
    "            # 极性\n",
    "            'polarity': {\n",
    "                'A': 0, 'R': 1, 'N': 1, 'D': 1, 'C': 0,\n",
    "                'Q': 1, 'E': 1, 'G': 0, 'H': 1, 'I': 0,\n",
    "                'L': 0, 'K': 1, 'M': 0, 'F': 0, 'P': 0,\n",
    "                'S': 1, 'T': 1, 'W': 0, 'Y': 1, 'V': 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def extract_plm_embeddings(self, sequences, batch_size=32, max_length=512):\n",
    "        \"\"\"\n",
    "        提取PLM (ESM-2) 表征\n",
    "        \n",
    "        Args:\n",
    "            sequences: 序列列表\n",
    "            batch_size: 批次大小\n",
    "            max_length: 最大序列长度\n",
    "            \n",
    "        Returns:\n",
    "            embeddings: shape (n_sequences, 2*hidden_dim) 的embedding矩阵\n",
    "        \"\"\"\n",
    "        print(f\"正在提取 {len(sequences)} 个序列的PLM embeddings...\")\n",
    "        \n",
    "        all_embeddings = []\n",
    "        \n",
    "        # 批次处理\n",
    "        for i in tqdm(range(0, len(sequences), batch_size), desc=\"提取PLM embeddings\"):\n",
    "            batch_sequences = sequences[i:i+batch_size]\n",
    "            \n",
    "            # 过滤掉过长的序列\n",
    "            valid_sequences = []\n",
    "            valid_indices = []\n",
    "            for j, seq in enumerate(batch_sequences):\n",
    "                if len(seq) <= max_length:\n",
    "                    valid_sequences.append(seq)\n",
    "                    valid_indices.append(j)\n",
    "            \n",
    "            if not valid_sequences:\n",
    "                # 如果批次中没有有效序列，添加零向量\n",
    "                batch_embeddings = torch.zeros(len(batch_sequences), 2 * self.esm_model.config.hidden_size)\n",
    "                all_embeddings.append(batch_embeddings)\n",
    "                continue\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = self.tokenizer(\n",
    "                valid_sequences, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=True, \n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.esm_model(**inputs)\n",
    "                # 获取序列表征 (去除CLS和SEP tokens)\n",
    "                sequence_embeddings = outputs.last_hidden_state[:, 1:-1, :]  # (batch, seq_len, hidden_dim)\n",
    "                \n",
    "                # 池化操作\n",
    "                mean_pooled = torch.mean(sequence_embeddings, dim=1)  # (batch, hidden_dim)\n",
    "                max_pooled = torch.max(sequence_embeddings, dim=1)[0]  # (batch, hidden_dim)\n",
    "                \n",
    "                # 拼接均值和最大池化\n",
    "                combined_embeddings = torch.cat([mean_pooled, max_pooled], dim=1)  # (batch, 2*hidden_dim)\n",
    "                \n",
    "                # 创建完整批次的embedding矩阵\n",
    "                batch_embeddings = torch.zeros(len(batch_sequences), 2 * self.esm_model.config.hidden_size)\n",
    "                for j, valid_idx in enumerate(valid_indices):\n",
    "                    batch_embeddings[valid_idx] = combined_embeddings[j].cpu()\n",
    "                \n",
    "                all_embeddings.append(batch_embeddings)\n",
    "        \n",
    "        # 合并所有批次\n",
    "        final_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "        print(f\"PLM embeddings shape: {final_embeddings.shape}\")\n",
    "        \n",
    "        return final_embeddings.numpy()\n",
    "    \n",
    "    def calculate_physicochemical_features(self, sequences):\n",
    "        \"\"\"\n",
    "        计算理化特征\n",
    "        \n",
    "        Args:\n",
    "            sequences: 序列列表\n",
    "            \n",
    "        Returns:\n",
    "            features: 理化特征矩阵\n",
    "        \"\"\"\n",
    "        print(f\"正在计算 {len(sequences)} 个序列的理化特征...\")\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for seq in tqdm(sequences, desc=\"计算理化特征\"):\n",
    "            seq_features = {}\n",
    "            \n",
    "            # 处理无效序列\n",
    "            if not seq or pd.isna(seq) or len(seq) == 0:\n",
    "                # 返回零特征\n",
    "                features.append([0] * 30)  # 预计30个特征\n",
    "                continue\n",
    "            \n",
    "            # 清理序列（移除非标准氨基酸）\n",
    "            clean_seq = ''.join([aa for aa in seq.upper() if aa in 'ACDEFGHIKLMNPQRSTVWY'])\n",
    "            if len(clean_seq) == 0:\n",
    "                features.append([0] * 30)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # 使用BioPython计算基本特征\n",
    "                analysis = ProteinAnalysis(clean_seq)\n",
    "                \n",
    "                # 1. 长度\n",
    "                length = len(clean_seq)\n",
    "                \n",
    "                # 2. 分子量\n",
    "                mw = analysis.molecular_weight()\n",
    "                \n",
    "                # 3. 等电点\n",
    "                try:\n",
    "                    isoelectric_point = analysis.isoelectric_point()\n",
    "                except:\n",
    "                    isoelectric_point = 7.0\n",
    "                \n",
    "                # 4. GRAVY (疏水性)\n",
    "                try:\n",
    "                    gravy = analysis.gravy()\n",
    "                except:\n",
    "                    gravy = 0.0\n",
    "                \n",
    "                # 5. 净电荷 (pH 7.4)\n",
    "                net_charge = sum([self.aa_properties['charge'].get(aa, 0) for aa in clean_seq])\n",
    "                \n",
    "                # 6. RK含量 (碱性残基比例)\n",
    "                rk_count = clean_seq.count('R') + clean_seq.count('K')\n",
    "                rk_ratio = rk_count / length if length > 0 else 0\n",
    "                \n",
    "                # 7. 氨基酸组成 (20维)\n",
    "                aa_composition = []\n",
    "                for aa in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "                    aa_composition.append(clean_seq.count(aa) / length if length > 0 else 0)\n",
    "                \n",
    "                # 8. 疏水矩 (假设α螺旋)\n",
    "                hydrophobic_moment = self.calculate_hydrophobic_moment(clean_seq)\n",
    "                \n",
    "                # 9. 其他特征\n",
    "                positive_charge = sum([1 for aa in clean_seq if self.aa_properties['charge'].get(aa, 0) > 0])\n",
    "                negative_charge = sum([1 for aa in clean_seq if self.aa_properties['charge'].get(aa, 0) < 0])\n",
    "                polar_residues = sum([1 for aa in clean_seq if self.aa_properties['polarity'].get(aa, 0) == 1])\n",
    "                \n",
    "                # 组装特征向量\n",
    "                feature_vector = [\n",
    "                    length,\n",
    "                    mw,\n",
    "                    isoelectric_point,\n",
    "                    gravy,\n",
    "                    net_charge,\n",
    "                    rk_ratio,\n",
    "                    hydrophobic_moment,\n",
    "                    positive_charge / length if length > 0 else 0,\n",
    "                    negative_charge / length if length > 0 else 0,\n",
    "                    polar_residues / length if length > 0 else 0\n",
    "                ] + aa_composition\n",
    "                \n",
    "                features.append(feature_vector)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"计算序列 {seq[:20]}... 的理化特征时出错: {e}\")\n",
    "                features.append([0] * 30)\n",
    "        \n",
    "        features_array = np.array(features, dtype=np.float32)\n",
    "        print(f\"理化特征 shape: {features_array.shape}\")\n",
    "        \n",
    "        return features_array\n",
    "    \n",
    "    def calculate_hydrophobic_moment(self, sequence, window=100):\n",
    "        \"\"\"\n",
    "        计算疏水矩 (假设α螺旋结构)\n",
    "        \n",
    "        Args:\n",
    "            sequence: 氨基酸序列\n",
    "            window: 螺旋角度窗口 (度)\n",
    "            \n",
    "        Returns:\n",
    "            hydrophobic_moment: 疏水矩值\n",
    "        \"\"\"\n",
    "        if len(sequence) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # α螺旋每个残基旋转100度\n",
    "        angle_per_residue = math.radians(window)\n",
    "        \n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        \n",
    "        for i, aa in enumerate(sequence):\n",
    "            hydrophobicity = self.aa_properties['hydrophobicity'].get(aa, 0)\n",
    "            angle = i * angle_per_residue\n",
    "            \n",
    "            sum_x += hydrophobicity * math.cos(angle)\n",
    "            sum_y += hydrophobicity * math.sin(angle)\n",
    "        \n",
    "        hydrophobic_moment = math.sqrt(sum_x**2 + sum_y**2) / len(sequence)\n",
    "        return hydrophobic_moment\n",
    "    \n",
    "    def create_bacteria_embeddings(self, bacteria_names, embedding_dim=32):\n",
    "        \"\"\"\n",
    "        创建菌株embedding映射\n",
    "        \n",
    "        Args:\n",
    "            bacteria_names: 菌株名称列表\n",
    "            embedding_dim: embedding维度\n",
    "            \n",
    "        Returns:\n",
    "            bacteria_to_id: 菌株名到ID的映射\n",
    "            embedding_matrix: embedding矩阵\n",
    "        \"\"\"\n",
    "        print(f\"正在创建菌株embeddings...\")\n",
    "        \n",
    "        # 统计菌株频次\n",
    "        bacteria_counts = pd.Series(bacteria_names).value_counts()\n",
    "        print(f\"唯一菌株数: {len(bacteria_counts)}\")\n",
    "        \n",
    "        # 创建菌株到ID的映射\n",
    "        bacteria_to_id = {}\n",
    "        id_to_bacteria = {}\n",
    "        \n",
    "        # 为常见菌株分配ID\n",
    "        for i, (bacteria, count) in enumerate(bacteria_counts.items()):\n",
    "            bacteria_to_id[bacteria] = i\n",
    "            id_to_bacteria[i] = bacteria\n",
    "        \n",
    "        # 创建可学习的embedding矩阵\n",
    "        n_bacteria = len(bacteria_to_id)\n",
    "        embedding_matrix = np.random.normal(0, 0.1, (n_bacteria, embedding_dim)).astype(np.float32)\n",
    "        \n",
    "        print(f\"菌株embedding shape: {embedding_matrix.shape}\")\n",
    "        \n",
    "        return bacteria_to_id, embedding_matrix, id_to_bacteria\n",
    "    \n",
    "    def process_all_datasets(self):\n",
    "        \"\"\"\n",
    "        处理所有数据集，生成特征\n",
    "        \"\"\"\n",
    "        print(\"开始特征工程流程...\")\n",
    "        \n",
    "        # 1. 加载处理后的数据\n",
    "        datasets = {}\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            # 条件回归数据集 (包含菌株信息)\n",
    "            conditional_file = os.path.join(self.processed_data_dir, f'grampa_conditional_{split}.csv')\n",
    "            if os.path.exists(conditional_file):\n",
    "                try:\n",
    "                    datasets[f'conditional_{split}'] = pd.read_csv(conditional_file, low_memory=False)\n",
    "                    print(f\"加载 {conditional_file}: {len(datasets[f'conditional_{split}'])} 样本\")\n",
    "                except Exception as e:\n",
    "                    print(f\"加载 {conditional_file} 失败: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # 序列回归数据集 (不含菌株信息)\n",
    "            sequence_file = os.path.join(self.processed_data_dir, f'grampa_sequence_{split}.csv')\n",
    "            if os.path.exists(sequence_file):\n",
    "                try:\n",
    "                    datasets[f'sequence_{split}'] = pd.read_csv(sequence_file, low_memory=False)\n",
    "                    print(f\"加载 {sequence_file}: {len(datasets[f'sequence_{split}'])} 样本\")\n",
    "                except Exception as e:\n",
    "                    print(f\"加载 {sequence_file} 失败: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 2. 收集所有唯一序列\n",
    "        all_sequences = set()\n",
    "        for dataset_name, df in datasets.items():\n",
    "            if 'sequence' in df.columns:\n",
    "                all_sequences.update(df['sequence'].dropna().unique())\n",
    "        \n",
    "        all_sequences = sorted(list(all_sequences))\n",
    "        print(f\"总共 {len(all_sequences)} 个唯一序列\")\n",
    "        \n",
    "        # 3. 提取PLM embeddings\n",
    "        print(\"\\n=== 提取PLM embeddings ===\")\n",
    "        plm_embeddings = self.extract_plm_embeddings(all_sequences)\n",
    "        \n",
    "        # 创建序列到embedding的映射\n",
    "        seq_to_embedding = {seq: plm_embeddings[i] for i, seq in enumerate(all_sequences)}\n",
    "        \n",
    "        # 4. 计算理化特征\n",
    "        print(\"\\n=== 计算理化特征 ===\")\n",
    "        physicochemical_features = self.calculate_physicochemical_features(all_sequences)\n",
    "        \n",
    "        # 创建序列到理化特征的映射\n",
    "        seq_to_physchem = {seq: physicochemical_features[i] for i, seq in enumerate(all_sequences)}\n",
    "        \n",
    "        # 5. 处理菌株embeddings (仅针对条件回归数据集)\n",
    "        print(\"\\n=== 创建菌株embeddings ===\")\n",
    "        all_bacteria = set()\n",
    "        for dataset_name, df in datasets.items():\n",
    "            if 'conditional' in dataset_name and 'bacterium' in df.columns:\n",
    "                all_bacteria.update(df['bacterium'].dropna().unique())\n",
    "        \n",
    "        all_bacteria = sorted(list(all_bacteria))\n",
    "        bacteria_to_id, bacteria_embedding_matrix, id_to_bacteria = self.create_bacteria_embeddings(all_bacteria)\n",
    "        \n",
    "        # 6. 为每个数据集生成特征\n",
    "        print(\"\\n=== 为各数据集生成特征 ===\")\n",
    "        for dataset_name, df in datasets.items():\n",
    "            print(f\"\\n处理数据集: {dataset_name}\")\n",
    "            \n",
    "            # 序列特征\n",
    "            sequences = df['sequence'].values\n",
    "            dataset_plm_embeddings = np.array([seq_to_embedding.get(seq, np.zeros(plm_embeddings.shape[1])) \n",
    "                                             for seq in sequences])\n",
    "            dataset_physchem_features = np.array([seq_to_physchem.get(seq, np.zeros(physicochemical_features.shape[1])) \n",
    "                                                for seq in sequences])\n",
    "            \n",
    "            # 保存序列特征\n",
    "            features_dict = {\n",
    "                'plm_embeddings': dataset_plm_embeddings,\n",
    "                'physicochemical_features': dataset_physchem_features,\n",
    "                'sequences': sequences\n",
    "            }\n",
    "            \n",
    "            # 如果是条件回归数据集，添加菌株信息\n",
    "            if 'conditional' in dataset_name and 'bacterium' in df.columns:\n",
    "                bacteria = df['bacterium'].values\n",
    "                bacteria_ids = np.array([bacteria_to_id.get(bact, 0) for bact in bacteria])\n",
    "                features_dict['bacteria_ids'] = bacteria_ids\n",
    "                features_dict['bacteria_names'] = bacteria\n",
    "            \n",
    "            # 添加目标变量和其他信息\n",
    "            if 'value_winsorized' in df.columns:\n",
    "                features_dict['targets'] = df['value_winsorized'].values\n",
    "            elif 'mean_log_mic' in df.columns:  # 序列聚合数据集的目标变量\n",
    "                features_dict['targets'] = df['mean_log_mic'].values\n",
    "            \n",
    "            if 'is_censored' in df.columns:\n",
    "                features_dict['is_censored'] = df['is_censored'].values\n",
    "            if 'censoring_threshold' in df.columns:\n",
    "                features_dict['censoring_threshold'] = df['censoring_threshold'].fillna(0).values\n",
    "            if 'n_measurements' in df.columns:\n",
    "                features_dict['sample_weights'] = df['n_measurements'].values\n",
    "            elif 'total_measurements' in df.columns:  # 序列聚合数据集的权重\n",
    "                features_dict['sample_weights'] = df['total_measurements'].values\n",
    "            \n",
    "            # 保存特征文件\n",
    "            output_file = os.path.join(self.features_output_dir, f'{dataset_name}_features.pkl')\n",
    "            with open(output_file, 'wb') as f:\n",
    "                pickle.dump(features_dict, f)\n",
    "            print(f\"保存特征文件: {output_file}\")\n",
    "            print(f\"  - PLM embeddings: {dataset_plm_embeddings.shape}\")\n",
    "            print(f\"  - 理化特征: {dataset_physchem_features.shape}\")\n",
    "            if 'bacteria_ids' in features_dict:\n",
    "                print(f\"  - 菌株IDs: {features_dict['bacteria_ids'].shape}\")\n",
    "        \n",
    "        # 7. 保存全局映射和embedding矩阵\n",
    "        print(\"\\n=== 保存全局映射 ===\")\n",
    "        \n",
    "        # 保存序列特征映射\n",
    "        seq_features_mapping = {\n",
    "            'seq_to_plm': seq_to_embedding,\n",
    "            'seq_to_physchem': seq_to_physchem,\n",
    "            'plm_embedding_dim': plm_embeddings.shape[1],\n",
    "            'physchem_feature_dim': physicochemical_features.shape[1]\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.features_output_dir, 'sequence_features_mapping.pkl'), 'wb') as f:\n",
    "            pickle.dump(seq_features_mapping, f)\n",
    "        \n",
    "        # 保存菌株映射和embedding\n",
    "        bacteria_mapping = {\n",
    "            'bacteria_to_id': bacteria_to_id,\n",
    "            'id_to_bacteria': id_to_bacteria,\n",
    "            'bacteria_embedding_matrix': bacteria_embedding_matrix,\n",
    "            'embedding_dim': bacteria_embedding_matrix.shape[1]\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.features_output_dir, 'bacteria_mapping.pkl'), 'wb') as f:\n",
    "            pickle.dump(bacteria_mapping, f)\n",
    "        \n",
    "        print(f\"\\n特征工程完成！所有文件保存在: {self.features_output_dir}\")\n",
    "        \n",
    "        # 8. 生成特征工程报告\n",
    "        self.generate_feature_report(datasets, seq_features_mapping, bacteria_mapping)\n",
    "    \n",
    "    def generate_feature_report(self, datasets, seq_features_mapping, bacteria_mapping):\n",
    "        \"\"\"\n",
    "        生成特征工程报告\n",
    "        \"\"\"\n",
    "        report_file = os.path.join(self.features_output_dir, 'feature_engineering_report.md')\n",
    "        \n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# 特征工程报告\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 数据集统计\\n\")\n",
    "            for dataset_name, df in datasets.items():\n",
    "                f.write(f\"- {dataset_name}: {len(df)} 样本\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"## 特征维度\\n\")\n",
    "            f.write(f\"- PLM embeddings: {seq_features_mapping['plm_embedding_dim']} 维\\n\")\n",
    "            f.write(f\"- 理化特征: {seq_features_mapping['physchem_feature_dim']} 维\\n\")\n",
    "            f.write(f\"- 菌株embedding: {bacteria_mapping['embedding_dim']} 维\\n\")\n",
    "            f.write(f\"- 总序列数: {len(seq_features_mapping['seq_to_plm'])}\\n\")\n",
    "            f.write(f\"- 总菌株数: {len(bacteria_mapping['bacteria_to_id'])}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 理化特征列表\\n\")\n",
    "            feature_names = [\n",
    "                \"序列长度\", \"分子量\", \"等电点\", \"GRAVY疏水性\", \"净电荷\", \"RK比例\", \"疏水矩\",\n",
    "                \"正电荷比例\", \"负电荷比例\", \"极性残基比例\"\n",
    "            ] + [f\"氨基酸_{aa}_比例\" for aa in 'ACDEFGHIKLMNPQRSTVWY']\n",
    "            \n",
    "            for i, name in enumerate(feature_names):\n",
    "                f.write(f\"{i+1}. {name}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.write(\"## Top 10 菌株\\n\")\n",
    "            bacteria_counts = pd.Series(list(bacteria_mapping['bacteria_to_id'].keys())).value_counts()\n",
    "            for i, (bacteria, _) in enumerate(bacteria_counts.head(10).items(), 1):\n",
    "                f.write(f\"{i}. {bacteria}\\n\")\n",
    "            \n",
    "        print(f\"特征工程报告已保存: {report_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 配置参数\n",
    "    processed_data_dir = \"/root/NKU-TMU_AMP_project/processed_data\"\n",
    "    features_output_dir = \"/root/NKU-TMU_AMP_project/features\"\n",
    "    \n",
    "    # 创建特征提取器\n",
    "    extractor = AMP_FeatureExtractor(\n",
    "        processed_data_dir=processed_data_dir,\n",
    "        features_output_dir=features_output_dir,\n",
    "        esm_model_name='facebook/esm2_t33_650M_UR50D',  # ESM-2 650M参数版本\n",
    "        device='auto'\n",
    "    )\n",
    "    \n",
    "    # 执行特征工程\n",
    "    extractor.process_all_datasets()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70367ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "正在加载特征数据...\n",
      "数据集大小: 4966\n",
      "特征维度: PLM=2560, 理化=30\n",
      "合并特征维度: 2590\n",
      "加载序列数据集 train: 4966 样本\n",
      "数据集大小: 706\n",
      "特征维度: PLM=2560, 理化=30\n",
      "合并特征维度: 2590\n",
      "加载序列数据集 val: 706 样本\n",
      "数据集大小: 1383\n",
      "特征维度: PLM=2560, 理化=30\n",
      "合并特征维度: 2590\n",
      "加载序列数据集 test: 1383 样本\n",
      "数据集大小: 22427\n",
      "特征维度: PLM=2560, 理化=30\n",
      "合并特征维度: 2590\n",
      "包含菌株信息: 269 个唯一菌株\n",
      "删失样本数: 499 / 22427 (2.2%)\n",
      "加载条件数据集 train: 22427 样本\n",
      "数据集大小: 3064\n",
      "特征维度: PLM=2560, 理化=30\n",
      "合并特征维度: 2590\n",
      "包含菌株信息: 248 个唯一菌株\n",
      "删失样本数: 102 / 3064 (3.3%)\n",
      "加载条件数据集 val: 3064 样本\n",
      "数据集大小: 6054\n",
      "特征维度: PLM=2560, 理化=30\n",
      "合并特征维度: 2590\n",
      "包含菌株信息: 257 个唯一菌株\n",
      "删失样本数: 132 / 6054 (2.2%)\n",
      "加载条件数据集 test: 6054 样本\n",
      "菌株数量: 269\n",
      "\n",
      "==================================================\n",
      "开始训练序列聚合回归模型\n",
      "==================================================\n",
      "\n",
      "=== 训练序列聚合回归模型 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 39/39 [00:00<00:00, 249.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3360, Val Loss=0.1176, Val RMSE=0.4876, Val R²=0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 39/39 [00:00<00:00, 250.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1132, Val Loss=0.0927, Val RMSE=0.4385, Val R²=0.2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 39/39 [00:00<00:00, 253.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1001, Val Loss=0.0865, Val RMSE=0.4205, Val R²=0.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 39/39 [00:00<00:00, 250.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.0986, Val Loss=0.0847, Val RMSE=0.4181, Val R²=0.2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 39/39 [00:00<00:00, 253.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.0922, Val Loss=0.0932, Val RMSE=0.4349, Val R²=0.2214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 39/39 [00:00<00:00, 251.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.0895, Val Loss=0.0843, Val RMSE=0.4145, Val R²=0.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 39/39 [00:00<00:00, 249.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.0861, Val Loss=0.0803, Val RMSE=0.4044, Val R²=0.3266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 39/39 [00:00<00:00, 243.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.0839, Val Loss=0.0801, Val RMSE=0.4054, Val R²=0.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 39/39 [00:00<00:00, 222.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0819, Val Loss=0.0843, Val RMSE=0.4158, Val R²=0.2881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 39/39 [00:00<00:00, 222.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0827, Val Loss=0.0821, Val RMSE=0.4085, Val R²=0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 39/39 [00:00<00:00, 221.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.0821, Val Loss=0.0805, Val RMSE=0.4034, Val R²=0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 39/39 [00:00<00:00, 222.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.0776, Val Loss=0.0794, Val RMSE=0.4019, Val R²=0.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 39/39 [00:00<00:00, 210.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.0771, Val Loss=0.0786, Val RMSE=0.4000, Val R²=0.3412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 39/39 [00:00<00:00, 226.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.0747, Val Loss=0.0774, Val RMSE=0.3961, Val R²=0.3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/100: 100%|██████████| 39/39 [00:00<00:00, 244.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0757, Val Loss=0.0789, Val RMSE=0.4000, Val R²=0.3414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 39/39 [00:00<00:00, 221.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=0.0765, Val Loss=0.0791, Val RMSE=0.4008, Val R²=0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 39/39 [00:00<00:00, 220.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=0.0725, Val Loss=0.0780, Val RMSE=0.3971, Val R²=0.3507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 39/39 [00:00<00:00, 222.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=0.0707, Val Loss=0.0819, Val RMSE=0.4092, Val R²=0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 39/39 [00:00<00:00, 219.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=0.0698, Val Loss=0.0899, Val RMSE=0.4296, Val R²=0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 39/39 [00:00<00:00, 222.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=0.0691, Val Loss=0.0755, Val RMSE=0.3929, Val R²=0.3646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 39/39 [00:00<00:00, 220.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=0.0683, Val Loss=0.0752, Val RMSE=0.3922, Val R²=0.3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 39/39 [00:00<00:00, 221.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=0.0655, Val Loss=0.0767, Val RMSE=0.3951, Val R²=0.3573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 39/39 [00:00<00:00, 225.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=0.0705, Val Loss=0.0757, Val RMSE=0.3917, Val R²=0.3683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 39/39 [00:00<00:00, 221.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=0.0714, Val Loss=0.0758, Val RMSE=0.3939, Val R²=0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 39/39 [00:00<00:00, 222.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=0.0638, Val Loss=0.0771, Val RMSE=0.3960, Val R²=0.3543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 39/39 [00:00<00:00, 223.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=0.0635, Val Loss=0.0746, Val RMSE=0.3898, Val R²=0.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 39/39 [00:00<00:00, 222.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=0.0639, Val Loss=0.0785, Val RMSE=0.4004, Val R²=0.3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 39/39 [00:00<00:00, 225.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=0.0622, Val Loss=0.0747, Val RMSE=0.3894, Val R²=0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 39/39 [00:00<00:00, 226.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=0.0629, Val Loss=0.0793, Val RMSE=0.4021, Val R²=0.3344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 39/39 [00:00<00:00, 226.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=0.0590, Val Loss=0.0761, Val RMSE=0.3954, Val R²=0.3565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 39/39 [00:00<00:00, 255.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=0.0598, Val Loss=0.0746, Val RMSE=0.3929, Val R²=0.3646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 39/39 [00:00<00:00, 228.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=0.0585, Val Loss=0.0731, Val RMSE=0.3883, Val R²=0.3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 39/39 [00:00<00:00, 225.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=0.0575, Val Loss=0.0871, Val RMSE=0.4191, Val R²=0.2769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 39/39 [00:00<00:00, 225.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=0.0566, Val Loss=0.0755, Val RMSE=0.3931, Val R²=0.3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 39/39 [00:00<00:00, 224.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=0.0559, Val Loss=0.0823, Val RMSE=0.4097, Val R²=0.3089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 39/39 [00:00<00:00, 226.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=0.0589, Val Loss=0.0753, Val RMSE=0.3912, Val R²=0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 39/39 [00:00<00:00, 226.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=0.0563, Val Loss=0.0746, Val RMSE=0.3902, Val R²=0.3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 39/39 [00:00<00:00, 225.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=0.0607, Val Loss=0.0801, Val RMSE=0.4031, Val R²=0.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 39/39 [00:00<00:00, 225.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=0.0497, Val Loss=0.0725, Val RMSE=0.3849, Val R²=0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 39/39 [00:00<00:00, 225.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=0.0470, Val Loss=0.0728, Val RMSE=0.3854, Val R²=0.3884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 39/39 [00:00<00:00, 226.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss=0.0463, Val Loss=0.0735, Val RMSE=0.3871, Val R²=0.3831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 39/39 [00:00<00:00, 227.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss=0.0465, Val Loss=0.0735, Val RMSE=0.3867, Val R²=0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 39/39 [00:00<00:00, 226.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss=0.0461, Val Loss=0.0732, Val RMSE=0.3861, Val R²=0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 39/39 [00:00<00:00, 227.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss=0.0458, Val Loss=0.0735, Val RMSE=0.3875, Val R²=0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 39/39 [00:00<00:00, 225.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss=0.0449, Val Loss=0.0744, Val RMSE=0.3889, Val R²=0.3773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 39/39 [00:00<00:00, 228.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss=0.0449, Val Loss=0.0739, Val RMSE=0.3876, Val R²=0.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 39/39 [00:00<00:00, 227.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss=0.0447, Val Loss=0.0739, Val RMSE=0.3876, Val R²=0.3816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 39/39 [00:00<00:00, 226.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss=0.0443, Val Loss=0.0741, Val RMSE=0.3883, Val R²=0.3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 39/39 [00:00<00:00, 227.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss=0.0444, Val Loss=0.0742, Val RMSE=0.3885, Val R²=0.3788\n",
      "早停在第 49 轮\n",
      "\n",
      "=== 评估序列聚合模型 ===\n",
      "测试集 RMSE: 0.3608\n",
      "测试集 R²: 0.4922\n",
      "2μM 阈值 - AUC: 0.8204, AP: 0.9295\n",
      "5μM 阈值 - AUC: 0.8664, AP: 0.9808\n",
      "10μM 阈值 - AUC: 0.9077, AP: 0.9900\n",
      "\n",
      "==================================================\n",
      "开始训练条件回归模型\n",
      "==================================================\n",
      "\n",
      "=== 训练条件回归模型 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 176/176 [00:01<00:00, 130.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2717, Val Loss=0.2794, Val RMSE=0.4793, Val R²=0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 176/176 [00:01<00:00, 129.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1738, Val Loss=0.2248, Val RMSE=0.5103, Val R²=-0.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 176/176 [00:01<00:00, 126.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1381, Val Loss=0.2595, Val RMSE=0.4789, Val R²=0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 176/176 [00:01<00:00, 126.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1145, Val Loss=0.2128, Val RMSE=0.5373, Val R²=-0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 176/176 [00:01<00:00, 132.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1016, Val Loss=0.1934, Val RMSE=0.4455, Val R²=0.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 176/176 [00:01<00:00, 127.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.0883, Val Loss=0.2088, Val RMSE=0.4334, Val R²=0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 176/176 [00:01<00:00, 131.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.0839, Val Loss=0.2472, Val RMSE=0.4631, Val R²=0.0909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 176/176 [00:01<00:00, 130.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.0849, Val Loss=0.2008, Val RMSE=0.4656, Val R²=0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 176/176 [00:01<00:00, 132.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0811, Val Loss=0.2106, Val RMSE=0.4342, Val R²=0.2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 176/176 [00:01<00:00, 131.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0779, Val Loss=0.1974, Val RMSE=0.4334, Val R²=0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 176/176 [00:01<00:00, 109.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.0778, Val Loss=0.1957, Val RMSE=0.4418, Val R²=0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 176/176 [00:01<00:00, 125.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.0695, Val Loss=0.2005, Val RMSE=0.4332, Val R²=0.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 176/176 [00:01<00:00, 125.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.0654, Val Loss=0.2033, Val RMSE=0.4342, Val R²=0.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 176/176 [00:01<00:00, 126.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.0638, Val Loss=0.1976, Val RMSE=0.4363, Val R²=0.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 176/176 [00:01<00:00, 124.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0650, Val Loss=0.2040, Val RMSE=0.4313, Val R²=0.2114\n",
      "早停在第 15 轮\n",
      "\n",
      "=== 评估条件回归模型 ===\n",
      "整体测试集 RMSE: 0.4288\n",
      "整体测试集 R²: 0.1970\n",
      "\n",
      "Top 10 菌株结果:\n",
      "escherichia_coli: RMSE=0.4370, R²=0.2446, N=1000\n",
      "staphylococcus_aureus: RMSE=0.4621, R²=0.2579, N=888\n",
      "pseudomonas_aeruginosa: RMSE=0.4696, R²=0.0048, N=529\n",
      "candida_albicans: RMSE=0.4589, R²=-0.0258, N=355\n",
      "bacillus_subtilis: RMSE=0.3859, R²=0.1055, N=297\n",
      "staphylococcus_epidermidis: RMSE=0.3847, R²=0.0541, N=175\n",
      "klebsiella_pneumoniae: RMSE=0.4409, R²=0.0488, N=166\n",
      "salmonella_typhimurium: RMSE=0.3869, R²=0.0464, N=148\n",
      "other: RMSE=0.7004, R²=-0.1035, N=144\n",
      "enterococcus_faecalis: RMSE=0.3815, R²=-0.2701, N=140\n",
      "2μM 阈值 - AUC: 0.7502, AP: 0.9094\n",
      "5μM 阈值 - AUC: 0.7980, AP: 0.9791\n",
      "10μM 阈值 - AUC: 0.8482, AP: 0.9891\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "训练完成！模型和结果已保存到 model_outputs/ 目录\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "两层建模方案训练脚本\n",
    "基于筛选器设计.md的第四部分要求\n",
    "\n",
    "实现：\n",
    "A. 序列聚合回归（~7k样本，总体活性预测）\n",
    "B. 条件回归（~45k样本，序列×菌株细粒度预测）\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class AMP_Dataset(Dataset):\n",
    "    \"\"\"AMP数据集类\"\"\"\n",
    "    def __init__(self, features_dict, scaler=None, fit_scaler=False):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        Args:\n",
    "            features_dict: 特征字典\n",
    "            scaler: 标准化器\n",
    "            fit_scaler: 是否拟合标准化器\n",
    "        \"\"\"\n",
    "        self.plm_embeddings = features_dict['plm_embeddings']\n",
    "        self.physicochemical_features = features_dict['physicochemical_features']\n",
    "        self.targets = features_dict['targets']\n",
    "        self.sequences = features_dict['sequences']\n",
    "        \n",
    "        # 可选字段\n",
    "        self.bacteria_ids = features_dict.get('bacteria_ids', None)\n",
    "        self.bacteria_names = features_dict.get('bacteria_names', None)\n",
    "        self.is_censored = features_dict.get('is_censored', None)\n",
    "        self.censoring_threshold = features_dict.get('censoring_threshold', None)\n",
    "        self.sample_weights = features_dict.get('sample_weights', None)\n",
    "        \n",
    "        # 标准化理化特征\n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            fit_scaler = True\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            \n",
    "        if fit_scaler:\n",
    "            self.physicochemical_features_scaled = self.scaler.fit_transform(self.physicochemical_features)\n",
    "        else:\n",
    "            self.physicochemical_features_scaled = self.scaler.transform(self.physicochemical_features)\n",
    "        \n",
    "        # 合并特征\n",
    "        self.combined_features = np.concatenate([\n",
    "            self.plm_embeddings,\n",
    "            self.physicochemical_features_scaled\n",
    "        ], axis=1)\n",
    "        \n",
    "        print(f\"数据集大小: {len(self.targets)}\")\n",
    "        print(f\"特征维度: PLM={self.plm_embeddings.shape[1]}, 理化={self.physicochemical_features.shape[1]}\")\n",
    "        print(f\"合并特征维度: {self.combined_features.shape[1]}\")\n",
    "        \n",
    "        if self.bacteria_ids is not None:\n",
    "            print(f\"包含菌株信息: {len(np.unique(self.bacteria_ids))} 个唯一菌株\")\n",
    "        if self.is_censored is not None:\n",
    "            censored_count = np.sum(self.is_censored)\n",
    "            print(f\"删失样本数: {censored_count} / {len(self.is_censored)} ({100*censored_count/len(self.is_censored):.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'features': torch.FloatTensor(self.combined_features[idx]),\n",
    "            'target': torch.FloatTensor([self.targets[idx]]),\n",
    "            'sequence': self.sequences[idx]\n",
    "        }\n",
    "        \n",
    "        if self.bacteria_ids is not None:\n",
    "            item['bacteria_id'] = torch.LongTensor([self.bacteria_ids[idx]])\n",
    "        \n",
    "        if self.is_censored is not None:\n",
    "            item['is_censored'] = torch.BoolTensor([self.is_censored[idx]])\n",
    "            item['censoring_threshold'] = torch.FloatTensor([self.censoring_threshold[idx]])\n",
    "        \n",
    "        if self.sample_weights is not None:\n",
    "            item['sample_weight'] = torch.FloatTensor([self.sample_weights[idx]])\n",
    "        \n",
    "        return item\n",
    "\n",
    "class SequenceRegressionModel(nn.Module):\n",
    "    \"\"\"序列聚合回归模型（模型A）\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[1024, 512], dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU(),  # Swish激活函数\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # 输出层\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # 权重初始化\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        return self.model(features).squeeze(-1)\n",
    "\n",
    "class ConditionalRegressionModel(nn.Module):\n",
    "    \"\"\"条件回归模型（模型B）\"\"\"\n",
    "    def __init__(self, input_dim, n_bacteria, bacteria_embedding_dim=32, \n",
    "                 hidden_dims=[1024, 512], dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 菌株embedding层\n",
    "        self.bacteria_embedding = nn.Embedding(n_bacteria, bacteria_embedding_dim)\n",
    "        \n",
    "        # 合并输入维度\n",
    "        combined_input_dim = input_dim + bacteria_embedding_dim\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = combined_input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # 输出层\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # 权重初始化\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0, std=0.1)\n",
    "    \n",
    "    def forward(self, features, bacteria_ids):\n",
    "        # 获取菌株embedding\n",
    "        bacteria_emb = self.bacteria_embedding(bacteria_ids.squeeze(-1))\n",
    "        \n",
    "        # 拼接特征\n",
    "        combined = torch.cat([features, bacteria_emb], dim=-1)\n",
    "        \n",
    "        return self.model(combined).squeeze(-1)\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    \"\"\"Huber损失函数\"\"\"\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        abs_error = torch.abs(pred - target)\n",
    "        quadratic = torch.clamp(abs_error, max=self.delta)\n",
    "        linear = abs_error - quadratic\n",
    "        return torch.mean(0.5 * quadratic**2 + self.delta * linear)\n",
    "\n",
    "class CensoringAwareHuberLoss(nn.Module):\n",
    "    \"\"\"删失感知的Huber损失\"\"\"\n",
    "    def __init__(self, delta=1.0, censoring_weight=2.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.censoring_weight = censoring_weight\n",
    "        self.huber = HuberLoss(delta)\n",
    "    \n",
    "    def forward(self, pred, target, is_censored=None, censoring_threshold=None):\n",
    "        if is_censored is None:\n",
    "            # 没有删失信息，使用标准Huber损失\n",
    "            return self.huber(pred, target)\n",
    "        \n",
    "        # 非删失样本的损失\n",
    "        uncensored_mask = ~is_censored\n",
    "        uncensored_loss = 0.0\n",
    "        if uncensored_mask.sum() > 0:\n",
    "            uncensored_loss = self.huber(pred[uncensored_mask], target[uncensored_mask])\n",
    "        \n",
    "        # 删失样本的损失（右删失）\n",
    "        censored_mask = is_censored\n",
    "        censored_loss = 0.0\n",
    "        if censored_mask.sum() > 0:\n",
    "            # 只有当预测值小于删失阈值时才惩罚\n",
    "            censored_pred = pred[censored_mask]\n",
    "            censored_thresh = censoring_threshold[censored_mask]\n",
    "            violation = torch.clamp(censored_thresh - censored_pred, min=0)\n",
    "            censored_loss = torch.mean(violation ** 2) * self.censoring_weight\n",
    "        \n",
    "        # 加权组合\n",
    "        n_uncensored = uncensored_mask.sum().float()\n",
    "        n_censored = censored_mask.sum().float()\n",
    "        n_total = len(pred)\n",
    "        \n",
    "        if n_uncensored > 0 and n_censored > 0:\n",
    "            total_loss = (n_uncensored / n_total) * uncensored_loss + (n_censored / n_total) * censored_loss\n",
    "        elif n_uncensored > 0:\n",
    "            total_loss = uncensored_loss\n",
    "        else:\n",
    "            total_loss = censored_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "class AMPTrainer:\n",
    "    \"\"\"AMP模型训练器\"\"\"\n",
    "    def __init__(self, device='auto', output_dir='model_outputs'):\n",
    "        if device == 'auto':\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = torch.device(device)\n",
    "        \n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"使用设备: {self.device}\")\n",
    "    \n",
    "    def load_data(self, features_dir='features'):\n",
    "        \"\"\"加载特征数据\"\"\"\n",
    "        print(\"正在加载特征数据...\")\n",
    "        \n",
    "        self.datasets = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # 加载序列聚合数据集\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            file_path = os.path.join(features_dir, f'sequence_{split}_features.pkl')\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    features_dict = pickle.load(f)\n",
    "                \n",
    "                # 第一个数据集拟合scaler\n",
    "                if f'sequence_{split}' not in self.scalers:\n",
    "                    if split == 'train':\n",
    "                        dataset = AMP_Dataset(features_dict, fit_scaler=True)\n",
    "                        self.scalers['sequence'] = dataset.scaler\n",
    "                    else:\n",
    "                        dataset = AMP_Dataset(features_dict, scaler=self.scalers['sequence'])\n",
    "                else:\n",
    "                    dataset = AMP_Dataset(features_dict, scaler=self.scalers['sequence'])\n",
    "                \n",
    "                self.datasets[f'sequence_{split}'] = dataset\n",
    "                print(f\"加载序列数据集 {split}: {len(dataset)} 样本\")\n",
    "        \n",
    "        # 加载条件回归数据集\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            file_path = os.path.join(features_dir, f'conditional_{split}_features.pkl')\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    features_dict = pickle.load(f)\n",
    "                \n",
    "                if f'conditional_{split}' not in self.scalers:\n",
    "                    if split == 'train':\n",
    "                        dataset = AMP_Dataset(features_dict, fit_scaler=True)\n",
    "                        self.scalers['conditional'] = dataset.scaler\n",
    "                    else:\n",
    "                        dataset = AMP_Dataset(features_dict, scaler=self.scalers['conditional'])\n",
    "                else:\n",
    "                    dataset = AMP_Dataset(features_dict, scaler=self.scalers['conditional'])\n",
    "                \n",
    "                self.datasets[f'conditional_{split}'] = dataset\n",
    "                print(f\"加载条件数据集 {split}: {len(dataset)} 样本\")\n",
    "        \n",
    "        # 加载菌株映射\n",
    "        bacteria_mapping_file = os.path.join(features_dir, 'bacteria_mapping.pkl')\n",
    "        with open(bacteria_mapping_file, 'rb') as f:\n",
    "            self.bacteria_mapping = pickle.load(f)\n",
    "        \n",
    "        print(f\"菌株数量: {len(self.bacteria_mapping['bacteria_to_id'])}\")\n",
    "    \n",
    "    def train_sequence_model(self, batch_size=128, learning_rate=2e-4, \n",
    "                           num_epochs=100, patience=10):\n",
    "        \"\"\"训练序列聚合回归模型\"\"\"\n",
    "        print(\"\\n=== 训练序列聚合回归模型 ===\")\n",
    "        \n",
    "        train_dataset = self.datasets['sequence_train']\n",
    "        val_dataset = self.datasets['sequence_val']\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 创建模型\n",
    "        input_dim = train_dataset.combined_features.shape[1]\n",
    "        model = SequenceRegressionModel(input_dim=input_dim).to(self.device)\n",
    "        \n",
    "        # 优化器和损失函数\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "        criterion = HuberLoss(delta=1.0)\n",
    "        \n",
    "        # 训练循环\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                features = batch['features'].to(self.device)\n",
    "                targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(features)\n",
    "                loss = criterion(predictions, targets)\n",
    "                loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # 验证阶段\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    features = batch['features'].to(self.device)\n",
    "                    targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                    \n",
    "                    predictions = model(features)\n",
    "                    loss = criterion(predictions, targets)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    val_predictions.extend(predictions.cpu().numpy())\n",
    "                    val_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            # 计算评估指标\n",
    "            val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
    "            val_r2 = r2_score(val_targets, val_predictions)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, \"\n",
    "                  f\"Val RMSE={val_rmse:.4f}, Val R²={val_r2:.4f}\")\n",
    "            \n",
    "            # 学习率调度\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # 早停\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型\n",
    "                torch.save(model.state_dict(), \n",
    "                          os.path.join(self.output_dir, 'sequence_regression_best.pt'))\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"早停在第 {epoch+1} 轮\")\n",
    "                    break\n",
    "        \n",
    "        # 保存训练历史\n",
    "        history = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.output_dir, 'sequence_training_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "        \n",
    "        # 加载最佳模型进行测试\n",
    "        model.load_state_dict(torch.load(os.path.join(self.output_dir, 'sequence_regression_best.pt')))\n",
    "        self.sequence_model = model\n",
    "        \n",
    "        # 在测试集上评估\n",
    "        self.evaluate_sequence_model()\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    def train_conditional_model(self, batch_size=128, learning_rate=2e-4,\n",
    "                              num_epochs=100, patience=10):\n",
    "        \"\"\"训练条件回归模型\"\"\"\n",
    "        print(\"\\n=== 训练条件回归模型 ===\")\n",
    "        \n",
    "        train_dataset = self.datasets['conditional_train']\n",
    "        val_dataset = self.datasets['conditional_val']\n",
    "        \n",
    "        # 创建加权采样器（平衡菌株分布）\n",
    "        bacteria_counts = np.bincount(train_dataset.bacteria_ids.flatten())\n",
    "        bacteria_weights = 1.0 / np.sqrt(bacteria_counts + 1e-8)  # 避免除零\n",
    "        sample_weights = bacteria_weights[train_dataset.bacteria_ids.flatten()]\n",
    "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 创建模型\n",
    "        input_dim = train_dataset.combined_features.shape[1]\n",
    "        n_bacteria = len(self.bacteria_mapping['bacteria_to_id'])\n",
    "        model = ConditionalRegressionModel(\n",
    "            input_dim=input_dim,\n",
    "            n_bacteria=n_bacteria,\n",
    "            bacteria_embedding_dim=32\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # 优化器和损失函数\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "        criterion = CensoringAwareHuberLoss(delta=1.0, censoring_weight=2.0)\n",
    "        \n",
    "        # 训练循环\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                features = batch['features'].to(self.device)\n",
    "                bacteria_ids = batch['bacteria_id'].to(self.device)\n",
    "                targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                is_censored = batch['is_censored'].squeeze(-1).to(self.device)\n",
    "                censoring_threshold = batch['censoring_threshold'].squeeze(-1).to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(features, bacteria_ids)\n",
    "                loss = criterion(predictions, targets, is_censored, censoring_threshold)\n",
    "                loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # 验证阶段\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    features = batch['features'].to(self.device)\n",
    "                    bacteria_ids = batch['bacteria_id'].to(self.device)\n",
    "                    targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                    is_censored = batch['is_censored'].squeeze(-1).to(self.device)\n",
    "                    censoring_threshold = batch['censoring_threshold'].squeeze(-1).to(self.device)\n",
    "                    \n",
    "                    predictions = model(features, bacteria_ids)\n",
    "                    loss = criterion(predictions, targets, is_censored, censoring_threshold)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    val_predictions.extend(predictions.cpu().numpy())\n",
    "                    val_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            # 计算评估指标\n",
    "            val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
    "            val_r2 = r2_score(val_targets, val_predictions)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, \"\n",
    "                  f\"Val RMSE={val_rmse:.4f}, Val R²={val_r2:.4f}\")\n",
    "            \n",
    "            # 学习率调度\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # 早停\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型\n",
    "                torch.save(model.state_dict(), \n",
    "                          os.path.join(self.output_dir, 'conditional_regression_best.pt'))\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"早停在第 {epoch+1} 轮\")\n",
    "                    break\n",
    "        \n",
    "        # 保存训练历史\n",
    "        history = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.output_dir, 'conditional_training_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "        \n",
    "        # 加载最佳模型进行测试\n",
    "        model.load_state_dict(torch.load(os.path.join(self.output_dir, 'conditional_regression_best.pt')))\n",
    "        self.conditional_model = model\n",
    "        \n",
    "        # 在测试集上评估\n",
    "        self.evaluate_conditional_model()\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    def evaluate_sequence_model(self):\n",
    "        \"\"\"评估序列聚合模型\"\"\"\n",
    "        print(\"\\n=== 评估序列聚合模型 ===\")\n",
    "        \n",
    "        test_dataset = self.datasets['sequence_test']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "        \n",
    "        self.sequence_model.eval()\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                features = batch['features'].to(self.device)\n",
    "                batch_targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                \n",
    "                batch_predictions = self.sequence_model(features)\n",
    "                \n",
    "                predictions.extend(batch_predictions.cpu().numpy())\n",
    "                targets.extend(batch_targets.cpu().numpy())\n",
    "        \n",
    "        # 计算回归指标\n",
    "        rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
    "        r2 = r2_score(targets, predictions)\n",
    "        \n",
    "        print(f\"测试集 RMSE: {rmse:.4f}\")\n",
    "        print(f\"测试集 R²: {r2:.4f}\")\n",
    "        \n",
    "        # 计算二分类指标（不同阈值）\n",
    "        thresholds = {\n",
    "            '2μM': np.log10(2),    # ≈ 0.301\n",
    "            '5μM': np.log10(5),    # ≈ 0.699  \n",
    "            '10μM': np.log10(10)   # = 1.0\n",
    "        }\n",
    "        \n",
    "        for name, threshold in thresholds.items():\n",
    "            y_true = (np.array(targets) <= threshold).astype(int)\n",
    "            y_scores = -np.array(predictions)  # 负号：越小的预测值越可能是活性的\n",
    "            \n",
    "            if len(np.unique(y_true)) == 2:  # 确保有两个类别\n",
    "                auc = roc_auc_score(y_true, y_scores)\n",
    "                ap = average_precision_score(y_true, y_scores)\n",
    "                print(f\"{name} 阈值 - AUC: {auc:.4f}, AP: {ap:.4f}\")\n",
    "        \n",
    "        # 保存预测结果\n",
    "        results = {\n",
    "            'predictions': predictions,\n",
    "            'targets': targets,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.output_dir, 'sequence_test_results.pkl'), 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_conditional_model(self):\n",
    "        \"\"\"评估条件回归模型\"\"\"\n",
    "        print(\"\\n=== 评估条件回归模型 ===\")\n",
    "        \n",
    "        test_dataset = self.datasets['conditional_test']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "        \n",
    "        self.conditional_model.eval()\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        bacteria_ids = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                features = batch['features'].to(self.device)\n",
    "                batch_bacteria_ids = batch['bacteria_id'].to(self.device)\n",
    "                batch_targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                \n",
    "                batch_predictions = self.conditional_model(features, batch_bacteria_ids)\n",
    "                \n",
    "                predictions.extend(batch_predictions.cpu().numpy())\n",
    "                targets.extend(batch_targets.cpu().numpy())\n",
    "                bacteria_ids.extend(batch_bacteria_ids.squeeze(-1).cpu().numpy())\n",
    "        \n",
    "        # 整体指标\n",
    "        rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
    "        r2 = r2_score(targets, predictions)\n",
    "        \n",
    "        print(f\"整体测试集 RMSE: {rmse:.4f}\")\n",
    "        print(f\"整体测试集 R²: {r2:.4f}\")\n",
    "        \n",
    "        # 按菌株评估\n",
    "        unique_bacteria = np.unique(bacteria_ids)\n",
    "        bacteria_results = {}\n",
    "        \n",
    "        for bacteria_id in unique_bacteria:\n",
    "            mask = np.array(bacteria_ids) == bacteria_id\n",
    "            if mask.sum() >= 10:  # 至少10个样本\n",
    "                bacteria_pred = np.array(predictions)[mask]\n",
    "                bacteria_target = np.array(targets)[mask]\n",
    "                \n",
    "                bacteria_rmse = np.sqrt(mean_squared_error(bacteria_target, bacteria_pred))\n",
    "                bacteria_r2 = r2_score(bacteria_target, bacteria_pred)\n",
    "                \n",
    "                bacteria_name = self.bacteria_mapping['id_to_bacteria'][bacteria_id]\n",
    "                bacteria_results[bacteria_name] = {\n",
    "                    'rmse': bacteria_rmse,\n",
    "                    'r2': bacteria_r2,\n",
    "                    'n_samples': mask.sum()\n",
    "                }\n",
    "        \n",
    "        # 显示Top 10菌株结果\n",
    "        print(\"\\nTop 10 菌株结果:\")\n",
    "        sorted_bacteria = sorted(bacteria_results.items(), \n",
    "                               key=lambda x: x[1]['n_samples'], reverse=True)\n",
    "        \n",
    "        for bacteria_name, results in sorted_bacteria[:10]:\n",
    "            print(f\"{bacteria_name}: RMSE={results['rmse']:.4f}, \"\n",
    "                  f\"R²={results['r2']:.4f}, N={results['n_samples']}\")\n",
    "        \n",
    "        # 计算二分类指标\n",
    "        thresholds = {\n",
    "            '2μM': np.log10(2),\n",
    "            '5μM': np.log10(5),\n",
    "            '10μM': np.log10(10)\n",
    "        }\n",
    "        \n",
    "        for name, threshold in thresholds.items():\n",
    "            y_true = (np.array(targets) <= threshold).astype(int)\n",
    "            y_scores = -np.array(predictions)\n",
    "            \n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc = roc_auc_score(y_true, y_scores)\n",
    "                ap = average_precision_score(y_true, y_scores)\n",
    "                print(f\"{name} 阈值 - AUC: {auc:.4f}, AP: {ap:.4f}\")\n",
    "        \n",
    "        # 保存结果\n",
    "        results = {\n",
    "            'predictions': predictions,\n",
    "            'targets': targets,\n",
    "            'bacteria_ids': bacteria_ids,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'bacteria_results': bacteria_results\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.output_dir, 'conditional_test_results.pkl'), 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_training_curves(self):\n",
    "        \"\"\"绘制训练曲线\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # 序列模型训练曲线\n",
    "        if os.path.exists(os.path.join(self.output_dir, 'sequence_training_history.pkl')):\n",
    "            with open(os.path.join(self.output_dir, 'sequence_training_history.pkl'), 'rb') as f:\n",
    "                seq_history = pickle.load(f)\n",
    "            \n",
    "            axes[0].plot(seq_history['train_losses'], label='训练损失', alpha=0.7)\n",
    "            axes[0].plot(seq_history['val_losses'], label='验证损失', alpha=0.7)\n",
    "            axes[0].set_title('序列聚合模型训练曲线')\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 条件模型训练曲线\n",
    "        if os.path.exists(os.path.join(self.output_dir, 'conditional_training_history.pkl')):\n",
    "            with open(os.path.join(self.output_dir, 'conditional_training_history.pkl'), 'rb') as f:\n",
    "                cond_history = pickle.load(f)\n",
    "            \n",
    "            axes[1].plot(cond_history['train_losses'], label='训练损失', alpha=0.7)\n",
    "            axes[1].plot(cond_history['val_losses'], label='验证损失', alpha=0.7)\n",
    "            axes[1].set_title('条件回归模型训练曲线')\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Loss')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 创建训练器\n",
    "    trainer = AMPTrainer(device='auto', output_dir='/root/NKU-TMU_AMP_project/model_outputs')\n",
    "    \n",
    "    # 加载数据\n",
    "    trainer.load_data(features_dir='/root/NKU-TMU_AMP_project/features')\n",
    "    \n",
    "    # 训练序列聚合模型\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"开始训练序列聚合回归模型\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    sequence_model, seq_history = trainer.train_sequence_model(\n",
    "        batch_size=128,\n",
    "        learning_rate=2e-4,\n",
    "        num_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    # 训练条件回归模型\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"开始训练条件回归模型\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    conditional_model, cond_history = trainer.train_conditional_model(\n",
    "        batch_size=128,\n",
    "        learning_rate=2e-4,\n",
    "        num_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    trainer.plot_training_curves()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"训练完成！模型和结果已保存到 model_outputs/ 目录\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d7a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AMP判别器两层建模训练\n",
      "============================================================\n",
      "批次大小: 128\n",
      "学习率: 0.0002\n",
      "训练轮数: 100\n",
      "早停patience: 10\n",
      "设备: auto\n",
      "特征目录: /root/.local/share/jupyter/runtime/kernel-v3f699397a0edb8b92a8a3a385e54e41119e4d6f86.json\n",
      "输出目录: /root/NKU-TMU_AMP_project/model_outputs\n",
      "============================================================\n",
      "使用设备: cuda\n",
      "\n",
      "步骤1: 加载特征数据\n",
      "正在加载特征数据...\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/root/.local/share/jupyter/runtime/kernel-v3f699397a0edb8b92a8a3a385e54e41119e4d6f86.json/bacteria_mapping.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotADirectoryError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     sys.path.insert(\u001b[32m0\u001b[39m, PROJECT_DIR)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrun_full_training\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m main\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NKU-TMU_AMP_project/run_full_training.py:41\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m步骤1: 加载特征数据\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m数据加载完成，耗时: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m秒\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 训练序列聚合模型\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NKU-TMU_AMP_project/train_discriminators.py:303\u001b[39m, in \u001b[36mAMPTrainer.load_data\u001b[39m\u001b[34m(self, features_dir)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# 加载菌株映射\u001b[39;00m\n\u001b[32m    302\u001b[39m bacteria_mapping_file = os.path.join(features_dir, \u001b[33m'\u001b[39m\u001b[33mbacteria_mapping.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbacteria_mapping_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    304\u001b[39m     \u001b[38;5;28mself\u001b[39m.bacteria_mapping = pickle.load(f)\n\u001b[32m    306\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m菌株数量: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.bacteria_mapping[\u001b[33m'\u001b[39m\u001b[33mbacteria_to_id\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotADirectoryError\u001b[39m: [Errno 20] Not a directory: '/root/.local/share/jupyter/runtime/kernel-v3f699397a0edb8b92a8a3a385e54e41119e4d6f86.json/bacteria_mapping.pkl'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "双头模型训练脚本 - 专注于E.coli和S.aureus\n",
    "基于共享骨干网络 + 两个独立输出头的架构\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 导入数据预处理和特征工程模块\n",
    "sys.path.append('/root/NKU-TMU_AMP_project')\n",
    "from data_preprocessing import GRAMPAPreprocessor\n",
    "from feature_engineering import AMP_FeatureExtractor\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class DualHeadDataset(Dataset):\n",
    "    \"\"\"双头模型数据集类\"\"\"\n",
    "    def __init__(self, features_dict, bacteria_mapping, scaler=None, fit_scaler=False):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        Args:\n",
    "            features_dict: 特征字典\n",
    "            bacteria_mapping: 菌株映射 {'escherichia_coli': 0, 'staphylococcus_aureus': 1}\n",
    "            scaler: 标准化器\n",
    "            fit_scaler: 是否拟合标准化器\n",
    "        \"\"\"\n",
    "        self.plm_embeddings = features_dict['plm_embeddings']\n",
    "        self.physicochemical_features = features_dict['physicochemical_features']\n",
    "        self.targets = features_dict['targets']\n",
    "        self.bacteria_names = features_dict['bacteria_names']\n",
    "        self.sequences = features_dict['sequences']\n",
    "        \n",
    "        # 可选字段\n",
    "        self.is_censored = features_dict.get('is_censored', None)\n",
    "        self.censoring_threshold = features_dict.get('censoring_threshold', None)\n",
    "        self.sample_weights = features_dict.get('sample_weights', None)\n",
    "        \n",
    "        # 菌株ID映射\n",
    "        self.bacteria_mapping = bacteria_mapping\n",
    "        self.bacteria_ids = np.array([bacteria_mapping[name] for name in self.bacteria_names])\n",
    "        \n",
    "        # 标准化理化特征\n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            fit_scaler = True\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            \n",
    "        if fit_scaler:\n",
    "            self.physicochemical_features_scaled = self.scaler.fit_transform(self.physicochemical_features)\n",
    "        else:\n",
    "            self.physicochemical_features_scaled = self.scaler.transform(self.physicochemical_features)\n",
    "        \n",
    "        # 合并特征\n",
    "        self.combined_features = np.concatenate([\n",
    "            self.plm_embeddings,\n",
    "            self.physicochemical_features_scaled\n",
    "        ], axis=1)\n",
    "        \n",
    "        print(f\"数据集大小: {len(self.targets)}\")\n",
    "        print(f\"特征维度: PLM={self.plm_embeddings.shape[1]}, 理化={self.physicochemical_features.shape[1]}\")\n",
    "        print(f\"合并特征维度: {self.combined_features.shape[1]}\")\n",
    "        \n",
    "        # 统计菌株分布\n",
    "        bacteria_counts = pd.Series(self.bacteria_names).value_counts()\n",
    "        print(\"菌株分布:\")\n",
    "        for bacteria, count in bacteria_counts.items():\n",
    "            print(f\"  {bacteria}: {count} ({100*count/len(self.bacteria_names):.1f}%)\")\n",
    "        \n",
    "        if self.is_censored is not None:\n",
    "            censored_count = np.sum(self.is_censored)\n",
    "            print(f\"删失样本数: {censored_count} / {len(self.is_censored)} ({100*censored_count/len(self.is_censored):.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'features': torch.FloatTensor(self.combined_features[idx]),\n",
    "            'target': torch.FloatTensor([self.targets[idx]]),\n",
    "            'bacteria_id': torch.LongTensor([self.bacteria_ids[idx]]),\n",
    "            'bacteria_name': self.bacteria_names[idx],\n",
    "            'sequence': self.sequences[idx]\n",
    "        }\n",
    "        \n",
    "        if self.is_censored is not None:\n",
    "            item['is_censored'] = torch.BoolTensor([self.is_censored[idx]])\n",
    "            item['censoring_threshold'] = torch.FloatTensor([self.censoring_threshold[idx]])\n",
    "        \n",
    "        if self.sample_weights is not None:\n",
    "            item['sample_weight'] = torch.FloatTensor([self.sample_weights[idx]])\n",
    "        \n",
    "        return item\n",
    "\n",
    "class DualHeadModel(nn.Module):\n",
    "    \"\"\"双头模型：共享骨干 + 两个独立输出头\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[512, 256], dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 共享骨干网络\n",
    "        backbone_layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            backbone_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU(),  # Swish激活函数\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "        \n",
    "        # 两个独立的输出头\n",
    "        self.head_ecoli = nn.Linear(prev_dim, 1)      # Head₀: E.coli\n",
    "        self.head_saureus = nn.Linear(prev_dim, 1)    # Head₁: S.aureus\n",
    "        \n",
    "        # 权重初始化\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 共享骨干\n",
    "        shared_features = self.backbone(features)\n",
    "        \n",
    "        # 两个独立输出头\n",
    "        pred_ecoli = self.head_ecoli(shared_features).squeeze(-1)\n",
    "        pred_saureus = self.head_saureus(shared_features).squeeze(-1)\n",
    "        \n",
    "        return pred_ecoli, pred_saureus\n",
    "\n",
    "class DualHeadLoss(nn.Module):\n",
    "    \"\"\"双头模型的损失函数（删失感知 + 稳健）\"\"\"\n",
    "    def __init__(self, delta=1.0, censoring_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.censoring_weight = censoring_weight\n",
    "    \n",
    "    def huber_loss(self, pred, target):\n",
    "        \"\"\"Huber损失\"\"\"\n",
    "        abs_error = torch.abs(pred - target)\n",
    "        quadratic = torch.clamp(abs_error, max=self.delta)\n",
    "        linear = abs_error - quadratic\n",
    "        return 0.5 * quadratic**2 + self.delta * linear\n",
    "    \n",
    "    def forward(self, pred_ecoli, pred_saureus, targets, bacteria_ids, \n",
    "                is_censored=None, censoring_threshold=None):\n",
    "        \"\"\"\n",
    "        计算双头损失\n",
    "        \n",
    "        Args:\n",
    "            pred_ecoli: E.coli预测值 (batch_size,)\n",
    "            pred_saureus: S.aureus预测值 (batch_size,)\n",
    "            targets: 真实值 (batch_size,)\n",
    "            bacteria_ids: 菌株ID (batch_size,) - 0: E.coli, 1: S.aureus\n",
    "            is_censored: 删失标记 (batch_size,)\n",
    "            censoring_threshold: 删失阈值 (batch_size,)\n",
    "        \"\"\"\n",
    "        batch_size = len(targets)\n",
    "        total_loss = 0.0\n",
    "        valid_samples = 0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            bacteria_id = bacteria_ids[i].item()\n",
    "            target = targets[i]\n",
    "            \n",
    "            # 根据菌株ID选择对应的预测头\n",
    "            if bacteria_id == 0:  # E.coli\n",
    "                pred = pred_ecoli[i]\n",
    "            else:  # S.aureus\n",
    "                pred = pred_saureus[i]\n",
    "            \n",
    "            # 计算该样本的损失\n",
    "            if is_censored is not None and is_censored[i]:\n",
    "                # 删失样本：右删失约束\n",
    "                threshold = censoring_threshold[i]\n",
    "                censored_loss = torch.clamp(threshold - pred, min=0) ** 2\n",
    "                sample_loss = self.censoring_weight * censored_loss\n",
    "            else:\n",
    "                # 非删失样本：Huber损失\n",
    "                sample_loss = self.huber_loss(pred, target)\n",
    "            \n",
    "            total_loss += sample_loss\n",
    "            valid_samples += 1\n",
    "        \n",
    "        return total_loss / valid_samples if valid_samples > 0 else torch.tensor(0.0)\n",
    "\n",
    "class DualHeadTrainer:\n",
    "    \"\"\"双头模型训练器\"\"\"\n",
    "    def __init__(self, device='auto', output_dir='model_outputs'):\n",
    "        if device == 'auto':\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = torch.device(device)\n",
    "        \n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"使用设备: {self.device}\")\n",
    "        \n",
    "        # 菌株映射\n",
    "        self.bacteria_mapping = {\n",
    "            'escherichia_coli': 0,\n",
    "            'staphylococcus_aureus': 1\n",
    "        }\n",
    "        self.id_to_bacteria = {0: 'escherichia_coli', 1: 'staphylococcus_aureus'}\n",
    "    \n",
    "    def prepare_data(self, input_file='/root/NKU-TMU_AMP_project/data/AMP/grampa_merged_dataset.csv'):\n",
    "        \"\"\"准备双头模型数据\"\"\"\n",
    "        print(\"=== 步骤1: 数据预处理（仅保留E.coli和S.aureus）===\")\n",
    "        \n",
    "        # 使用数据预处理器\n",
    "        preprocessor = GRAMPAPreprocessor(\n",
    "            input_file=input_file,\n",
    "            output_dir='/root/NKU-TMU_AMP_project/processed_data'\n",
    "        )\n",
    "        \n",
    "        # 运行预处理流程\n",
    "        preprocessor.run_full_pipeline()\n",
    "        \n",
    "        # 加载聚合数据\n",
    "        aggregated_df = pd.read_csv('/root/NKU-TMU_AMP_project/processed_data/grampa_aggregated_full.csv')\n",
    "        \n",
    "        # 过滤只保留两个目标菌株\n",
    "        target_bacteria = ['escherichia_coli', 'staphylococcus_aureus']\n",
    "        filtered_df = aggregated_df[aggregated_df['bacterium'].isin(target_bacteria)].copy()\n",
    "        \n",
    "        print(f\"原始聚合数据: {len(aggregated_df)} 样本\")\n",
    "        print(f\"过滤后数据: {len(filtered_df)} 样本\")\n",
    "        \n",
    "        # 统计过滤后的菌株分布\n",
    "        bacteria_counts = filtered_df['bacterium'].value_counts()\n",
    "        print(\"过滤后菌株分布:\")\n",
    "        for bacteria, count in bacteria_counts.items():\n",
    "            print(f\"  {bacteria}: {count}\")\n",
    "        \n",
    "        # 保存过滤后的数据集\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_df = filtered_df[filtered_df['split'] == split].copy()\n",
    "            if len(split_df) > 0:\n",
    "                output_file = f'/root/NKU-TMU_AMP_project/processed_data/grampa_conditional_{split}_top2.csv'\n",
    "                split_df.to_csv(output_file, index=False)\n",
    "                print(f\"保存 {split} 集: {output_file} ({len(split_df)} 样本)\")\n",
    "        \n",
    "        return filtered_df\n",
    "    \n",
    "    def extract_features(self):\n",
    "        \"\"\"提取特征\"\"\"\n",
    "        print(\"\\n=== 步骤2: 特征提取 ===\")\n",
    "        \n",
    "        # 使用特征提取器\n",
    "        extractor = AMP_FeatureExtractor(\n",
    "            processed_data_dir='/root/NKU-TMU_AMP_project/processed_data',\n",
    "            features_output_dir='/root/NKU-TMU_AMP_project/features',\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # 为双头数据集提取特征\n",
    "        datasets = {}\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            file_path = f'/root/NKU-TMU_AMP_project/processed_data/grampa_conditional_{split}_top2.csv'\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # 收集唯一序列\n",
    "                sequences = df['sequence'].unique()\n",
    "                \n",
    "                # 提取PLM embeddings\n",
    "                plm_embeddings = extractor.extract_plm_embeddings(sequences.tolist())\n",
    "                \n",
    "                # 提取理化特征\n",
    "                physchem_features = extractor.calculate_physicochemical_features(sequences.tolist())\n",
    "                \n",
    "                # 标准化理化特征\n",
    "                if split == 'train':\n",
    "                    scaler = StandardScaler()\n",
    "                    physchem_features_scaled = scaler.fit_transform(physchem_features)\n",
    "                    self.scaler = scaler\n",
    "                else:\n",
    "                    physchem_features_scaled = self.scaler.transform(physchem_features)\n",
    "                \n",
    "                # 创建序列到特征的映射\n",
    "                seq_to_plm = {seq: plm_embeddings[i] for i, seq in enumerate(sequences)}\n",
    "                seq_to_physchem = {seq: physchem_features_scaled[i] for i, seq in enumerate(sequences)}\n",
    "                \n",
    "                # 为数据集中的每个样本分配特征\n",
    "                dataset_plm = np.array([seq_to_plm[seq] for seq in df['sequence']])\n",
    "                dataset_physchem = np.array([seq_to_physchem[seq] for seq in df['sequence']])\n",
    "                \n",
    "                # 构建特征字典\n",
    "                features_dict = {\n",
    "                    'plm_embeddings': dataset_plm,\n",
    "                    'physicochemical_features': dataset_physchem,\n",
    "                    'sequences': df['sequence'].values,\n",
    "                    'bacteria_names': df['bacterium'].values,\n",
    "                    'targets': df['value_winsorized'].values,\n",
    "                    'is_censored': df['is_censored'].values,\n",
    "                    'censoring_threshold': df['censoring_threshold'].fillna(0).values,\n",
    "                    'sample_weights': df['n_measurements'].values\n",
    "                }\n",
    "                \n",
    "                # 保存特征文件\n",
    "                output_file = f'/root/NKU-TMU_AMP_project/features/dual_head_{split}_features.pkl'\n",
    "                with open(output_file, 'wb') as f:\n",
    "                    pickle.dump(features_dict, f)\n",
    "                \n",
    "                datasets[split] = features_dict\n",
    "                print(f\"{split}集特征提取完成: PLM {dataset_plm.shape}, 理化 {dataset_physchem.shape}\")\n",
    "        \n",
    "        return datasets\n",
    "    \n",
    "    def create_datasets(self, features_data):\n",
    "        \"\"\"创建PyTorch数据集\"\"\"\n",
    "        print(\"\\n=== 步骤3: 创建PyTorch数据集 ===\")\n",
    "        \n",
    "        datasets = {}\n",
    "        \n",
    "        # 训练集\n",
    "        train_dataset = DualHeadDataset(\n",
    "            features_data['train'], \n",
    "            self.bacteria_mapping,\n",
    "            fit_scaler=True\n",
    "        )\n",
    "        datasets['train'] = train_dataset\n",
    "        self.scaler = train_dataset.scaler\n",
    "        \n",
    "        # 验证集和测试集\n",
    "        for split in ['val', 'test']:\n",
    "            if split in features_data:\n",
    "                dataset = DualHeadDataset(\n",
    "                    features_data[split],\n",
    "                    self.bacteria_mapping,\n",
    "                    scaler=self.scaler\n",
    "                )\n",
    "                datasets[split] = dataset\n",
    "        \n",
    "        return datasets\n",
    "    \n",
    "    def train_model(self, datasets, batch_size=128, learning_rate=1e-4, \n",
    "                   num_epochs=100, patience=15):\n",
    "        \"\"\"训练双头模型\"\"\"\n",
    "        print(\"\\n=== 步骤4: 训练双头模型 ===\")\n",
    "        \n",
    "        train_dataset = datasets['train']\n",
    "        val_dataset = datasets['val']\n",
    "        \n",
    "        # 创建平衡采样器\n",
    "        bacteria_ids = train_dataset.bacteria_ids\n",
    "        bacteria_counts = np.bincount(bacteria_ids)\n",
    "        bacteria_weights = 1.0 / np.sqrt(bacteria_counts + 1e-8)\n",
    "        sample_weights = bacteria_weights[bacteria_ids]\n",
    "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 创建模型\n",
    "        input_dim = train_dataset.combined_features.shape[1]\n",
    "        model = DualHeadModel(input_dim=input_dim, hidden_dims=[512, 256], dropout=0.2).to(self.device)\n",
    "        \n",
    "        # 优化器和损失函数\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "        criterion = DualHeadLoss(delta=1.0, censoring_weight=1.0)\n",
    "        \n",
    "        # 训练循环\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                features = batch['features'].to(self.device)\n",
    "                targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                bacteria_ids = batch['bacteria_id'].squeeze(-1).to(self.device)\n",
    "                is_censored = batch['is_censored'].squeeze(-1).to(self.device)\n",
    "                censoring_threshold = batch['censoring_threshold'].squeeze(-1).to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                pred_ecoli, pred_saureus = model(features)\n",
    "                loss = criterion(pred_ecoli, pred_saureus, targets, bacteria_ids, \n",
    "                               is_censored, censoring_threshold)\n",
    "                loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            \n",
    "            # 验证阶段\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_predictions = {0: [], 1: []}  # 分菌株记录预测\n",
    "            val_targets = {0: [], 1: []}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    features = batch['features'].to(self.device)\n",
    "                    targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                    bacteria_ids = batch['bacteria_id'].squeeze(-1).to(self.device)\n",
    "                    is_censored = batch['is_censored'].squeeze(-1).to(self.device)\n",
    "                    censoring_threshold = batch['censoring_threshold'].squeeze(-1).to(self.device)\n",
    "                    \n",
    "                    pred_ecoli, pred_saureus = model(features)\n",
    "                    loss = criterion(pred_ecoli, pred_saureus, targets, bacteria_ids,\n",
    "                                   is_censored, censoring_threshold)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # 分菌株记录预测结果\n",
    "                    for i in range(len(targets)):\n",
    "                        bacteria_id = bacteria_ids[i].item()\n",
    "                        target = targets[i].item()\n",
    "                        \n",
    "                        if bacteria_id == 0:\n",
    "                            pred = pred_ecoli[i].item()\n",
    "                        else:\n",
    "                            pred = pred_saureus[i].item()\n",
    "                        \n",
    "                        val_predictions[bacteria_id].append(pred)\n",
    "                        val_targets[bacteria_id].append(target)\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            # 计算分菌株评估指标\n",
    "            val_metrics = {}\n",
    "            for bacteria_id in [0, 1]:\n",
    "                if len(val_targets[bacteria_id]) > 0:\n",
    "                    preds = np.array(val_predictions[bacteria_id])\n",
    "                    targs = np.array(val_targets[bacteria_id])\n",
    "                    rmse = np.sqrt(mean_squared_error(targs, preds))\n",
    "                    r2 = r2_score(targs, preds)\n",
    "                    val_metrics[self.id_to_bacteria[bacteria_id]] = {'rmse': rmse, 'r2': r2}\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            # 打印进度\n",
    "            print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "            for bacteria_name, metrics in val_metrics.items():\n",
    "                print(f\"  {bacteria_name}: RMSE={metrics['rmse']:.4f}, R²={metrics['r2']:.4f}\")\n",
    "            \n",
    "            # 学习率调度\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # 早停\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型\n",
    "                torch.save(model.state_dict(), \n",
    "                          os.path.join(self.output_dir, 'dual_head_best.pt'))\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"早停在第 {epoch+1} 轮\")\n",
    "                    break\n",
    "        \n",
    "        # 保存训练历史\n",
    "        history = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.output_dir, 'dual_head_training_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "        \n",
    "        # 加载最佳模型\n",
    "        model.load_state_dict(torch.load(os.path.join(self.output_dir, 'dual_head_best.pt')))\n",
    "        self.model = model\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    def evaluate_model(self, datasets):\n",
    "        \"\"\"评估模型\"\"\"\n",
    "        print(\"\\n=== 步骤5: 模型评估 ===\")\n",
    "        \n",
    "        test_dataset = datasets['test']\n",
    "        test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "        \n",
    "        self.model.eval()\n",
    "        predictions = {0: [], 1: []}\n",
    "        targets = {0: [], 1: []}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                features = batch['features'].to(self.device)\n",
    "                batch_targets = batch['target'].squeeze(-1).to(self.device)\n",
    "                bacteria_ids = batch['bacteria_id'].squeeze(-1).to(self.device)\n",
    "                \n",
    "                pred_ecoli, pred_saureus = self.model(features)\n",
    "                \n",
    "                # 分菌株记录结果\n",
    "                for i in range(len(batch_targets)):\n",
    "                    bacteria_id = bacteria_ids[i].item()\n",
    "                    target = batch_targets[i].item()\n",
    "                    \n",
    "                    if bacteria_id == 0:\n",
    "                        pred = pred_ecoli[i].item()\n",
    "                    else:\n",
    "                        pred = pred_saureus[i].item()\n",
    "                    \n",
    "                    predictions[bacteria_id].append(pred)\n",
    "                    targets[bacteria_id].append(target)\n",
    "        \n",
    "        # 计算评估指标\n",
    "        results = {}\n",
    "        for bacteria_id in [0, 1]:\n",
    "            bacteria_name = self.id_to_bacteria[bacteria_id]\n",
    "            preds = np.array(predictions[bacteria_id])\n",
    "            targs = np.array(targets[bacteria_id])\n",
    "            \n",
    "            if len(targs) > 0:\n",
    "                rmse = np.sqrt(mean_squared_error(targs, preds))\n",
    "                r2 = r2_score(targs, preds)\n",
    "                \n",
    "                # 计算二分类指标\n",
    "                thresholds = {'2μM': np.log10(2), '5μM': np.log10(5), '10μM': np.log10(10)}\n",
    "                binary_metrics = {}\n",
    "                \n",
    "                for name, threshold in thresholds.items():\n",
    "                    y_true = (targs <= threshold).astype(int)\n",
    "                    y_scores = -preds  # 负号：越小的预测值越可能是活性的\n",
    "                    \n",
    "                    if len(np.unique(y_true)) == 2:\n",
    "                        auc = roc_auc_score(y_true, y_scores)\n",
    "                        ap = average_precision_score(y_true, y_scores)\n",
    "                        binary_metrics[name] = {'auc': auc, 'ap': ap}\n",
    "                \n",
    "                results[bacteria_name] = {\n",
    "                    'rmse': rmse,\n",
    "                    'r2': r2,\n",
    "                    'n_samples': len(targs),\n",
    "                    'predictions': preds,\n",
    "                    'targets': targs,\n",
    "                    'binary_metrics': binary_metrics\n",
    "                }\n",
    "                \n",
    "                print(f\"{bacteria_name} 测试结果:\")\n",
    "                print(f\"  样本数: {len(targs)}\")\n",
    "                print(f\"  RMSE: {rmse:.4f}\")\n",
    "                print(f\"  R²: {r2:.4f}\")\n",
    "                \n",
    "                for name, metrics in binary_metrics.items():\n",
    "                    print(f\"  {name} - AUC: {metrics['auc']:.4f}, AP: {metrics['ap']:.4f}\")\n",
    "        \n",
    "        # 保存结果\n",
    "        with open(os.path.join(self.output_dir, 'dual_head_test_results.pkl'), 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_results(self, history, test_results):\n",
    "        \"\"\"绘制结果图\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # 训练曲线\n",
    "        axes[0, 0].plot(history['train_losses'], label='训练损失', alpha=0.7)\n",
    "        axes[0, 0].plot(history['val_losses'], label='验证损失', alpha=0.7)\n",
    "        axes[0, 0].set_title('双头模型训练曲线')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 预测vs真实值散点图\n",
    "        for i, (bacteria_name, results) in enumerate(test_results.items()):\n",
    "            row = (i + 1) // 2\n",
    "            col = (i + 1) % 2\n",
    "            \n",
    "            preds = results['predictions']\n",
    "            targs = results['targets']\n",
    "            \n",
    "            axes[row, col].scatter(targs, preds, alpha=0.6)\n",
    "            axes[row, col].plot([targs.min(), targs.max()], [targs.min(), targs.max()], 'r--', alpha=0.8)\n",
    "            axes[row, col].set_xlabel('真实值 (log MIC)')\n",
    "            axes[row, col].set_ylabel('预测值 (log MIC)')\n",
    "            axes[row, col].set_title(f'{bacteria_name}\\nR²={results[\"r2\"]:.4f}, RMSE={results[\"rmse\"]:.4f}')\n",
    "            axes[row, col].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, 'dual_head_results.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"结果图已保存: {os.path.join(self.output_dir, 'dual_head_results.png')}\")\n",
    "    \n",
    "    def run_full_pipeline(self, input_file='/root/NKU-TMU_AMP_project/data/AMP/grampa_merged_dataset.csv'):\n",
    "        \"\"\"运行完整流程\"\"\"\n",
    "        print(\"开始双头模型训练流程...\")\n",
    "        \n",
    "        # 步骤1: 数据准备\n",
    "        self.prepare_data(input_file)\n",
    "        \n",
    "        # 步骤2: 特征提取\n",
    "        features_data = self.extract_features()\n",
    "        \n",
    "        # 步骤3: 创建数据集\n",
    "        datasets = self.create_datasets(features_data)\n",
    "        \n",
    "        # 步骤4: 训练模型\n",
    "        model, history = self.train_model(datasets)\n",
    "        \n",
    "        # 步骤5: 评估模型\n",
    "        test_results = self.evaluate_model(datasets)\n",
    "        \n",
    "        # 步骤6: 绘制结果\n",
    "        self.plot_results(history, test_results)\n",
    "        \n",
    "        # 生成报告\n",
    "        self.generate_report(history, test_results)\n",
    "        \n",
    "        print(f\"\\n双头模型训练完成！结果保存在: {self.output_dir}\")\n",
    "        \n",
    "        return model, history, test_results\n",
    "    \n",
    "    def generate_report(self, history, test_results):\n",
    "        \"\"\"生成训练报告\"\"\"\n",
    "        report_file = os.path.join(self.output_dir, 'dual_head_report.md')\n",
    "        \n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# 双头模型训练报告\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 模型架构\\n\")\n",
    "            f.write(\"- 共享骨干网络: 512 → 256\\n\")\n",
    "            f.write(\"- 两个独立输出头: E.coli 和 S.aureus\\n\")\n",
    "            f.write(\"- 激活函数: SiLU\\n\")\n",
    "            f.write(\"- 正则化: LayerNorm + Dropout(0.2)\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 训练结果\\n\")\n",
    "            f.write(f\"- 训练轮数: {len(history['train_losses'])}\\n\")\n",
    "            f.write(f\"- 最佳验证损失: {history['best_val_loss']:.4f}\\n\")\n",
    "            f.write(f\"- 最终训练损失: {history['train_losses'][-1]:.4f}\\n\")\n",
    "            f.write(f\"- 最终验证损失: {history['val_losses'][-1]:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## 测试结果\\n\")\n",
    "            for bacteria_name, results in test_results.items():\n",
    "                f.write(f\"### {bacteria_name}\\n\")\n",
    "                f.write(f\"- 样本数: {results['n_samples']}\\n\")\n",
    "                f.write(f\"- RMSE: {results['rmse']:.4f}\\n\")\n",
    "                f.write(f\"- R²: {results['r2']:.4f}\\n\")\n",
    "                \n",
    "                f.write(\"- 二分类指标:\\n\")\n",
    "                for threshold, metrics in results['binary_metrics'].items():\n",
    "                    f.write(f\"  - {threshold}: AUC={metrics['auc']:.4f}, AP={metrics['ap']:.4f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        print(f\"训练报告已保存: {report_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 创建训练器\n",
    "    trainer = DualHeadTrainer(\n",
    "        device='auto',\n",
    "        output_dir='/root/NKU-TMU_AMP_project/model_outputs'\n",
    "    )\n",
    "    \n",
    "    # 运行完整流程\n",
    "    model, history, test_results = trainer.run_full_pipeline()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "序列筛选脚本\n",
    "合并两个CSV文件并应用严格的筛选规则\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_net_charge(sequence, ph=7.0):\n",
    "    \"\"\"\n",
    "    计算序列在指定pH下的净电荷\n",
    "    使用简化的pKa模型\n",
    "    \"\"\"\n",
    "    # 氨基酸pKa值 (简化模型)\n",
    "    pka_values = {\n",
    "        'K': 10.5,  # Lys\n",
    "        'R': 12.5,  # Arg  \n",
    "        'H': 6.0,   # His\n",
    "        'D': 3.9,   # Asp\n",
    "        'E': 4.3,   # Glu\n",
    "        'C': 8.3,   # Cys\n",
    "        'Y': 10.1,  # Tyr\n",
    "    }\n",
    "    \n",
    "    # N端和C端\n",
    "    n_term_pka = 9.6\n",
    "    c_term_pka = 2.3\n",
    "    \n",
    "    net_charge = 0.0\n",
    "    \n",
    "    # N端贡献 (正电荷)\n",
    "    net_charge += 1 / (1 + 10**(ph - n_term_pka))\n",
    "    \n",
    "    # C端贡献 (负电荷)\n",
    "    net_charge -= 1 / (1 + 10**(c_term_pka - ph))\n",
    "    \n",
    "    # 各氨基酸贡献\n",
    "    for aa in sequence:\n",
    "        if aa in pka_values:\n",
    "            pka = pka_values[aa]\n",
    "            if aa in ['K', 'R', 'H']:  # 碱性氨基酸 (正电荷)\n",
    "                net_charge += 1 / (1 + 10**(ph - pka))\n",
    "            else:  # 酸性氨基酸 (负电荷)\n",
    "                net_charge -= 1 / (1 + 10**(pka - ph))\n",
    "    \n",
    "    return net_charge\n",
    "\n",
    "def has_long_repeats(sequence, max_repeat=10):\n",
    "    \"\"\"\n",
    "    检查序列是否有超过max_repeat的连续重复氨基酸\n",
    "    \"\"\"\n",
    "    current_aa = sequence[0] if sequence else ''\n",
    "    count = 1\n",
    "    \n",
    "    for i in range(1, len(sequence)):\n",
    "        if sequence[i] == current_aa:\n",
    "            count += 1\n",
    "            if count > max_repeat:\n",
    "                return True\n",
    "        else:\n",
    "            current_aa = sequence[i]\n",
    "            count = 1\n",
    "    \n",
    "    return False\n",
    "\n",
    "def calculate_kr_ratio(sequence):\n",
    "    \"\"\"\n",
    "    计算K+R占比\n",
    "    \"\"\"\n",
    "    if not sequence:\n",
    "        return 0.0\n",
    "    \n",
    "    k_count = sequence.count('K')\n",
    "    r_count = sequence.count('R')\n",
    "    total_length = len(sequence)\n",
    "    \n",
    "    return (k_count + r_count) / total_length\n",
    "\n",
    "def load_and_merge_data():\n",
    "    \"\"\"\n",
    "    加载并合并两个CSV文件\n",
    "    \"\"\"\n",
    "    print(\"正在加载数据文件...\")\n",
    "    \n",
    "    # 读取两个文件\n",
    "    df1 = pd.read_csv('/root/NKU-TMU_AMP_project/decode/full_data/decoded_optimized.csv')\n",
    "    df2 = pd.read_csv('/root/NKU-TMU_AMP_project/decode/full_data/decoded_optimized2.csv')\n",
    "    \n",
    "    print(f\"文件1包含 {len(df1)} 条序列\")\n",
    "    print(f\"文件2包含 {len(df2)} 条序列\")\n",
    "    \n",
    "    # 合并数据\n",
    "    merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(f\"合并后共 {len(merged_df)} 条序列\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def load_known_sequences():\n",
    "    \"\"\"\n",
    "    加载已知的AMP序列\n",
    "    \"\"\"\n",
    "    try:\n",
    "        final_amp_df = pd.read_csv('/root/NKU-TMU_AMP_project/data/AMP/final_AMP.csv')\n",
    "        # 假设序列列名为'sequence'，如果不是需要调整\n",
    "        if 'sequence' in final_amp_df.columns:\n",
    "            known_sequences = set(final_amp_df['sequence'].dropna())\n",
    "        elif 'Sequence' in final_amp_df.columns:\n",
    "            known_sequences = set(final_amp_df['Sequence'].dropna())\n",
    "        else:\n",
    "            # 取第一列作为序列列\n",
    "            known_sequences = set(final_amp_df.iloc[:, 0].dropna())\n",
    "        \n",
    "        print(f\"加载了 {len(known_sequences)} 条已知AMP序列\")\n",
    "        return known_sequences\n",
    "    except Exception as e:\n",
    "        print(f\"加载已知序列时出错: {e}\")\n",
    "        return set()\n",
    "\n",
    "def apply_filters(df, known_sequences=None):\n",
    "    \"\"\"\n",
    "    应用所有筛选规则\n",
    "    \"\"\"\n",
    "    print(\"\\n开始应用筛选规则...\")\n",
    "    original_count = len(df)\n",
    "    \n",
    "    # 确保有序列列\n",
    "    sequence_col = None\n",
    "    for col in ['sequence', 'Sequence', 'seq']:\n",
    "        if col in df.columns:\n",
    "            sequence_col = col\n",
    "            break\n",
    "    \n",
    "    if sequence_col is None:\n",
    "        # 假设第一列是序列\n",
    "        sequence_col = df.columns[0]\n",
    "    \n",
    "    print(f\"使用列 '{sequence_col}' 作为序列数据\")\n",
    "    \n",
    "    # 1. 去除空序列\n",
    "    df = df.dropna(subset=[sequence_col])\n",
    "    df = df[df[sequence_col].str.len() > 0]\n",
    "    print(f\"去除空序列后: {len(df)} 条 (减少 {original_count - len(df)} 条)\")\n",
    "    \n",
    "    # 2. 去除重复序列\n",
    "    df = df.drop_duplicates(subset=[sequence_col])\n",
    "    print(f\"去除重复序列后: {len(df)} 条 (减少 {original_count - len(df)} 条)\")\n",
    "    \n",
    "    # 3. 去除已知序列\n",
    "    if known_sequences:\n",
    "        mask = ~df[sequence_col].isin(known_sequences)\n",
    "        df = df[mask]\n",
    "        print(f\"去除已知序列后: {len(df)} 条 (减少 {original_count - len(df)} 条)\")\n",
    "    \n",
    "    # 4. 连续重复筛选\n",
    "    print(\"应用连续重复筛选...\")\n",
    "    mask = ~df[sequence_col].apply(lambda x: has_long_repeats(x, max_repeat=10))\n",
    "    df = df[mask]\n",
    "    print(f\"连续重复筛选后: {len(df)} 条 (减少 {original_count - len(df)} 条)\")\n",
    "    \n",
    "    # 5. 净电荷筛选\n",
    "    print(\"计算净电荷...\")\n",
    "    net_charges = df[sequence_col].apply(calculate_net_charge)\n",
    "    mask = net_charges > 0\n",
    "    df = df[mask]\n",
    "    print(f\"净电荷>0筛选后: {len(df)} 条 (减少 {original_count - len(df)} 条)\")\n",
    "    \n",
    "    # 6. K+R占比筛选\n",
    "    print(\"计算K+R占比...\")\n",
    "    kr_ratios = df[sequence_col].apply(calculate_kr_ratio)\n",
    "    mask = kr_ratios <= 0.4\n",
    "    df = df[mask]\n",
    "    print(f\"K+R占比≤40%筛选后: {len(df)} 条 (减少 {original_count - len(df)} 条)\")\n",
    "    \n",
    "    # 添加统计信息列\n",
    "    df['net_charge'] = df[sequence_col].apply(calculate_net_charge)\n",
    "    df['kr_ratio'] = df[sequence_col].apply(calculate_kr_ratio)\n",
    "    df['length'] = df[sequence_col].str.len()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数\n",
    "    \"\"\"\n",
    "    print(\"=== AMP序列筛选程序 ===\")\n",
    "    \n",
    "    # 1. 加载和合并数据\n",
    "    merged_df = load_and_merge_data()\n",
    "    \n",
    "    # 2. 加载已知序列\n",
    "    known_sequences = load_known_sequences()\n",
    "    \n",
    "    # 3. 应用筛选规则\n",
    "    filtered_df = apply_filters(merged_df, known_sequences)\n",
    "    \n",
    "    # 4. 保存结果\n",
    "    output_path = '/root/NKU-TMU_AMP_project/decode/filtered_candidate_sequences.csv'\n",
    "    filtered_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n筛选完成！\")\n",
    "    print(f\"原始序列数: {len(merged_df)}\")\n",
    "    print(f\"筛选后序列数: {len(filtered_df)}\")\n",
    "    print(f\"筛选率: {len(filtered_df)/len(merged_df)*100:.1f}%\")\n",
    "    print(f\"结果已保存到: {output_path}\")\n",
    "    \n",
    "    # 显示一些统计信息\n",
    "    if len(filtered_df) > 0:\n",
    "        sequence_col = None\n",
    "        for col in ['sequence', 'Sequence', 'seq']:\n",
    "            if col in filtered_df.columns:\n",
    "                sequence_col = col\n",
    "                break\n",
    "        if sequence_col is None:\n",
    "            sequence_col = filtered_df.columns[0]\n",
    "            \n",
    "        print(f\"\\n统计信息:\")\n",
    "        print(f\"序列长度范围: {filtered_df['length'].min()}-{filtered_df['length'].max()}\")\n",
    "        print(f\"平均长度: {filtered_df['length'].mean():.1f}\")\n",
    "        print(f\"净电荷范围: {filtered_df['net_charge'].min():.2f}-{filtered_df['net_charge'].max():.2f}\")\n",
    "        print(f\"平均净电荷: {filtered_df['net_charge'].mean():.2f}\")\n",
    "        print(f\"K+R占比范围: {filtered_df['kr_ratio'].min():.3f}-{filtered_df['kr_ratio'].max():.3f}\")\n",
    "        print(f\"平均K+R占比: {filtered_df['kr_ratio'].mean():.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
